{
    "total_valid_rows": {
        "value": 272,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "143",
        "agreement_percentage": 52.57352941176471,
        "mcc": 0.077415994312682,
        "accuracy": 0.5257352941176471,
        "precision": 0.6153846153846154,
        "recall": 0.11851851851851852,
        "f1_score": 0.19875776397515532,
        "balanced_accuracy": 0.5227629088942958,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "152",
        "agreement_percentage": 55.88235294117647,
        "mcc": 0.1428505998189478,
        "accuracy": 0.5588235294117647,
        "precision": 0.6415094339622641,
        "recall": 0.2518518518518518,
        "f1_score": 0.3617021276595744,
        "balanced_accuracy": 0.5565828602324953,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "170",
        "agreement_percentage": 62.5,
        "mcc": 0.25657369019392745,
        "accuracy": 0.625,
        "precision": 0.6012269938650306,
        "recall": 0.725925925925926,
        "f1_score": 0.6577181208053691,
        "balanced_accuracy": 0.6257366855907003,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "165",
        "agreement_percentage": 60.66176470588235,
        "mcc": 0.2166781825675225,
        "accuracy": 0.6066176470588235,
        "precision": 0.5897435897435898,
        "recall": 0.6814814814814815,
        "f1_score": 0.6323024054982818,
        "balanced_accuracy": 0.6071640984049743,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "169",
        "agreement_percentage": 62.13235294117647,
        "mcc": 0.25614583582729283,
        "accuracy": 0.6213235294117647,
        "precision": 0.5909090909090909,
        "recall": 0.7703703703703704,
        "f1_score": 0.6688102893890675,
        "balanced_accuracy": 0.622411462557448,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "160",
        "agreement_percentage": 58.82352941176471,
        "mcc": 0.18634095585804986,
        "accuracy": 0.5882352941176471,
        "precision": 0.632183908045977,
        "recall": 0.4074074074074074,
        "f1_score": 0.4954954954954955,
        "balanced_accuracy": 0.5869153825358204,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "166",
        "agreement_percentage": 61.029411764705884,
        "mcc": 0.2212659547389007,
        "accuracy": 0.6102941176470589,
        "precision": 0.6013986013986014,
        "recall": 0.6370370370370371,
        "f1_score": 0.618705035971223,
        "balanced_accuracy": 0.6104893214382265,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "169",
        "agreement_percentage": 62.13235294117647,
        "mcc": 0.2486454618191658,
        "accuracy": 0.6213235294117647,
        "precision": 0.5987654320987654,
        "recall": 0.7185185185185186,
        "f1_score": 0.6531986531986532,
        "balanced_accuracy": 0.6220329818869965,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "174",
        "agreement_percentage": 63.970588235294116,
        "mcc": 0.28476465073093105,
        "accuracy": 0.6397058823529411,
        "precision": 0.6163522012578616,
        "recall": 0.725925925925926,
        "f1_score": 0.6666666666666667,
        "balanced_accuracy": 0.6403352257366857,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "171",
        "agreement_percentage": 62.86764705882353,
        "mcc": 0.2620000865635834,
        "accuracy": 0.6286764705882353,
        "precision": 0.6075949367088608,
        "recall": 0.7111111111111111,
        "f1_score": 0.6552901023890785,
        "balanced_accuracy": 0.6292781832927818,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "150",
        "agreement_percentage": 55.14705882352941,
        "mcc": 0.1107150178499882,
        "accuracy": 0.5514705882352942,
        "precision": 0.5844155844155844,
        "recall": 0.3333333333333333,
        "f1_score": 0.4245283018867924,
        "balanced_accuracy": 0.5498783454987834,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "150",
        "agreement_percentage": 55.14705882352941,
        "mcc": 0.10866990881715782,
        "accuracy": 0.5514705882352942,
        "precision": 0.5783132530120482,
        "recall": 0.35555555555555557,
        "f1_score": 0.44036697247706424,
        "balanced_accuracy": 0.5500405515004055,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "161",
        "agreement_percentage": 59.19117647058824,
        "mcc": 0.1947654602452237,
        "accuracy": 0.5919117647058824,
        "precision": 0.6395348837209303,
        "recall": 0.4074074074074074,
        "f1_score": 0.49773755656108587,
        "balanced_accuracy": 0.5905650175723168,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}