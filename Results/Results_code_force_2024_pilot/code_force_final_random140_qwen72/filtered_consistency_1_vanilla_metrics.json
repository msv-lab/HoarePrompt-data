{
    "total_valid_rows": {
        "value": 45,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "11",
        "agreement_percentage": 24.444444444444443,
        "mcc": 0,
        "accuracy": 0.24444444444444444,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "16",
        "agreement_percentage": 35.55555555555556,
        "mcc": -0.0374331550802139,
        "accuracy": 0.35555555555555557,
        "precision": 0.7272727272727273,
        "recall": 0.23529411764705882,
        "f1_score": 0.3555555555555555,
        "balanced_accuracy": 0.4812834224598931,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "32",
        "agreement_percentage": 71.11111111111111,
        "mcc": 0.08112739143148368,
        "accuracy": 0.7111111111111111,
        "precision": 0.7692307692307693,
        "recall": 0.8823529411764706,
        "f1_score": 0.8219178082191781,
        "balanced_accuracy": 0.5320855614973262,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "32",
        "agreement_percentage": 71.11111111111111,
        "mcc": 0.08112739143148368,
        "accuracy": 0.7111111111111111,
        "precision": 0.7692307692307693,
        "recall": 0.8823529411764706,
        "f1_score": 0.8219178082191781,
        "balanced_accuracy": 0.5320855614973262,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "34",
        "agreement_percentage": 75.55555555555556,
        "mcc": 0.1857377184774664,
        "accuracy": 0.7555555555555555,
        "precision": 0.7804878048780488,
        "recall": 0.9411764705882353,
        "f1_score": 0.8533333333333334,
        "balanced_accuracy": 0.5614973262032086,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "27",
        "agreement_percentage": 60.0,
        "mcc": -0.08288770053475936,
        "accuracy": 0.6,
        "precision": 0.7352941176470589,
        "recall": 0.7352941176470589,
        "f1_score": 0.735294117647059,
        "balanced_accuracy": 0.4585561497326204,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "29",
        "agreement_percentage": 64.44444444444444,
        "mcc": -0.2010999166349609,
        "accuracy": 0.6444444444444445,
        "precision": 0.725,
        "recall": 0.8529411764705882,
        "f1_score": 0.7837837837837837,
        "balanced_accuracy": 0.4264705882352941,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "29",
        "agreement_percentage": 64.44444444444444,
        "mcc": -0.2010999166349609,
        "accuracy": 0.6444444444444445,
        "precision": 0.725,
        "recall": 0.8529411764705882,
        "f1_score": 0.7837837837837837,
        "balanced_accuracy": 0.4264705882352941,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "29",
        "agreement_percentage": 64.44444444444444,
        "mcc": -0.1014549775037929,
        "accuracy": 0.6444444444444445,
        "precision": 0.7368421052631579,
        "recall": 0.8235294117647058,
        "f1_score": 0.7777777777777778,
        "balanced_accuracy": 0.4572192513368984,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "32",
        "agreement_percentage": 71.11111111111111,
        "mcc": 0.14125902401572996,
        "accuracy": 0.7111111111111111,
        "precision": 0.7837837837837838,
        "recall": 0.8529411764705882,
        "f1_score": 0.8169014084507041,
        "balanced_accuracy": 0.5628342245989304,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "18",
        "agreement_percentage": 40.0,
        "mcc": -0.0900625665675425,
        "accuracy": 0.4,
        "precision": 0.7058823529411765,
        "recall": 0.35294117647058826,
        "f1_score": 0.4705882352941177,
        "balanced_accuracy": 0.44919786096256686,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "17",
        "agreement_percentage": 37.77777777777778,
        "mcc": -0.21968621277986813,
        "accuracy": 0.37777777777777777,
        "precision": 0.65,
        "recall": 0.38235294117647056,
        "f1_score": 0.48148148148148157,
        "balanced_accuracy": 0.3729946524064171,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "25",
        "agreement_percentage": 55.55555555555556,
        "mcc": 0.14252158054681255,
        "accuracy": 0.5555555555555556,
        "precision": 0.8181818181818182,
        "recall": 0.5294117647058824,
        "f1_score": 0.6428571428571428,
        "balanced_accuracy": 0.5828877005347594,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}