{
    "total_valid_rows": {
        "value": 135,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "70",
        "agreement_percentage": 51.85185185185185,
        "mcc": 0.07291428512050491,
        "accuracy": 0.5185185185185185,
        "precision": 0.6153846153846154,
        "recall": 0.11764705882352941,
        "f1_score": 0.19753086419753085,
        "balanced_accuracy": 0.5215100965759438,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "76",
        "agreement_percentage": 56.2962962962963,
        "mcc": 0.16296743401013894,
        "accuracy": 0.562962962962963,
        "precision": 0.6666666666666666,
        "recall": 0.2647058823529412,
        "f1_score": 0.3789473684210526,
        "balanced_accuracy": 0.565188762071993,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "85",
        "agreement_percentage": 62.96296296296296,
        "mcc": 0.26040648964687085,
        "accuracy": 0.6296296296296297,
        "precision": 0.618421052631579,
        "recall": 0.6911764705882353,
        "f1_score": 0.6527777777777778,
        "balanced_accuracy": 0.6291703248463565,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "85",
        "agreement_percentage": 62.96296296296296,
        "mcc": 0.26040648964687085,
        "accuracy": 0.6296296296296297,
        "precision": 0.618421052631579,
        "recall": 0.6911764705882353,
        "f1_score": 0.6527777777777778,
        "balanced_accuracy": 0.6291703248463565,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "86",
        "agreement_percentage": 63.70370370370371,
        "mcc": 0.28665192843809356,
        "accuracy": 0.6370370370370371,
        "precision": 0.6067415730337079,
        "recall": 0.7941176470588235,
        "f1_score": 0.6878980891719746,
        "balanced_accuracy": 0.6358647936786654,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "80",
        "agreement_percentage": 59.25925925925925,
        "mcc": 0.20162935716810124,
        "accuracy": 0.5925925925925926,
        "precision": 0.6511627906976745,
        "recall": 0.4117647058823529,
        "f1_score": 0.5045045045045045,
        "balanced_accuracy": 0.5939420544337137,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "82",
        "agreement_percentage": 60.74074074074074,
        "mcc": 0.21493180462342537,
        "accuracy": 0.6074074074074074,
        "precision": 0.6027397260273972,
        "recall": 0.6470588235294118,
        "f1_score": 0.6241134751773049,
        "balanced_accuracy": 0.6071115013169447,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "88",
        "agreement_percentage": 65.18518518518519,
        "mcc": 0.30846272664836394,
        "accuracy": 0.6518518518518519,
        "precision": 0.6296296296296297,
        "recall": 0.75,
        "f1_score": 0.6845637583892616,
        "balanced_accuracy": 0.6511194029850746,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "91",
        "agreement_percentage": 67.4074074074074,
        "mcc": 0.3528896256283647,
        "accuracy": 0.674074074074074,
        "precision": 0.65,
        "recall": 0.7647058823529411,
        "f1_score": 0.7027027027027027,
        "balanced_accuracy": 0.6733977172958736,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "93",
        "agreement_percentage": 68.88888888888889,
        "mcc": 0.3830415873118009,
        "accuracy": 0.6888888888888889,
        "precision": 0.6625,
        "recall": 0.7794117647058824,
        "f1_score": 0.7162162162162162,
        "balanced_accuracy": 0.6882133450395083,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "75",
        "agreement_percentage": 55.55555555555556,
        "mcc": 0.12954176130661488,
        "accuracy": 0.5555555555555556,
        "precision": 0.6111111111111112,
        "recall": 0.3235294117647059,
        "f1_score": 0.42307692307692313,
        "balanced_accuracy": 0.5572870939420544,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "75",
        "agreement_percentage": 55.55555555555556,
        "mcc": 0.12954176130661488,
        "accuracy": 0.5555555555555556,
        "precision": 0.6111111111111112,
        "recall": 0.3235294117647059,
        "f1_score": 0.42307692307692313,
        "balanced_accuracy": 0.5572870939420544,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "79",
        "agreement_percentage": 58.51851851851851,
        "mcc": 0.18703333852114173,
        "accuracy": 0.5851851851851851,
        "precision": 0.6428571428571429,
        "recall": 0.39705882352941174,
        "f1_score": 0.49090909090909085,
        "balanced_accuracy": 0.5865891132572432,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}