Correctness: **False**

The provided program does not correctly compute the maximum sum for the matrix and the operations needed to achieve this sum. Let's analyze why:

1. **Sum Calculation**: The program calculates the sum based on a flawed logic. It attempts to calculate the sum by adding `n * (n + 1) // 2` for some rows and `i * n` for others, which doesn't align with the goal of maximizing the sum of the matrix by filling it with permutations.

2. **Operations Description**: The operations described in the output are not optimal and do not necessarily lead to the maximum sum. The program suggests filling rows and columns with the permutation `[1, 2, ..., n]` repeatedly, which is not the best strategy to maximize the sum.

### Correct Approach:
To maximize the sum of the matrix, we can use the following strategy:
- For each row `i`, set `a[i, j] = j` for all `j` from `1` to `n`. This ensures that each row is filled with a permutation of `[1, 2, ..., n]`.
- This can be achieved with `n` operations of type 1, where each row `i` is set to the permutation `[1, 2, ..., n]`.

This will result in a matrix where each row is `[1, 2, ..., n]`, and the sum of all elements in the matrix will be `n * (n * (n + 1) // 2)`, which is the maximum possible sum.

### Correct Implementation:
```python
def func():
    t = int(input())
    for _ in range(t):
        n = int(input())
        max_sum = n * (n * (n + 1) // 2)
        print(max_sum, n)
        for i in range(1, n + 1):
            print(1, i, *range(1, n + 1))

func()
```

This implementation correctly calculates the maximum sum and provides the operations needed to achieve this sum within the allowed number of operations (`2n`).