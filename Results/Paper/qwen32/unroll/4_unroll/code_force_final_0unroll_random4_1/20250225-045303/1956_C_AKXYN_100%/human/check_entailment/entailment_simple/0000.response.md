### Reasoning:

The problem requires maximizing the sum of all the numbers in an \( n \times n \) matrix using no more than \( 2n \) operations. The operations involve filling rows or columns with permutations of numbers from 1 to \( n \).

The provided program generates a matrix where each row is filled with the permutation \( [1, 2, \ldots, n] \) and calculates the sum of the matrix. The sum is calculated using the formula \( \sum_{i=0}^{n-1} (i + 1) \times (2i + 1) \), which is a specific formula for the sum when each row is filled with the same permutation.

Here's a breakdown of the program:
1. **Matrix Initialization:** The matrix is initialized with each row being a permutation of numbers from 1 to \( n \).
2. **Sum Calculation:** The sum is calculated using the formula \( \sum_{i=0}^{n-1} (i + 1) \times (2i + 1) \).
3. **Operation Output:** The program outputs the sum and the number of operations (which is \( 2n \)). It then prints \( n \) operations of type 1 and \( n \) operations of type 2, each filling a row or column with the permutation \( [1, 2, \ldots, n] \).

The operations described in the program are valid and ensure that the matrix is filled in such a way that the sum is maximized. The formula used for the sum calculation is correct for the specific filling pattern used in the program. Therefore, the program is correct in terms of both the logic and the operations performed.

### Correctness:
Correctness: **True**