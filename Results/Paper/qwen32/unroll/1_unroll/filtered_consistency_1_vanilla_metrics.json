{
    "total_valid_rows": {
        "value": 58,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "32",
        "agreement_percentage": 55.172413793103445,
        "mcc": 0.1486310266774138,
        "accuracy": 0.5517241379310345,
        "precision": 0.72,
        "recall": 0.4864864864864865,
        "f1_score": 0.5806451612903226,
        "balanced_accuracy": 0.5765765765765766,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "23",
        "agreement_percentage": 39.6551724137931,
        "mcc": -0.03602396837837688,
        "accuracy": 0.39655172413793105,
        "precision": 0.6,
        "recall": 0.16216216216216217,
        "f1_score": 0.25531914893617025,
        "balanced_accuracy": 0.48584298584298585,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "35",
        "agreement_percentage": 60.3448275862069,
        "mcc": 0.05802345006999417,
        "accuracy": 0.603448275862069,
        "precision": 0.6521739130434783,
        "recall": 0.8108108108108109,
        "f1_score": 0.7228915662650603,
        "balanced_accuracy": 0.5244530244530244,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "37",
        "agreement_percentage": 63.793103448275865,
        "mcc": 0.20821052398711914,
        "accuracy": 0.6379310344827587,
        "precision": 0.7105263157894737,
        "recall": 0.7297297297297297,
        "f1_score": 0.7200000000000001,
        "balanced_accuracy": 0.6029601029601029,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "27",
        "agreement_percentage": 46.55172413793103,
        "mcc": -0.061889910108337665,
        "accuracy": 0.46551724137931033,
        "precision": 0.6071428571428571,
        "recall": 0.4594594594594595,
        "f1_score": 0.5230769230769231,
        "balanced_accuracy": 0.46782496782496785,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "19",
        "agreement_percentage": 32.758620689655174,
        "mcc": -0.24572427133532143,
        "accuracy": 0.3275862068965517,
        "precision": 0.42857142857142855,
        "recall": 0.16216216216216217,
        "f1_score": 0.23529411764705885,
        "balanced_accuracy": 0.3906048906048906,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "34",
        "agreement_percentage": 58.620689655172406,
        "mcc": 0.08566309142741742,
        "accuracy": 0.5862068965517241,
        "precision": 0.6666666666666666,
        "recall": 0.7027027027027027,
        "f1_score": 0.6842105263157895,
        "balanced_accuracy": 0.5418275418275418,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "25",
        "agreement_percentage": 43.103448275862064,
        "mcc": -0.0954460595646613,
        "accuracy": 0.43103448275862066,
        "precision": 0.5833333333333334,
        "recall": 0.3783783783783784,
        "f1_score": 0.45901639344262296,
        "balanced_accuracy": 0.4510939510939511,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "28",
        "agreement_percentage": 48.275862068965516,
        "mcc": 0.02402399071651421,
        "accuracy": 0.4827586206896552,
        "precision": 0.6521739130434783,
        "recall": 0.40540540540540543,
        "f1_score": 0.5,
        "balanced_accuracy": 0.5122265122265123,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "23",
        "agreement_percentage": 39.6551724137931,
        "mcc": -0.09687303228651607,
        "accuracy": 0.39655172413793105,
        "precision": 0.5625,
        "recall": 0.24324324324324326,
        "f1_score": 0.339622641509434,
        "balanced_accuracy": 0.45495495495495497,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "22",
        "agreement_percentage": 37.93103448275862,
        "mcc": -0.1285437678163764,
        "accuracy": 0.3793103448275862,
        "precision": 0.5333333333333333,
        "recall": 0.21621621621621623,
        "f1_score": 0.3076923076923077,
        "balanced_accuracy": 0.44144144144144143,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "30",
        "agreement_percentage": 51.724137931034484,
        "mcc": 0.19917221167152824,
        "accuracy": 0.5172413793103449,
        "precision": 0.8,
        "recall": 0.32432432432432434,
        "f1_score": 0.46153846153846156,
        "balanced_accuracy": 0.5907335907335907,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "31",
        "agreement_percentage": 53.44827586206896,
        "mcc": 0.1951983301731552,
        "accuracy": 0.5344827586206896,
        "precision": 0.7777777777777778,
        "recall": 0.3783783783783784,
        "f1_score": 0.5090909090909091,
        "balanced_accuracy": 0.5939510939510939,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}