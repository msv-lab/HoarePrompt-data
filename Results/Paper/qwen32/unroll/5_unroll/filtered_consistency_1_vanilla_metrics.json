{
    "total_valid_rows": {
        "value": 47,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "31",
        "agreement_percentage": 65.95744680851064,
        "mcc": 0.2862979048121443,
        "accuracy": 0.6595744680851063,
        "precision": 0.8148148148148148,
        "recall": 0.6666666666666666,
        "f1_score": 0.7333333333333333,
        "balanced_accuracy": 0.6547619047619048,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "19",
        "agreement_percentage": 40.42553191489361,
        "mcc": 0.030393084083442344,
        "accuracy": 0.40425531914893614,
        "precision": 0.7272727272727273,
        "recall": 0.24242424242424243,
        "f1_score": 0.36363636363636365,
        "balanced_accuracy": 0.5140692640692641,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "31",
        "agreement_percentage": 65.95744680851064,
        "mcc": 0.15209998447489212,
        "accuracy": 0.6595744680851063,
        "precision": 0.7428571428571429,
        "recall": 0.7878787878787878,
        "f1_score": 0.7647058823529412,
        "balanced_accuracy": 0.5725108225108225,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "26",
        "agreement_percentage": 55.319148936170215,
        "mcc": -0.1987435534182576,
        "accuracy": 0.5531914893617021,
        "precision": 0.6578947368421053,
        "recall": 0.7575757575757576,
        "f1_score": 0.704225352112676,
        "balanced_accuracy": 0.4145021645021645,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "25",
        "agreement_percentage": 53.191489361702125,
        "mcc": 0.04165977904505309,
        "accuracy": 0.5319148936170213,
        "precision": 0.72,
        "recall": 0.5454545454545454,
        "f1_score": 0.6206896551724138,
        "balanced_accuracy": 0.5227272727272727,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "23",
        "agreement_percentage": 48.93617021276596,
        "mcc": 0.14652356753831736,
        "accuracy": 0.48936170212765956,
        "precision": 0.8,
        "recall": 0.36363636363636365,
        "f1_score": 0.5000000000000001,
        "balanced_accuracy": 0.5746753246753247,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "33",
        "agreement_percentage": 70.2127659574468,
        "mcc": 0.25879698850951793,
        "accuracy": 0.7021276595744681,
        "precision": 0.7714285714285715,
        "recall": 0.8181818181818182,
        "f1_score": 0.7941176470588236,
        "balanced_accuracy": 0.6233766233766234,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "32",
        "agreement_percentage": 68.08510638297872,
        "mcc": 0.3166816131136075,
        "accuracy": 0.6808510638297872,
        "precision": 0.8214285714285714,
        "recall": 0.696969696969697,
        "f1_score": 0.7540983606557378,
        "balanced_accuracy": 0.66991341991342,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "32",
        "agreement_percentage": 68.08510638297872,
        "mcc": 0.2842974802836732,
        "accuracy": 0.6808510638297872,
        "precision": 0.8,
        "recall": 0.7272727272727273,
        "f1_score": 0.761904761904762,
        "balanced_accuracy": 0.6493506493506493,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "26",
        "agreement_percentage": 55.319148936170215,
        "mcc": 0.18419165903998094,
        "accuracy": 0.5531914893617021,
        "precision": 0.8,
        "recall": 0.48484848484848486,
        "f1_score": 0.6037735849056605,
        "balanced_accuracy": 0.5995670995670996,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "29",
        "agreement_percentage": 61.702127659574465,
        "mcc": 0.19219999204171925,
        "accuracy": 0.6170212765957447,
        "precision": 0.7777777777777778,
        "recall": 0.6363636363636364,
        "f1_score": 0.7000000000000001,
        "balanced_accuracy": 0.6038961038961039,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "26",
        "agreement_percentage": 55.319148936170215,
        "mcc": 0.06968683416725756,
        "accuracy": 0.5531914893617021,
        "precision": 0.7307692307692307,
        "recall": 0.5757575757575758,
        "f1_score": 0.6440677966101696,
        "balanced_accuracy": 0.5378787878787878,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "22",
        "agreement_percentage": 46.808510638297875,
        "mcc": 0.03461725937492032,
        "accuracy": 0.46808510638297873,
        "precision": 0.7222222222222222,
        "recall": 0.3939393939393939,
        "f1_score": 0.5098039215686274,
        "balanced_accuracy": 0.5183982683982684,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}