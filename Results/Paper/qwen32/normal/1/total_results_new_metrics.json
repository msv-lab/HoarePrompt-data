{
    "total_valid_rows": {
        "value": 264,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "158",
        "agreement_percentage": 59.84848484848485,
        "mcc": 0.2548980810579412,
        "accuracy": 0.5984848484848485,
        "precision": 0.7473684210526316,
        "recall": 0.46405228758169936,
        "f1_score": 0.5725806451612904,
        "balanced_accuracy": 0.6239180356827416,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "136",
        "agreement_percentage": 51.515151515151516,
        "mcc": 0.13055410986203747,
        "accuracy": 0.5151515151515151,
        "precision": 0.6923076923076923,
        "recall": 0.29411764705882354,
        "f1_score": 0.4128440366972477,
        "balanced_accuracy": 0.5569687334393216,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "157",
        "agreement_percentage": 59.46969696969697,
        "mcc": 0.17573745790202464,
        "accuracy": 0.5946969696969697,
        "precision": 0.6575342465753424,
        "recall": 0.6274509803921569,
        "f1_score": 0.6421404682274248,
        "balanced_accuracy": 0.5885002649708533,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "166",
        "agreement_percentage": 62.878787878787875,
        "mcc": 0.264629277642475,
        "accuracy": 0.6287878787878788,
        "precision": 0.7131782945736435,
        "recall": 0.6013071895424836,
        "f1_score": 0.6524822695035462,
        "balanced_accuracy": 0.6339869281045751,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "140",
        "agreement_percentage": 53.03030303030303,
        "mcc": 0.10798023749581982,
        "accuracy": 0.5303030303030303,
        "precision": 0.6494845360824743,
        "recall": 0.4117647058823529,
        "f1_score": 0.504,
        "balanced_accuracy": 0.5527291997880233,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "127",
        "agreement_percentage": 48.10606060606061,
        "mcc": 0.05909376776164437,
        "accuracy": 0.4810606060606061,
        "precision": 0.6333333333333333,
        "recall": 0.24836601307189543,
        "f1_score": 0.3568075117370892,
        "balanced_accuracy": 0.5250839074368486,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "158",
        "agreement_percentage": 59.84848484848485,
        "mcc": 0.20834931980311946,
        "accuracy": 0.5984848484848485,
        "precision": 0.688,
        "recall": 0.5620915032679739,
        "f1_score": 0.6187050359712231,
        "balanced_accuracy": 0.6053700759583113,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "147",
        "agreement_percentage": 55.68181818181818,
        "mcc": 0.172021910379979,
        "accuracy": 0.5568181818181818,
        "precision": 0.6956521739130435,
        "recall": 0.41830065359477125,
        "f1_score": 0.5224489795918367,
        "balanced_accuracy": 0.5830242006712595,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "156",
        "agreement_percentage": 59.09090909090909,
        "mcc": 0.2426048626438507,
        "accuracy": 0.5909090909090909,
        "precision": 0.7419354838709677,
        "recall": 0.45098039215686275,
        "f1_score": 0.5609756097560976,
        "balanced_accuracy": 0.6173820879703232,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "150",
        "agreement_percentage": 56.81818181818182,
        "mcc": 0.19796651912117066,
        "accuracy": 0.5681818181818182,
        "precision": 0.7142857142857143,
        "recall": 0.42483660130718953,
        "f1_score": 0.5327868852459017,
        "balanced_accuracy": 0.5953011835364777,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "143",
        "agreement_percentage": 54.166666666666664,
        "mcc": 0.16089998261475497,
        "accuracy": 0.5416666666666666,
        "precision": 0.7,
        "recall": 0.3660130718954248,
        "f1_score": 0.4806866952789699,
        "balanced_accuracy": 0.5748984278396043,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "149",
        "agreement_percentage": 56.439393939393945,
        "mcc": 0.20293989743004134,
        "accuracy": 0.5643939393939394,
        "precision": 0.7261904761904762,
        "recall": 0.39869281045751637,
        "f1_score": 0.5147679324894515,
        "balanced_accuracy": 0.5957428016251546,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "137",
        "agreement_percentage": 51.89393939393939,
        "mcc": 0.13320116410980448,
        "accuracy": 0.5189393939393939,
        "precision": 0.6911764705882353,
        "recall": 0.30718954248366015,
        "f1_score": 0.42533936651583715,
        "balanced_accuracy": 0.5590001766472354,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}