{
    "total_valid_rows": {
        "value": 9,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "1",
        "agreement_percentage": 11.11111111111111,
        "mcc": -0.7559289460184544,
        "accuracy": 0.1111111111111111,
        "precision": 0.3333333333333333,
        "recall": 0.14285714285714285,
        "f1_score": 0.2,
        "balanced_accuracy": 0.07142857142857142,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "4",
        "agreement_percentage": 44.44444444444444,
        "mcc": 0.2857142857142857,
        "accuracy": 0.4444444444444444,
        "precision": 1.0,
        "recall": 0.2857142857142857,
        "f1_score": 0.4444444444444445,
        "balanced_accuracy": 0.6428571428571428,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "6",
        "agreement_percentage": 66.66666666666666,
        "mcc": 0.1889822365046136,
        "accuracy": 0.6666666666666666,
        "precision": 0.8333333333333334,
        "recall": 0.7142857142857143,
        "f1_score": 0.7692307692307692,
        "balanced_accuracy": 0.6071428571428572,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "5",
        "agreement_percentage": 55.55555555555556,
        "mcc": 0.05976143046671968,
        "accuracy": 0.5555555555555556,
        "precision": 0.8,
        "recall": 0.5714285714285714,
        "f1_score": 0.6666666666666666,
        "balanced_accuracy": 0.5357142857142857,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "3",
        "agreement_percentage": 33.33333333333333,
        "mcc": -0.47809144373375745,
        "accuracy": 0.3333333333333333,
        "precision": 0.6,
        "recall": 0.42857142857142855,
        "f1_score": 0.5,
        "balanced_accuracy": 0.21428571428571427,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "4",
        "agreement_percentage": 44.44444444444444,
        "mcc": 0.2857142857142857,
        "accuracy": 0.4444444444444444,
        "precision": 1.0,
        "recall": 0.2857142857142857,
        "f1_score": 0.4444444444444445,
        "balanced_accuracy": 0.6428571428571428,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "6",
        "agreement_percentage": 66.66666666666666,
        "mcc": 0.1889822365046136,
        "accuracy": 0.6666666666666666,
        "precision": 0.8333333333333334,
        "recall": 0.7142857142857143,
        "f1_score": 0.7692307692307692,
        "balanced_accuracy": 0.6071428571428572,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "4",
        "agreement_percentage": 44.44444444444444,
        "mcc": -0.3779644730092272,
        "accuracy": 0.4444444444444444,
        "precision": 0.6666666666666666,
        "recall": 0.5714285714285714,
        "f1_score": 0.6153846153846153,
        "balanced_accuracy": 0.2857142857142857,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "4",
        "agreement_percentage": 44.44444444444444,
        "mcc": -0.05976143046671968,
        "accuracy": 0.4444444444444444,
        "precision": 0.75,
        "recall": 0.42857142857142855,
        "f1_score": 0.5454545454545454,
        "balanced_accuracy": 0.4642857142857143,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "3",
        "agreement_percentage": 33.33333333333333,
        "mcc": -0.47809144373375745,
        "accuracy": 0.3333333333333333,
        "precision": 0.6,
        "recall": 0.42857142857142855,
        "f1_score": 0.5,
        "balanced_accuracy": 0.21428571428571427,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "4",
        "agreement_percentage": 44.44444444444444,
        "mcc": 0.2857142857142857,
        "accuracy": 0.4444444444444444,
        "precision": 1.0,
        "recall": 0.2857142857142857,
        "f1_score": 0.4444444444444445,
        "balanced_accuracy": 0.6428571428571428,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "5",
        "agreement_percentage": 55.55555555555556,
        "mcc": 0.3779644730092272,
        "accuracy": 0.5555555555555556,
        "precision": 1.0,
        "recall": 0.42857142857142855,
        "f1_score": 0.6,
        "balanced_accuracy": 0.7142857142857143,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "5",
        "agreement_percentage": 55.55555555555556,
        "mcc": 0.3779644730092272,
        "accuracy": 0.5555555555555556,
        "precision": 1.0,
        "recall": 0.42857142857142855,
        "f1_score": 0.6,
        "balanced_accuracy": 0.7142857142857143,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}