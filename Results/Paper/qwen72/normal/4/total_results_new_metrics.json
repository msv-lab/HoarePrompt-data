{
    "total_valid_rows": {
        "value": 293,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "160",
        "agreement_percentage": 54.60750853242321,
        "mcc": 0.18034291546963438,
        "accuracy": 0.5460750853242321,
        "precision": 0.8181818181818182,
        "recall": 0.12244897959183673,
        "f1_score": 0.21301775147928992,
        "balanced_accuracy": 0.5475258596589321,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "156",
        "agreement_percentage": 53.242320819112635,
        "mcc": 0.10268703728058381,
        "accuracy": 0.5324232081911263,
        "precision": 0.6388888888888888,
        "recall": 0.1564625850340136,
        "f1_score": 0.25136612021857924,
        "balanced_accuracy": 0.5337107445718013,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "174",
        "agreement_percentage": 59.38566552901023,
        "mcc": 0.1878885409973354,
        "accuracy": 0.5938566552901023,
        "precision": 0.5897435897435898,
        "recall": 0.6258503401360545,
        "f1_score": 0.6072607260726074,
        "balanced_accuracy": 0.5937470878762464,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "184",
        "agreement_percentage": 62.79863481228669,
        "mcc": 0.2559526585882859,
        "accuracy": 0.6279863481228669,
        "precision": 0.6283783783783784,
        "recall": 0.6326530612244898,
        "f1_score": 0.6305084745762711,
        "balanced_accuracy": 0.6279703662286833,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "177",
        "agreement_percentage": 60.40955631399317,
        "mcc": 0.2105872708841761,
        "accuracy": 0.6040955631399317,
        "precision": 0.5906432748538012,
        "recall": 0.6870748299319728,
        "f1_score": 0.6352201257861635,
        "balanced_accuracy": 0.6038113875687261,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "151",
        "agreement_percentage": 51.5358361774744,
        "mcc": 0.03409267500077804,
        "accuracy": 0.515358361774744,
        "precision": 0.5263157894736842,
        "recall": 0.3401360544217687,
        "f1_score": 0.4132231404958677,
        "balanced_accuracy": 0.5159584381697885,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "179",
        "agreement_percentage": 61.092150170648466,
        "mcc": 0.22212902341471835,
        "accuracy": 0.6109215017064846,
        "precision": 0.6170212765957447,
        "recall": 0.5918367346938775,
        "f1_score": 0.6041666666666666,
        "balanced_accuracy": 0.6109868604976236,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "166",
        "agreement_percentage": 56.655290102389074,
        "mcc": 0.13410285216918122,
        "accuracy": 0.5665529010238908,
        "precision": 0.5757575757575758,
        "recall": 0.5170068027210885,
        "f1_score": 0.5448028673835126,
        "balanced_accuracy": 0.566722579442736,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "170",
        "agreement_percentage": 58.02047781569966,
        "mcc": 0.1607201927546535,
        "accuracy": 0.5802047781569966,
        "precision": 0.5857142857142857,
        "recall": 0.5578231292517006,
        "f1_score": 0.5714285714285715,
        "balanced_accuracy": 0.5802814276395489,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "174",
        "agreement_percentage": 59.38566552901023,
        "mcc": 0.1909746772089218,
        "accuracy": 0.5938566552901023,
        "precision": 0.6147540983606558,
        "recall": 0.5102040816326531,
        "f1_score": 0.5576208178438662,
        "balanced_accuracy": 0.5941431367067376,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "168",
        "agreement_percentage": 57.33788395904437,
        "mcc": 0.16268878897794112,
        "accuracy": 0.5733788395904437,
        "precision": 0.627906976744186,
        "recall": 0.3673469387755102,
        "f1_score": 0.46351931330472107,
        "balanced_accuracy": 0.5740844282918647,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "171",
        "agreement_percentage": 58.36177474402731,
        "mcc": 0.18721676473597573,
        "accuracy": 0.5836177474402731,
        "precision": 0.6506024096385542,
        "recall": 0.3673469387755102,
        "f1_score": 0.4695652173913043,
        "balanced_accuracy": 0.5843584008946044,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "168",
        "agreement_percentage": 57.33788395904437,
        "mcc": 0.16644346493643392,
        "accuracy": 0.5733788395904437,
        "precision": 0.6375,
        "recall": 0.3469387755102041,
        "f1_score": 0.44933920704845814,
        "balanced_accuracy": 0.5741543192619514,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}