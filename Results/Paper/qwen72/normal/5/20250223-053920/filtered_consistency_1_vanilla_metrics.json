{
    "total_valid_rows": {
        "value": 17,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "6",
        "agreement_percentage": 35.294117647058826,
        "mcc": 0.1613743060919757,
        "accuracy": 0.35294117647058826,
        "precision": 1.0,
        "recall": 0.08333333333333333,
        "f1_score": 0.15384615384615385,
        "balanced_accuracy": 0.5416666666666666,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "6",
        "agreement_percentage": 35.294117647058826,
        "mcc": 0.1613743060919757,
        "accuracy": 0.35294117647058826,
        "precision": 1.0,
        "recall": 0.08333333333333333,
        "f1_score": 0.15384615384615385,
        "balanced_accuracy": 0.5416666666666666,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "13",
        "agreement_percentage": 76.47058823529412,
        "mcc": 0.43333333333333335,
        "accuracy": 0.7647058823529411,
        "precision": 0.8333333333333334,
        "recall": 0.8333333333333334,
        "f1_score": 0.8333333333333334,
        "balanced_accuracy": 0.7166666666666667,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "13",
        "agreement_percentage": 76.47058823529412,
        "mcc": 0.43333333333333335,
        "accuracy": 0.7647058823529411,
        "precision": 0.8333333333333334,
        "recall": 0.8333333333333334,
        "f1_score": 0.8333333333333334,
        "balanced_accuracy": 0.7166666666666667,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "9",
        "agreement_percentage": 52.94117647058824,
        "mcc": -0.13333333333333333,
        "accuracy": 0.5294117647058824,
        "precision": 0.6666666666666666,
        "recall": 0.6666666666666666,
        "f1_score": 0.6666666666666666,
        "balanced_accuracy": 0.43333333333333335,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "10",
        "agreement_percentage": 58.82352941176471,
        "mcc": 0.27774602993176545,
        "accuracy": 0.5882352941176471,
        "precision": 0.8571428571428571,
        "recall": 0.5,
        "f1_score": 0.631578947368421,
        "balanced_accuracy": 0.65,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "12",
        "agreement_percentage": 70.58823529411765,
        "mcc": 0.3337119062359573,
        "accuracy": 0.7058823529411765,
        "precision": 0.8181818181818182,
        "recall": 0.75,
        "f1_score": 0.7826086956521738,
        "balanced_accuracy": 0.675,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "11",
        "agreement_percentage": 64.70588235294117,
        "mcc": 0.03984095364447979,
        "accuracy": 0.6470588235294118,
        "precision": 0.7142857142857143,
        "recall": 0.8333333333333334,
        "f1_score": 0.7692307692307692,
        "balanced_accuracy": 0.5166666666666667,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "11",
        "agreement_percentage": 64.70588235294117,
        "mcc": 0.15,
        "accuracy": 0.6470588235294118,
        "precision": 0.75,
        "recall": 0.75,
        "f1_score": 0.75,
        "balanced_accuracy": 0.575,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "10",
        "agreement_percentage": 58.82352941176471,
        "mcc": 0.16735967034880075,
        "accuracy": 0.5882352941176471,
        "precision": 0.7777777777777778,
        "recall": 0.5833333333333334,
        "f1_score": 0.6666666666666666,
        "balanced_accuracy": 0.5916666666666667,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "9",
        "agreement_percentage": 52.94117647058824,
        "mcc": 0.35805743701971643,
        "accuracy": 0.5294117647058824,
        "precision": 1.0,
        "recall": 0.3333333333333333,
        "f1_score": 0.5,
        "balanced_accuracy": 0.6666666666666666,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "10",
        "agreement_percentage": 58.82352941176471,
        "mcc": 0.27774602993176545,
        "accuracy": 0.5882352941176471,
        "precision": 0.8571428571428571,
        "recall": 0.5,
        "f1_score": 0.631578947368421,
        "balanced_accuracy": 0.65,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "8",
        "agreement_percentage": 47.05882352941176,
        "mcc": 0.13333333333333333,
        "accuracy": 0.47058823529411764,
        "precision": 0.8,
        "recall": 0.3333333333333333,
        "f1_score": 0.47058823529411764,
        "balanced_accuracy": 0.5666666666666667,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}