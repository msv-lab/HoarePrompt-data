{
    "total_valid_rows": {
        "value": 49,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "18",
        "agreement_percentage": 36.734693877551024,
        "mcc": 0.16962422738696273,
        "accuracy": 0.3673469387755102,
        "precision": 1.0,
        "recall": 0.08823529411764706,
        "f1_score": 0.1621621621621622,
        "balanced_accuracy": 0.5441176470588235,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "18",
        "agreement_percentage": 36.734693877551024,
        "mcc": 0.16962422738696273,
        "accuracy": 0.3673469387755102,
        "precision": 1.0,
        "recall": 0.08823529411764706,
        "f1_score": 0.1621621621621622,
        "balanced_accuracy": 0.5441176470588235,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "35",
        "agreement_percentage": 71.42857142857143,
        "mcc": 0.30293796298659603,
        "accuracy": 0.7142857142857143,
        "precision": 0.7777777777777778,
        "recall": 0.8235294117647058,
        "f1_score": 0.7999999999999999,
        "balanced_accuracy": 0.6450980392156862,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "38",
        "agreement_percentage": 77.55102040816327,
        "mcc": 0.4455118783769423,
        "accuracy": 0.7755102040816326,
        "precision": 0.8108108108108109,
        "recall": 0.8823529411764706,
        "f1_score": 0.8450704225352113,
        "balanced_accuracy": 0.7078431372549019,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "26",
        "agreement_percentage": 53.06122448979592,
        "mcc": -0.08479116984486139,
        "accuracy": 0.5306122448979592,
        "precision": 0.6666666666666666,
        "recall": 0.6470588235294118,
        "f1_score": 0.6567164179104478,
        "balanced_accuracy": 0.45686274509803926,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "25",
        "agreement_percentage": 51.02040816326531,
        "mcc": 0.13871695028878325,
        "accuracy": 0.5102040816326531,
        "precision": 0.7777777777777778,
        "recall": 0.4117647058823529,
        "f1_score": 0.5384615384615384,
        "balanced_accuracy": 0.5725490196078431,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "33",
        "agreement_percentage": 67.3469387755102,
        "mcc": 0.2026409347004933,
        "accuracy": 0.673469387755102,
        "precision": 0.75,
        "recall": 0.7941176470588235,
        "f1_score": 0.7714285714285715,
        "balanced_accuracy": 0.5970588235294118,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "31",
        "agreement_percentage": 63.26530612244898,
        "mcc": 0.13529411764705881,
        "accuracy": 0.6326530612244898,
        "precision": 0.7352941176470589,
        "recall": 0.7352941176470589,
        "f1_score": 0.735294117647059,
        "balanced_accuracy": 0.5676470588235294,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "31",
        "agreement_percentage": 63.26530612244898,
        "mcc": 0.16706986983639835,
        "accuracy": 0.6326530612244898,
        "precision": 0.75,
        "recall": 0.7058823529411765,
        "f1_score": 0.7272727272727272,
        "balanced_accuracy": 0.5862745098039216,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "27",
        "agreement_percentage": 55.10204081632652,
        "mcc": 0.05113099925649136,
        "accuracy": 0.5510204081632653,
        "precision": 0.7142857142857143,
        "recall": 0.5882352941176471,
        "f1_score": 0.6451612903225806,
        "balanced_accuracy": 0.5274509803921569,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "30",
        "agreement_percentage": 61.224489795918366,
        "mcc": 0.30678599553894814,
        "accuracy": 0.6122448979591837,
        "precision": 0.8571428571428571,
        "recall": 0.5294117647058824,
        "f1_score": 0.6545454545454545,
        "balanced_accuracy": 0.6647058823529413,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "28",
        "agreement_percentage": 57.14285714285714,
        "mcc": 0.18107742914725763,
        "accuracy": 0.5714285714285714,
        "precision": 0.782608695652174,
        "recall": 0.5294117647058824,
        "f1_score": 0.631578947368421,
        "balanced_accuracy": 0.5980392156862745,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "25",
        "agreement_percentage": 51.02040816326531,
        "mcc": 0.13871695028878325,
        "accuracy": 0.5102040816326531,
        "precision": 0.7777777777777778,
        "recall": 0.4117647058823529,
        "f1_score": 0.5384615384615384,
        "balanced_accuracy": 0.5725490196078431,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}