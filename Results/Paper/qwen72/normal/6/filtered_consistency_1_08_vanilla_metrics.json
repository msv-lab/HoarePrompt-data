{
    "total_valid_rows": {
        "value": 23,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "9",
        "agreement_percentage": 39.130434782608695,
        "mcc": 0.1556997888323046,
        "accuracy": 0.391304347826087,
        "precision": 1.0,
        "recall": 0.06666666666666667,
        "f1_score": 0.125,
        "balanced_accuracy": 0.5333333333333333,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "14",
        "agreement_percentage": 60.86956521739131,
        "mcc": 0.4338609156373123,
        "accuracy": 0.6086956521739131,
        "precision": 1.0,
        "recall": 0.4,
        "f1_score": 0.5714285714285715,
        "balanced_accuracy": 0.7,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "16",
        "agreement_percentage": 69.56521739130434,
        "mcc": 0.2592724864350674,
        "accuracy": 0.6956521739130435,
        "precision": 0.7,
        "recall": 0.9333333333333333,
        "f1_score": 0.8,
        "balanced_accuracy": 0.5916666666666667,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "13",
        "agreement_percentage": 56.52173913043478,
        "mcc": -0.2253744679276044,
        "accuracy": 0.5652173913043478,
        "precision": 0.6190476190476191,
        "recall": 0.8666666666666667,
        "f1_score": 0.7222222222222222,
        "balanced_accuracy": 0.43333333333333335,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "16",
        "agreement_percentage": 69.56521739130434,
        "mcc": 0.2919371040605711,
        "accuracy": 0.6956521739130435,
        "precision": 0.6818181818181818,
        "recall": 1.0,
        "f1_score": 0.8108108108108109,
        "balanced_accuracy": 0.5625,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "19",
        "agreement_percentage": 82.6086956521739,
        "mcc": 0.6055975280770818,
        "accuracy": 0.8260869565217391,
        "precision": 0.8235294117647058,
        "recall": 0.9333333333333333,
        "f1_score": 0.8749999999999999,
        "balanced_accuracy": 0.7791666666666667,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "14",
        "agreement_percentage": 60.86956521739131,
        "mcc": -0.1556997888323046,
        "accuracy": 0.6086956521739131,
        "precision": 0.6363636363636364,
        "recall": 0.9333333333333333,
        "f1_score": 0.7567567567567568,
        "balanced_accuracy": 0.4666666666666667,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "16",
        "agreement_percentage": 69.56521739130434,
        "mcc": 0.2592724864350674,
        "accuracy": 0.6956521739130435,
        "precision": 0.7,
        "recall": 0.9333333333333333,
        "f1_score": 0.8,
        "balanced_accuracy": 0.5916666666666667,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "17",
        "agreement_percentage": 73.91304347826086,
        "mcc": 0.4225771273642583,
        "accuracy": 0.7391304347826086,
        "precision": 0.7142857142857143,
        "recall": 1.0,
        "f1_score": 0.8333333333333333,
        "balanced_accuracy": 0.625,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "17",
        "agreement_percentage": 73.91304347826086,
        "mcc": 0.4225771273642583,
        "accuracy": 0.7391304347826086,
        "precision": 0.7142857142857143,
        "recall": 1.0,
        "f1_score": 0.8333333333333333,
        "balanced_accuracy": 0.625,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "14",
        "agreement_percentage": 60.86956521739131,
        "mcc": 0.16265001215808886,
        "accuracy": 0.6086956521739131,
        "precision": 0.7142857142857143,
        "recall": 0.6666666666666666,
        "f1_score": 0.689655172413793,
        "balanced_accuracy": 0.5833333333333333,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "15",
        "agreement_percentage": 65.21739130434783,
        "mcc": 0.2802242691589025,
        "accuracy": 0.6521739130434783,
        "precision": 0.7692307692307693,
        "recall": 0.6666666666666666,
        "f1_score": 0.7142857142857142,
        "balanced_accuracy": 0.6458333333333333,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "15",
        "agreement_percentage": 65.21739130434783,
        "mcc": 0.2802242691589025,
        "accuracy": 0.6521739130434783,
        "precision": 0.7692307692307693,
        "recall": 0.6666666666666666,
        "f1_score": 0.7142857142857142,
        "balanced_accuracy": 0.6458333333333333,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}