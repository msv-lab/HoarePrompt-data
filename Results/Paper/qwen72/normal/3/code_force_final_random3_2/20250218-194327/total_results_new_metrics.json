{
    "total_valid_rows": {
        "value": 103,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "54",
        "agreement_percentage": 52.42718446601942,
        "mcc": 0,
        "accuracy": 0.5242718446601942,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "60",
        "agreement_percentage": 58.252427184466015,
        "mcc": 0.2129168697249481,
        "accuracy": 0.5825242718446602,
        "precision": 0.8,
        "recall": 0.16326530612244897,
        "f1_score": 0.27118644067796605,
        "balanced_accuracy": 0.563114134542706,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "63",
        "agreement_percentage": 61.165048543689316,
        "mcc": 0.2250755928990542,
        "accuracy": 0.6116504854368932,
        "precision": 0.5849056603773585,
        "recall": 0.6326530612244898,
        "f1_score": 0.6078431372549019,
        "balanced_accuracy": 0.6126228269085412,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "64",
        "agreement_percentage": 62.13592233009708,
        "mcc": 0.24169191183791058,
        "accuracy": 0.6213592233009708,
        "precision": 0.6,
        "recall": 0.6122448979591837,
        "f1_score": 0.6060606060606062,
        "balanced_accuracy": 0.6209372637944066,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "55",
        "agreement_percentage": 53.398058252427184,
        "mcc": 0.0809377441453347,
        "accuracy": 0.5339805825242718,
        "precision": 0.5079365079365079,
        "recall": 0.6530612244897959,
        "f1_score": 0.5714285714285714,
        "balanced_accuracy": 0.5394935752078609,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "62",
        "agreement_percentage": 60.19417475728155,
        "mcc": 0.21073074969725528,
        "accuracy": 0.6019417475728155,
        "precision": 0.6666666666666666,
        "recall": 0.32653061224489793,
        "f1_score": 0.43835616438356156,
        "balanced_accuracy": 0.5891912320483749,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "60",
        "agreement_percentage": 58.252427184466015,
        "mcc": 0.16231565507395204,
        "accuracy": 0.5825242718446602,
        "precision": 0.5625,
        "recall": 0.5510204081632653,
        "f1_score": 0.5567010309278351,
        "balanced_accuracy": 0.5810657596371882,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "57",
        "agreement_percentage": 55.33980582524271,
        "mcc": 0.11048058573798133,
        "accuracy": 0.5533980582524272,
        "precision": 0.5272727272727272,
        "recall": 0.5918367346938775,
        "f1_score": 0.5576923076923076,
        "balanced_accuracy": 0.5551776266061981,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "59",
        "agreement_percentage": 57.28155339805825,
        "mcc": 0.14728100877622677,
        "accuracy": 0.5728155339805825,
        "precision": 0.5471698113207547,
        "recall": 0.5918367346938775,
        "f1_score": 0.5686274509803921,
        "balanced_accuracy": 0.5736961451247166,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "52",
        "agreement_percentage": 50.48543689320388,
        "mcc": 0.010192532017596302,
        "accuracy": 0.5048543689320388,
        "precision": 0.4807692307692308,
        "recall": 0.5102040816326531,
        "f1_score": 0.4950495049504951,
        "balanced_accuracy": 0.5051020408163265,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "60",
        "agreement_percentage": 58.252427184466015,
        "mcc": 0.16078096934096642,
        "accuracy": 0.5825242718446602,
        "precision": 0.6071428571428571,
        "recall": 0.3469387755102041,
        "f1_score": 0.4415584415584415,
        "balanced_accuracy": 0.5716175359032502,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "55",
        "agreement_percentage": 53.398058252427184,
        "mcc": 0.05203695871567719,
        "accuracy": 0.5339805825242718,
        "precision": 0.5172413793103449,
        "recall": 0.30612244897959184,
        "f1_score": 0.38461538461538464,
        "balanced_accuracy": 0.5234315948601662,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "59",
        "agreement_percentage": 57.28155339805825,
        "mcc": 0.13947608959655508,
        "accuracy": 0.5728155339805825,
        "precision": 0.5925925925925926,
        "recall": 0.32653061224489793,
        "f1_score": 0.42105263157894735,
        "balanced_accuracy": 0.5614134542705971,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}