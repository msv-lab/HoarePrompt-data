{
    "total_valid_rows": {
        "value": 1780,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "958",
        "agreement_percentage": 53.82022471910113,
        "mcc": 0.13685552030364714,
        "accuracy": 0.5382022471910113,
        "precision": 0.75,
        "recall": 0.10204081632653061,
        "f1_score": 0.17964071856287425,
        "balanced_accuracy": 0.5343166219717286,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "989",
        "agreement_percentage": 55.561797752808985,
        "mcc": 0.15901205285875047,
        "accuracy": 0.5556179775280898,
        "precision": 0.7077625570776256,
        "recall": 0.17573696145124718,
        "f1_score": 0.28156221616712085,
        "balanced_accuracy": 0.5522337368503452,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "1104",
        "agreement_percentage": 62.022471910112365,
        "mcc": 0.24161484185359614,
        "accuracy": 0.6202247191011236,
        "precision": 0.608421052631579,
        "recall": 0.655328798185941,
        "f1_score": 0.631004366812227,
        "balanced_accuracy": 0.6205374503179149,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "1115",
        "agreement_percentage": 62.64044943820225,
        "mcc": 0.25397378809441973,
        "accuracy": 0.6264044943820225,
        "precision": 0.6143308746048473,
        "recall": 0.6609977324263039,
        "f1_score": 0.636810486073184,
        "balanced_accuracy": 0.6267126746764036,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "1049",
        "agreement_percentage": 58.932584269662925,
        "mcc": 0.18597028703619461,
        "accuracy": 0.5893258426966292,
        "precision": 0.5686988171064604,
        "recall": 0.7086167800453514,
        "f1_score": 0.6309944472488643,
        "balanced_accuracy": 0.5903885681963951,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "1033",
        "agreement_percentage": 58.03370786516854,
        "mcc": 0.17147466419522664,
        "accuracy": 0.5803370786516854,
        "precision": 0.626641651031895,
        "recall": 0.3786848072562358,
        "f1_score": 0.4720848056537103,
        "balanced_accuracy": 0.5785406218909241,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "1091",
        "agreement_percentage": 61.29213483146068,
        "mcc": 0.22582280348457676,
        "accuracy": 0.6129213483146068,
        "precision": 0.608793686583991,
        "recall": 0.6122448979591837,
        "f1_score": 0.6105144149236857,
        "balanced_accuracy": 0.6129153220308168,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "1050",
        "agreement_percentage": 58.98876404494382,
        "mcc": 0.18033079619598041,
        "accuracy": 0.5898876404494382,
        "precision": 0.5818965517241379,
        "recall": 0.6122448979591837,
        "f1_score": 0.5966850828729282,
        "balanced_accuracy": 0.5900868142357165,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "1058",
        "agreement_percentage": 59.43820224719101,
        "mcc": 0.19006748032425816,
        "accuracy": 0.5943820224719101,
        "precision": 0.5833333333333334,
        "recall": 0.6349206349206349,
        "f1_score": 0.6080347448425624,
        "balanced_accuracy": 0.5947431682398274,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "1050",
        "agreement_percentage": 58.98876404494382,
        "mcc": 0.17962590128801836,
        "accuracy": 0.5898876404494382,
        "precision": 0.5873563218390805,
        "recall": 0.5793650793650794,
        "f1_score": 0.5833333333333333,
        "balanced_accuracy": 0.58979389825715,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "1028",
        "agreement_percentage": 57.752808988764045,
        "mcc": 0.17374252611179894,
        "accuracy": 0.5775280898876405,
        "precision": 0.6457399103139013,
        "recall": 0.32653061224489793,
        "f1_score": 0.4337349397590361,
        "balanced_accuracy": 0.5752920321803554,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "1044",
        "agreement_percentage": 58.651685393258425,
        "mcc": 0.19218348576117825,
        "accuracy": 0.5865168539325842,
        "precision": 0.6573275862068966,
        "recall": 0.3458049886621315,
        "f1_score": 0.45319465081723626,
        "balanced_accuracy": 0.584372427515921,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "1019",
        "agreement_percentage": 57.247191011235955,
        "mcc": 0.15911509920299413,
        "accuracy": 0.5724719101123595,
        "precision": 0.6273684210526316,
        "recall": 0.3378684807256236,
        "f1_score": 0.4392041267501842,
        "balanced_accuracy": 0.570381901832745,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}