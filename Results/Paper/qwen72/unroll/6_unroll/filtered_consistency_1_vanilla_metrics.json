{
    "total_valid_rows": {
        "value": 58,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "17",
        "agreement_percentage": 29.310344827586203,
        "mcc": 0,
        "accuracy": 0.29310344827586204,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "25",
        "agreement_percentage": 43.103448275862064,
        "mcc": 0.2575683664867139,
        "accuracy": 0.43103448275862066,
        "precision": 1.0,
        "recall": 0.1951219512195122,
        "f1_score": 0.326530612244898,
        "balanced_accuracy": 0.5975609756097561,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "43",
        "agreement_percentage": 74.13793103448276,
        "mcc": 0.29165829734524956,
        "accuracy": 0.7413793103448276,
        "precision": 0.76,
        "recall": 0.926829268292683,
        "f1_score": 0.8351648351648352,
        "balanced_accuracy": 0.6104734576757532,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "39",
        "agreement_percentage": 67.24137931034483,
        "mcc": 0.03002163562743107,
        "accuracy": 0.6724137931034483,
        "precision": 0.7115384615384616,
        "recall": 0.9024390243902439,
        "f1_score": 0.7956989247311829,
        "balanced_accuracy": 0.5100430416068866,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "44",
        "agreement_percentage": 75.86206896551724,
        "mcc": 0.3626993274587609,
        "accuracy": 0.7586206896551724,
        "precision": 0.7454545454545455,
        "recall": 1.0,
        "f1_score": 0.8541666666666666,
        "balanced_accuracy": 0.5882352941176471,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "37",
        "agreement_percentage": 63.793103448275865,
        "mcc": 0.22806937818058579,
        "accuracy": 0.6379310344827587,
        "precision": 0.7941176470588235,
        "recall": 0.6585365853658537,
        "f1_score": 0.72,
        "balanced_accuracy": 0.6233859397417504,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "45",
        "agreement_percentage": 77.58620689655173,
        "mcc": 0.40150363011164225,
        "accuracy": 0.7758620689655172,
        "precision": 0.78,
        "recall": 0.9512195121951219,
        "f1_score": 0.8571428571428571,
        "balanced_accuracy": 0.6520803443328551,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "40",
        "agreement_percentage": 68.96551724137932,
        "mcc": 0.14249230358858822,
        "accuracy": 0.6896551724137931,
        "precision": 0.7346938775510204,
        "recall": 0.8780487804878049,
        "f1_score": 0.8,
        "balanced_accuracy": 0.5566714490674318,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "40",
        "agreement_percentage": 68.96551724137932,
        "mcc": 0.14249230358858822,
        "accuracy": 0.6896551724137931,
        "precision": 0.7346938775510204,
        "recall": 0.8780487804878049,
        "f1_score": 0.8,
        "balanced_accuracy": 0.5566714490674318,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "40",
        "agreement_percentage": 68.96551724137932,
        "mcc": 0.22520638580619742,
        "accuracy": 0.6896551724137931,
        "precision": 0.7674418604651163,
        "recall": 0.8048780487804879,
        "f1_score": 0.7857142857142858,
        "balanced_accuracy": 0.6083213773314204,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "25",
        "agreement_percentage": 43.103448275862064,
        "mcc": -0.04306961587883279,
        "accuracy": 0.43103448275862066,
        "precision": 0.6818181818181818,
        "recall": 0.36585365853658536,
        "f1_score": 0.47619047619047616,
        "balanced_accuracy": 0.4770444763271162,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "27",
        "agreement_percentage": 46.55172413793103,
        "mcc": 0.03499406290155164,
        "accuracy": 0.46551724137931033,
        "precision": 0.7272727272727273,
        "recall": 0.3902439024390244,
        "f1_score": 0.5079365079365079,
        "balanced_accuracy": 0.5186513629842181,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "31",
        "agreement_percentage": 53.44827586206896,
        "mcc": 0.12343826289126507,
        "accuracy": 0.5344827586206896,
        "precision": 0.7692307692307693,
        "recall": 0.4878048780487805,
        "f1_score": 0.5970149253731344,
        "balanced_accuracy": 0.5674318507890961,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}