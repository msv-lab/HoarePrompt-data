{
    "total_valid_rows": {
        "value": 13,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "4",
        "agreement_percentage": 30.76923076923077,
        "mcc": 0,
        "accuracy": 0.3076923076923077,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "5",
        "agreement_percentage": 38.46153846153847,
        "mcc": 0.19245008972987526,
        "accuracy": 0.38461538461538464,
        "precision": 1.0,
        "recall": 0.1111111111111111,
        "f1_score": 0.19999999999999998,
        "balanced_accuracy": 0.5555555555555556,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "8",
        "agreement_percentage": 61.53846153846154,
        "mcc": -0.19245008972987526,
        "accuracy": 0.6153846153846154,
        "precision": 0.6666666666666666,
        "recall": 0.8888888888888888,
        "f1_score": 0.761904761904762,
        "balanced_accuracy": 0.4444444444444444,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "8",
        "agreement_percentage": 61.53846153846154,
        "mcc": 0.03042903097250923,
        "accuracy": 0.6153846153846154,
        "precision": 0.7,
        "recall": 0.7777777777777778,
        "f1_score": 0.7368421052631577,
        "balanced_accuracy": 0.5138888888888888,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "10",
        "agreement_percentage": 76.92307692307693,
        "mcc": 0.4330127018922193,
        "accuracy": 0.7692307692307693,
        "precision": 0.75,
        "recall": 1.0,
        "f1_score": 0.8571428571428571,
        "balanced_accuracy": 0.625,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "9",
        "agreement_percentage": 69.23076923076923,
        "mcc": 0.2777777777777778,
        "accuracy": 0.6923076923076923,
        "precision": 0.7777777777777778,
        "recall": 0.7777777777777778,
        "f1_score": 0.7777777777777778,
        "balanced_accuracy": 0.6388888888888888,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "7",
        "agreement_percentage": 53.84615384615385,
        "mcc": -0.2842676218074806,
        "accuracy": 0.5384615384615384,
        "precision": 0.6363636363636364,
        "recall": 0.7777777777777778,
        "f1_score": 0.7000000000000001,
        "balanced_accuracy": 0.3888888888888889,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "11",
        "agreement_percentage": 84.61538461538461,
        "mcc": 0.6396021490668313,
        "accuracy": 0.8461538461538461,
        "precision": 0.8181818181818182,
        "recall": 1.0,
        "f1_score": 0.9,
        "balanced_accuracy": 0.75,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "9",
        "agreement_percentage": 69.23076923076923,
        "mcc": 0.17766726362967536,
        "accuracy": 0.6923076923076923,
        "precision": 0.7272727272727273,
        "recall": 0.8888888888888888,
        "f1_score": 0.7999999999999999,
        "balanced_accuracy": 0.5694444444444444,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "9",
        "agreement_percentage": 69.23076923076923,
        "mcc": 0.17766726362967536,
        "accuracy": 0.6923076923076923,
        "precision": 0.7272727272727273,
        "recall": 0.8888888888888888,
        "f1_score": 0.7999999999999999,
        "balanced_accuracy": 0.5694444444444444,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "6",
        "agreement_percentage": 46.15384615384615,
        "mcc": -0.18446619684315546,
        "accuracy": 0.46153846153846156,
        "precision": 0.625,
        "recall": 0.5555555555555556,
        "f1_score": 0.5882352941176471,
        "balanced_accuracy": 0.4027777777777778,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "8",
        "agreement_percentage": 61.53846153846154,
        "mcc": 0.2828894749305018,
        "accuracy": 0.6153846153846154,
        "precision": 0.8333333333333334,
        "recall": 0.5555555555555556,
        "f1_score": 0.6666666666666667,
        "balanced_accuracy": 0.6527777777777778,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "8",
        "agreement_percentage": 61.53846153846154,
        "mcc": 0.15811388300841897,
        "accuracy": 0.6153846153846154,
        "precision": 0.75,
        "recall": 0.6666666666666666,
        "f1_score": 0.7058823529411765,
        "balanced_accuracy": 0.5833333333333333,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}