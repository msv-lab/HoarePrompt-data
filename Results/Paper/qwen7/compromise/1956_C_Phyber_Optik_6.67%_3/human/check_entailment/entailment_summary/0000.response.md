Reasoning:
1. The problem requires maximizing the sum of an \( n \times n \) matrix using up to \( 2n \) operations.
2. The provided code seems to attempt to calculate the sum and generate the required operations, but let's analyze its logic step-by-step.

### Analysis:
- The variable `r` is calculated such that `r = i` when `n * (n + 1) // 2 > i * n`, otherwise `sum += i * n`.
- The sum is then calculated as `sum += n * (n + 1) // 2` for the initial part and `sum += i * n` for the remaining part.
- The output includes the calculated sum and the number of operations (`n + r`).
- For each test case, the code prints a sequence of operations:
  - For the first `n` operations, it sets the entire row to a permutation of numbers from 1 to `n` (Type 1 operation).
  - For the remaining operations, it sets the entire column to a permutation of numbers from 1 to `n` (Type 2 operation).

### Verification:
1. **Sum Calculation**: The logic for calculating the sum seems correct. It correctly identifies the point where the sum changes from `i * n` to `n * (n + 1) // 2`.
2. **Operations**: The operations seem to cover all elements of the matrix, ensuring that each element is set to a value from 1 to `n`. This ensures that the sum is maximized.
3. **Number of Operations**: The total number of operations is `n + r`, which is within the limit of `2n`.

Given the above analysis, the provided code appears to correctly implement the solution according to the problem statement.

Correctness: **True**