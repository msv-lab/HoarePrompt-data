{
    "total_valid_rows": {
        "value": 293,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "132",
        "agreement_percentage": 45.051194539249146,
        "mcc": 0.016529178646673835,
        "accuracy": 0.45051194539249145,
        "precision": 0.6,
        "recall": 0.03680981595092025,
        "f1_score": 0.06936416184971099,
        "balanced_accuracy": 0.5030202925908447,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "129",
        "agreement_percentage": 44.027303754266214,
        "mcc": -0.04282362180587459,
        "accuracy": 0.4402730375426621,
        "precision": 0.47058823529411764,
        "recall": 0.049079754601226995,
        "f1_score": 0.08888888888888889,
        "balanced_accuracy": 0.4899244926852289,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "153",
        "agreement_percentage": 52.218430034129696,
        "mcc": 0.00267743199506593,
        "accuracy": 0.5221843003412969,
        "precision": 0.5572139303482587,
        "recall": 0.6871165644171779,
        "f1_score": 0.6153846153846153,
        "balanced_accuracy": 0.5012505899008967,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "169",
        "agreement_percentage": 57.67918088737202,
        "mcc": 0.12609471301164019,
        "accuracy": 0.5767918088737202,
        "precision": 0.6020942408376964,
        "recall": 0.7055214723926381,
        "f1_score": 0.6497175141242938,
        "balanced_accuracy": 0.5604530438886267,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "153",
        "agreement_percentage": 52.218430034129696,
        "mcc": 0.02907765534937024,
        "accuracy": 0.5221843003412969,
        "precision": 0.5688622754491018,
        "recall": 0.5828220858895705,
        "f1_score": 0.5757575757575758,
        "balanced_accuracy": 0.5144879660217083,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "125",
        "agreement_percentage": 42.66211604095563,
        "mcc": -0.09788290336617275,
        "accuracy": 0.42662116040955633,
        "precision": 0.4528301886792453,
        "recall": 0.147239263803681,
        "f1_score": 0.2222222222222222,
        "balanced_accuracy": 0.462081170363379,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "158",
        "agreement_percentage": 53.92491467576792,
        "mcc": 0.060190047627943964,
        "accuracy": 0.5392491467576792,
        "precision": 0.5813953488372093,
        "recall": 0.6134969325153374,
        "f1_score": 0.5970149253731343,
        "balanced_accuracy": 0.5298253893345918,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "146",
        "agreement_percentage": 49.829351535836174,
        "mcc": 0.007822448382318218,
        "accuracy": 0.49829351535836175,
        "precision": 0.5606060606060606,
        "recall": 0.4539877300613497,
        "f1_score": 0.5016949152542372,
        "balanced_accuracy": 0.5039169419537518,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "148",
        "agreement_percentage": 50.51194539249146,
        "mcc": 0.0122405420093441,
        "accuracy": 0.5051194539249146,
        "precision": 0.5625,
        "recall": 0.49693251533742333,
        "f1_score": 0.5276872964169381,
        "balanced_accuracy": 0.5061585653610193,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "147",
        "agreement_percentage": 50.170648464163826,
        "mcc": 0.006144579520369435,
        "accuracy": 0.5017064846416383,
        "precision": 0.5594405594405595,
        "recall": 0.49079754601226994,
        "f1_score": 0.5228758169934641,
        "balanced_accuracy": 0.5030910806984427,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "134",
        "agreement_percentage": 45.73378839590443,
        "mcc": -0.06366737860205608,
        "accuracy": 0.45733788395904434,
        "precision": 0.5172413793103449,
        "recall": 0.36809815950920244,
        "f1_score": 0.43010752688172044,
        "balanced_accuracy": 0.4686644643699858,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "147",
        "agreement_percentage": 50.170648464163826,
        "mcc": 0.025159211847594915,
        "accuracy": 0.5017064846416383,
        "precision": 0.5714285714285714,
        "recall": 0.4171779141104294,
        "f1_score": 0.4822695035460992,
        "balanced_accuracy": 0.5124351109013685,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "150",
        "agreement_percentage": 51.19453924914675,
        "mcc": 0.050446503322207,
        "accuracy": 0.5119453924914675,
        "precision": 0.5877192982456141,
        "recall": 0.4110429447852761,
        "f1_score": 0.48375451263537905,
        "balanced_accuracy": 0.5247522416234073,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}