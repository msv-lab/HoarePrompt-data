{
    "total_valid_rows": {
        "value": 1806,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "939",
        "agreement_percentage": 51.993355481727576,
        "mcc": 0.09873996517218525,
        "accuracy": 0.5199335548172758,
        "precision": 0.7538461538461538,
        "recall": 0.05444444444444444,
        "f1_score": 0.10155440414507773,
        "balanced_accuracy": 0.518392200147167,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "939",
        "agreement_percentage": 51.993355481727576,
        "mcc": 0.08345328673826019,
        "accuracy": 0.5199335548172758,
        "precision": 0.6774193548387096,
        "recall": 0.07,
        "f1_score": 0.12688821752265864,
        "balanced_accuracy": 0.5184437086092716,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "1026",
        "agreement_percentage": 56.810631229235874,
        "mcc": 0.1418748969363757,
        "accuracy": 0.5681063122923588,
        "precision": 0.5528169014084507,
        "recall": 0.6977777777777778,
        "f1_score": 0.6168958742632613,
        "balanced_accuracy": 0.5685356880058867,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "1042",
        "agreement_percentage": 57.696566998892585,
        "mcc": 0.1594016439169769,
        "accuracy": 0.5769656699889258,
        "precision": 0.5607142857142857,
        "recall": 0.6977777777777778,
        "f1_score": 0.6217821782178218,
        "balanced_accuracy": 0.577365710080942,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "981",
        "agreement_percentage": 54.31893687707641,
        "mcc": 0.08653735949363424,
        "accuracy": 0.5431893687707641,
        "precision": 0.5401929260450161,
        "recall": 0.56,
        "f1_score": 0.5499181669394437,
        "balanced_accuracy": 0.5432450331125829,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "942",
        "agreement_percentage": 52.159468438538205,
        "mcc": 0.05424756707207955,
        "accuracy": 0.521594684385382,
        "precision": 0.5576923076923077,
        "recall": 0.19333333333333333,
        "f1_score": 0.2871287128712871,
        "balanced_accuracy": 0.5205077262693156,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "1000",
        "agreement_percentage": 55.370985603543744,
        "mcc": 0.10762995269392338,
        "accuracy": 0.5537098560354374,
        "precision": 0.5501066098081023,
        "recall": 0.5733333333333334,
        "f1_score": 0.5614798694232862,
        "balanced_accuracy": 0.5537748344370861,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "898",
        "agreement_percentage": 49.72314507198228,
        "mcc": -0.005946034182690837,
        "accuracy": 0.49723145071982283,
        "precision": 0.49501246882793015,
        "recall": 0.4411111111111111,
        "f1_score": 0.46650998824911866,
        "balanced_accuracy": 0.49704562178072115,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "934",
        "agreement_percentage": 51.71650055370986,
        "mcc": 0.03418545538320744,
        "accuracy": 0.5171650055370985,
        "precision": 0.5177664974619289,
        "recall": 0.4533333333333333,
        "f1_score": 0.48341232227488146,
        "balanced_accuracy": 0.5169536423841059,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "933",
        "agreement_percentage": 51.66112956810631,
        "mcc": 0.03308330822136388,
        "accuracy": 0.5166112956810631,
        "precision": 0.5159010600706714,
        "recall": 0.4866666666666667,
        "f1_score": 0.5008576329331046,
        "balanced_accuracy": 0.5165121412803533,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "962",
        "agreement_percentage": 53.266888150609084,
        "mcc": 0.06762017592912035,
        "accuracy": 0.5326688815060908,
        "precision": 0.5448717948717948,
        "recall": 0.37777777777777777,
        "f1_score": 0.44619422572178474,
        "balanced_accuracy": 0.5321559970566593,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "958",
        "agreement_percentage": 53.0454042081949,
        "mcc": 0.06296258486397957,
        "accuracy": 0.530454042081949,
        "precision": 0.5416666666666666,
        "recall": 0.37555555555555553,
        "f1_score": 0.44356955380577423,
        "balanced_accuracy": 0.5299411331861663,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "971",
        "agreement_percentage": 53.76522702104097,
        "mcc": 0.0779730816870639,
        "accuracy": 0.5376522702104097,
        "precision": 0.5516693163751988,
        "recall": 0.38555555555555554,
        "f1_score": 0.4538914323086985,
        "balanced_accuracy": 0.53714863870493,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}