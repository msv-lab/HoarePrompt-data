{
    "total_valid_rows": {
        "value": 59,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "20",
        "agreement_percentage": 33.89830508474576,
        "mcc": 0,
        "accuracy": 0.3389830508474576,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "18",
        "agreement_percentage": 30.508474576271187,
        "mcc": -0.26157418189029846,
        "accuracy": 0.3050847457627119,
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.45,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "32",
        "agreement_percentage": 54.23728813559322,
        "mcc": -0.15894098830143774,
        "accuracy": 0.5423728813559322,
        "precision": 0.625,
        "recall": 0.7692307692307693,
        "f1_score": 0.6896551724137931,
        "balanced_accuracy": 0.4346153846153846,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "36",
        "agreement_percentage": 61.016949152542374,
        "mcc": 0.07526178090063816,
        "accuracy": 0.6101694915254238,
        "precision": 0.6818181818181818,
        "recall": 0.7692307692307693,
        "f1_score": 0.7228915662650602,
        "balanced_accuracy": 0.5346153846153846,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "28",
        "agreement_percentage": 47.45762711864407,
        "mcc": -0.25366007636881754,
        "accuracy": 0.4745762711864407,
        "precision": 0.5909090909090909,
        "recall": 0.6666666666666666,
        "f1_score": 0.6265060240963856,
        "balanced_accuracy": 0.3833333333333333,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "19",
        "agreement_percentage": 32.20338983050847,
        "mcc": -0.29025969549635755,
        "accuracy": 0.3220338983050847,
        "precision": 0.47619047619047616,
        "recall": 0.2564102564102564,
        "f1_score": 0.3333333333333333,
        "balanced_accuracy": 0.35320512820512817,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "31",
        "agreement_percentage": 52.54237288135594,
        "mcc": -0.009883324222148016,
        "accuracy": 0.5254237288135594,
        "precision": 0.6571428571428571,
        "recall": 0.5897435897435898,
        "f1_score": 0.6216216216216216,
        "balanced_accuracy": 0.4948717948717949,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "23",
        "agreement_percentage": 38.983050847457626,
        "mcc": -0.2503571831011286,
        "accuracy": 0.3898305084745763,
        "precision": 0.5483870967741935,
        "recall": 0.4358974358974359,
        "f1_score": 0.4857142857142857,
        "balanced_accuracy": 0.367948717948718,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "29",
        "agreement_percentage": 49.152542372881356,
        "mcc": 0.03438755255523523,
        "accuracy": 0.4915254237288136,
        "precision": 0.68,
        "recall": 0.4358974358974359,
        "f1_score": 0.53125,
        "balanced_accuracy": 0.5179487179487179,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "29",
        "agreement_percentage": 49.152542372881356,
        "mcc": 0.010963225241337865,
        "accuracy": 0.4915254237288136,
        "precision": 0.6666666666666666,
        "recall": 0.46153846153846156,
        "f1_score": 0.5454545454545455,
        "balanced_accuracy": 0.5057692307692307,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "25",
        "agreement_percentage": 42.3728813559322,
        "mcc": -0.06591049854065761,
        "accuracy": 0.423728813559322,
        "precision": 0.6190476190476191,
        "recall": 0.3333333333333333,
        "f1_score": 0.43333333333333335,
        "balanced_accuracy": 0.4666666666666667,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "21",
        "agreement_percentage": 35.59322033898305,
        "mcc": -0.235179430538674,
        "accuracy": 0.3559322033898305,
        "precision": 0.5217391304347826,
        "recall": 0.3076923076923077,
        "f1_score": 0.3870967741935484,
        "balanced_accuracy": 0.37884615384615383,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "23",
        "agreement_percentage": 38.983050847457626,
        "mcc": -0.1617636294710456,
        "accuracy": 0.3898305084745763,
        "precision": 0.5652173913043478,
        "recall": 0.3333333333333333,
        "f1_score": 0.4193548387096774,
        "balanced_accuracy": 0.41666666666666663,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}