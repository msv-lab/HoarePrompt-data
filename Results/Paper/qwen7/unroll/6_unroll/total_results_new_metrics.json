{
    "total_valid_rows": {
        "value": 254,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "129",
        "agreement_percentage": 50.78740157480315,
        "mcc": 0.15256133256989787,
        "accuracy": 0.5078740157480315,
        "precision": 0.9,
        "recall": 0.06766917293233082,
        "f1_score": 0.1258741258741259,
        "balanced_accuracy": 0.5297023550612068,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "118",
        "agreement_percentage": 46.45669291338583,
        "mcc": -0.06815371567162344,
        "accuracy": 0.4645669291338583,
        "precision": 0.36363636363636365,
        "recall": 0.03007518796992481,
        "f1_score": 0.05555555555555555,
        "balanced_accuracy": 0.48611197415025165,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "144",
        "agreement_percentage": 56.69291338582677,
        "mcc": 0.1273648119854486,
        "accuracy": 0.5669291338582677,
        "precision": 0.5761589403973509,
        "recall": 0.6541353383458647,
        "f1_score": 0.6126760563380281,
        "balanced_accuracy": 0.562604859255577,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "167",
        "agreement_percentage": 65.74803149606299,
        "mcc": 0.3149500632194887,
        "accuracy": 0.65748031496063,
        "precision": 0.6796875,
        "recall": 0.6541353383458647,
        "f1_score": 0.6666666666666666,
        "balanced_accuracy": 0.6576461815696266,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "139",
        "agreement_percentage": 54.7244094488189,
        "mcc": 0.09734871649144311,
        "accuracy": 0.547244094488189,
        "precision": 0.575,
        "recall": 0.518796992481203,
        "f1_score": 0.5454545454545455,
        "balanced_accuracy": 0.5486546945877089,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "136",
        "agreement_percentage": 53.54330708661418,
        "mcc": 0.1629761644071609,
        "accuracy": 0.5354330708661418,
        "precision": 0.7419354838709677,
        "recall": 0.17293233082706766,
        "f1_score": 0.2804878048780488,
        "balanced_accuracy": 0.5534083141738644,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "144",
        "agreement_percentage": 56.69291338582677,
        "mcc": 0.14324361192350143,
        "accuracy": 0.5669291338582677,
        "precision": 0.6074766355140186,
        "recall": 0.48872180451127817,
        "f1_score": 0.5416666666666666,
        "balanced_accuracy": 0.5708071832473747,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "136",
        "agreement_percentage": 53.54330708661418,
        "mcc": 0.09174932689574956,
        "accuracy": 0.5354330708661418,
        "precision": 0.5882352941176471,
        "recall": 0.37593984962406013,
        "f1_score": 0.4587155963302752,
        "balanced_accuracy": 0.5433418256384763,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "136",
        "agreement_percentage": 53.54330708661418,
        "mcc": 0.0891829787169934,
        "accuracy": 0.5354330708661418,
        "precision": 0.5842696629213483,
        "recall": 0.39097744360902253,
        "f1_score": 0.46846846846846846,
        "balanced_accuracy": 0.5425961598210403,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "134",
        "agreement_percentage": 52.75590551181102,
        "mcc": 0.06529421874986026,
        "accuracy": 0.5275590551181102,
        "precision": 0.5631067961165048,
        "recall": 0.43609022556390975,
        "f1_score": 0.4915254237288135,
        "balanced_accuracy": 0.5320946995588144,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "135",
        "agreement_percentage": 53.14960629921261,
        "mcc": 0.09111402066144872,
        "accuracy": 0.531496062992126,
        "precision": 0.5945945945945946,
        "recall": 0.3308270676691729,
        "f1_score": 0.4251207729468599,
        "balanced_accuracy": 0.5414465916858262,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "139",
        "agreement_percentage": 54.7244094488189,
        "mcc": 0.11607826127814895,
        "accuracy": 0.547244094488189,
        "precision": 0.6046511627906976,
        "recall": 0.39097744360902253,
        "f1_score": 0.4748858447488584,
        "balanced_accuracy": 0.5549928540359162,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "138",
        "agreement_percentage": 54.330708661417326,
        "mcc": 0.10705632029788839,
        "accuracy": 0.5433070866141733,
        "precision": 0.5977011494252874,
        "recall": 0.39097744360902253,
        "f1_score": 0.4727272727272727,
        "balanced_accuracy": 0.5508606226309576,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}