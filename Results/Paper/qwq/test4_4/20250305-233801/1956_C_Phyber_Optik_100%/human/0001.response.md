Alright, I have this problem to solve. Let's see what it's about. So, there's this magical girl named Nene who has an n by n matrix filled with zeros. She can perform two types of operations on this matrix. The first type allows her to choose a row and set its elements to a permutation of numbers from 1 to n. The second type is similar but for columns. She can do these operations any number of times, but she wants to maximize the sum of all the elements in the matrix, and she wants to do this with no more than 2n operations.

First, I need to understand what these operations do. For type 1 operation, she chooses a row i and a permutation p of 1 to n, and sets a[i][j] to p[j] for all j. Similarly, for type 2 operation, she chooses a column i and a permutation p of 1 to n, and sets a[j][i] to p[j] for all j.

So, each operation allows her to set an entire row or column to a permutation of 1 to n. Since permutations are just rearrangements of these numbers, each operation sets the chosen row or column to some order of these numbers.

The goal is to maximize the sum of all elements in the matrix using at most 2n operations.

I need to think about how to approach this.

First, let's consider what happens when we perform these operations.

Suppose I perform a type 1 operation on row i with permutation p. Then, the elements in row i are set to p[1], p[2], ..., p[n]. Similarly, if I perform a type 2 operation on column j with permutation q, then the elements in column j are set to q[1], q[2], ..., q[n].

Now, if I perform both type 1 and type 2 operations on the same cell, the value in that cell will be overwritten by the last operation performed on its row or column.

So, to maximize the sum, I need to strategically choose which rows and columns to operate on and with which permutations to maximize the overall sum.

Let me think about the maximum possible sum.

If I could set every cell in the matrix to n, the maximum value in the permutation, the sum would be n * n * n = n^3. However, since each operation sets an entire row or column, and permutations must be used, I need to see how to arrange these operations to maximize the sum.

But there's a constraint: I can't perform more than 2n operations.

So, I need to find a way to maximize the sum with at most 2n operations.

Let me consider small values of n to see a pattern.

Let's take n=1.

Matrix is 1x1. She can perform either type 1 or type 2 operation, both of which set the single element to 1. So, the sum is 1. That's straightforward.

For n=2.

Matrix is 2x2. She can perform up to 4 operations.

Let's see.

If she performs two type 1 operations, setting both rows to permutations of [1,2], say [1,2] and [2,1], then the matrix would be:

1 2

2 1

Sum is 6.

Alternatively, if she performs two type 2 operations, setting both columns to permutations of [1,2], say [1,2] and [2,1], then the matrix would be:

1 2

2 1

Again, sum is 6.

If she performs one type 1 and one type 2:

Set row 1 to [1,2], then set column 1 to [2,1].

Matrix becomes:

2 2

1 0

Wait, but in the second operation, setting column 1 to [2,1], it overwrites the first element of row 1 to 2.

So, matrix is:

2 2

1 0

But wait, in type 2 operation, setting column 1 to [2,1], it sets a[1][1] to 2 and a[2][1] to 1, and leaves a[1][2] and a[2][2] as they are, which were set by the first operation to [1,2], so a[1][2]=2 and a[2][2]=0? Wait, but initially, the matrix is zero, and operations set entire rows or columns.

Wait, I need to clarify: when an operation is performed, it sets the entire row or column to the permutation specified.

So, in the first operation, setting row 1 to [1,2], matrix becomes:

1 2

0 0

Then, setting column 1 to [2,1], it sets a[1][1]=2 and a[2][1]=1, so matrix becomes:

2 2

1 0

Sum is 5.

Which is less than the previous 6.

So, seems like performing operations on rows or columns separately can give different sums.

In the example provided in the problem for n=2, they achieved a sum of 7 with 3 operations.

Wait, in the example output:

7 3

1 1 1 2

1 2 1 2

2 1 1 2

So, first operation: type 1 on row 1 with permutation [1,2]

Second operation: type 1 on row 2 with permutation [1,2]

Third operation: type 2 on column 1 with permutation [1,2]

Let's see what the matrix looks like after each operation.

Initial matrix:

0 0

0 0

First operation: set row 1 to [1,2]

1 2

0 0

Second operation: set row 2 to [1,2]

1 2

1 2

Third operation: set column 1 to [1,2]

So, a[1][1]=1, a[2][1]=2

So, matrix becomes:

1 2

2 2

Sum is 1+2+2+2=7.

Okay, that makes sense.

So, by performing operations in this order, they achieved a higher sum than just performing operations on rows or columns alone.

This suggests that combining operations on rows and columns can lead to higher sums.

I need to find a general strategy for any n.

Let me think about what's the maximum possible sum achievable with at most 2n operations.

I need to maximize the sum of a[i][j] for all i,j.

Each operation sets an entire row or column to a permutation of 1 to n.

Since permutations contain each number from 1 to n exactly once, I need to think about how to arrange these operations to maximize the values in the matrix cells.

One idea is to try to set as many high values as possible in the matrix, preferably as many n's as possible.

But I need to consider that operations can overwrite each other.

Let me consider the following approach:

- Perform type 1 operations on all rows, setting them to some permutations.

- Then, perform type 2 operations on some columns to try to set higher values in those columns.

But I need to make sure that I don't overwrite important values set by previous operations.

Wait, perhaps I should prioritize setting higher values in positions that will not be overwritten by later operations.

Alternatively, maybe there's a mathematical formula to calculate the maximum sum without explicitly constructing the operations.

Let me think about the sum.

Suppose I perform k type 1 operations and m type 2 operations, with k + m <= 2n.

I need to choose which rows and columns to operate on and with which permutations.

I need to maximize the sum of the matrix after these operations.

Is there a way to calculate this sum directly?

Let me consider that each operation on a row or column sets that row or column to a permutation of 1 to n, meaning that the sum of that row or column will be the sum of numbers from 1 to n, which is n(n+1)/2.

But in the matrix, cells can be set multiple times if their row and column are both operated on.

So, perhaps I need to consider which cells are set by both row and column operations.

Wait, perhaps inclusion-exclusion can be applied here.

Let me think differently.

Suppose I perform operations on all rows, setting each row to a permutation of 1 to n.

Then, the sum of the matrix would be the sum of the sums of each row, which is n times the sum of 1 to n, which is n * n(n+1)/2 = n^2(n+1)/2.

Similarly, if I perform operations on all columns, setting each column to a permutation of 1 to n, the sum would be the sum of the sums of each column, which is also n times the sum of 1 to n, same as above.

But if I perform operations on both rows and columns, some cells will be set twice, so their values will be overwritten by the last operation.

So, the sum would be the sum of all cells set by row operations plus the sum of all cells set by column operations minus the sum of cells set by both row and column operations (since they are counted twice).

Wait, that sounds like inclusion-exclusion.

Let me formalize this.

Let S_r be the sum of all cells set by row operations.

Let S_c be the sum of all cells set by column operations.

Let S_b be the sum of all cells set by both row and column operations.

Then, the total sum S = S_r + S_c - S_b.

Because cells set by both operations are counted in both S_r and S_c, so we need to subtract S_b to avoid double-counting.

Now, I need to maximize S.

Given that, I need to choose which rows and columns to operate on and with which permutations to maximize S.

But this seems complicated.

Maybe there's a better way.

Let me consider that each cell can be set by either its row operation or its column operation, whichever comes last.

So, for each cell, its value will be the one set by the last operation that affects it, whether it's its row or its column.

Therefore, to maximize the sum, I should aim to set as many high values as possible in the cells, preferring to set higher values in cells that are less likely to be overwritten.

But this is still vague.

Let me think about it differently.

Suppose I perform type 1 operations on all rows, setting each row to a permutation where the highest numbers are placed in columns that are not operated on by type 2 operations.

Then, perform type 2 operations on some columns to set higher values in those columns.

Wait, but I need to make sure that the operations are coordinated so that the highest possible values are set in the matrix cells.

This is getting too vague.

Maybe I should look for a pattern or formula that directly gives the maximum sum based on n.

Looking back at the example for n=2, the maximum sum is 7.

Let's see for n=1, sum=1.

For n=2, sum=7.

For n=3?

Let's try to compute it.

If I perform operations on all 3 rows and all 3 columns, that's 6 operations, which is within 2n=6.

Let's see what sum I can achieve.

Suppose I set rows 1,2,3 to permutations [3,2,1], [3,2,1], [3,2,1], and columns 1,2,3 to [3,2,1], [3,2,1], [3,2,1].

But I need to see how the matrix looks.

First, set row 1 to [3,2,1], matrix:

3 2 1

0 0 0

0 0 0

Then, set row 2 to [3,2,1], matrix:

3 2 1

3 2 1

0 0 0

Then, set row 3 to [3,2,1], matrix:

3 2 1

3 2 1

3 2 1

Then, set column 1 to [3,2,1], matrix:

3 2 1

2 2 1

1 2 1

Then, set column 2 to [3,2,1], matrix:

3 3 1

2 2 1

1 2 1

Then, set column 3 to [3,2,1], matrix:

3 3 3

2 2 2

1 2 1

Sum is 3+3+3 + 2+2+2 + 1+2+1 = 18.

Is this the maximum?

Is there a way to get a higher sum?

If I perform operations differently, can I get a higher sum?

Let's try another approach.

Suppose I perform operations only on rows.

Set row 1 to [3,2,1], row 2 to [3,2,1], row 3 to [3,2,1], total sum is 3+2+1 + 3+2+1 + 3+2+1 = 3*6 = 18.

Same as above.

Alternatively, perform operations only on columns.

Set column 1 to [3,2,1], column 2 to [3,2,1], column 3 to [3,2,1], matrix becomes:

3 3 3

2 2 2

1 1 1

Sum is 3+3+3 + 2+2+2 + 1+1+1 = 18.

Same sum.

Now, let's try a mix of row and column operations.

Suppose perform operations on rows 1 and 2, and columns 1 and 3.

So, total operations: 4, which is within 2n=6.

First, set row 1 to [3,2,1], matrix:

3 2 1

0 0 0

0 0 0

Then, set row 2 to [3,2,1], matrix:

3 2 1

3 2 1

0 0 0

Then, set column 1 to [3,2,1], matrix:

3 2 1

2 2 1

1 0 0

Then, set column 3 to [3,2,1], matrix:

3 2 3

2 2 2

1 0 1

Sum is 3+2+3 + 2+2+2 + 1+0+1 = 14.

Which is less than 18.

So, seems like performing operations on both rows and columns doesn't necessarily increase the sum beyond what can be achieved by operating on all rows or all columns.

Wait, but in n=2 example, they achieved 7, which is higher than operating on all rows or all columns separately.

Wait, in n=2, operating on all rows gives sum 6, operating on all columns gives sum 6, but combining row and column operations allows sum 7.

Similarly, in n=3, operating on all rows gives sum 18, operating on all columns gives sum 18, and combining row and column operations seems to give at most 18.

Wait, is there a way to get a higher sum in n=3 by combining row and column operations?

Let's try a different combination.

Perform operations on rows 1 and 3, and columns 1 and 2.

Total operations: 4, within 2n=6.

First, set row 1 to [3,2,1], matrix:

3 2 1

0 0 0

0 0 0

Then, set row 3 to [3,2,1], matrix:

3 2 1

0 0 0

3 2 1

Then, set column 1 to [3,2,1], matrix:

3 2 1

2 0 0

1 2 1

Then, set column 2 to [3,2,1], matrix:

3 3 1

2 2 0

1 1 1

Sum is 3+3+1 + 2+2+0 + 1+1+1 = 14.

Again, less than 18.

Is there a better combination?

Let's try performing operations on rows 1 and 2, and columns 3.

Total operations: 3.

First, set row 1 to [3,2,1], matrix:

3 2 1

0 0 0

0 0 0

Then, set row 2 to [3,2,1], matrix:

3 2 1

3 2 1

0 0 0

Then, set column 3 to [3,2,1], matrix:

3 2 3

3 2 2

0 0 1

Sum is 3+2+3 + 3+2+2 + 0+0+1 = 16.

Still less than 18.

Seems like operating on all rows or all columns gives the highest sum.

Wait, but in n=2 example, they achieved 7 with 3 operations, which is higher than operating on all rows (sum 6).

So, perhaps for n=2, combining row and column operations can give a higher sum.

But for n=3, is there a way to get higher than 18?

Let's see.

If I perform operations on all rows and one column.

Total operations: 4, within 2n=6.

Set row 1 to [3,2,1], matrix:

3 2 1

0 0 0

0 0 0

Set row 2 to [3,2,1], matrix:

3 2 1

3 2 1

0 0 0

Set row 3 to [3,2,1], matrix:

3 2 1

3 2 1

3 2 1

Set column 1 to [3,2,1], matrix:

3 2 1

2 2 1

1 2 1

Sum is 3+2+1 + 2+2+1 + 1+2+1 = 13.

Less than 18.

Alternatively, set row 1 to [3,2,1], matrix:

3 2 1

0 0 0

0 0 0

Set row 2 to [3,2,1], matrix:

3 2 1

3 2 1

0 0 0

Set row 3 to [3,2,1], matrix:

3 2 1

3 2 1

3 2 1

Set column 3 to [3,2,1], matrix:

3 2 3

3 2 2

3 2 1

Sum is 3+2+3 + 3+2+2 + 3+2+1 = 21.

Wait, that's higher than 18.

Is this possible?

Wait, but operating on all rows already sets column 3 to [1,1,1], and then operating on column 3 sets it to [3,2,1].

So, the final column 3 is [3,2,1], overwriting the previous values.

So, sum is 3+2+3 + 3+2+2 + 3+2+1 = 21.

But earlier, when operating only on all rows, sum was 18.

So, by performing one additional operation on column 3, I increased the sum from 18 to 21.

Is this better?

Wait, but in n=2 example, they achieved sum=7 with 3 operations, which is higher than operating on all rows (sum=6).

Similarly, in n=3, operating on all rows and one column gives sum=21, which is higher than operating on all rows (sum=18).

Is there a pattern here?

Let me see.

For n=1, sum=1.

For n=2, sum=7.

For n=3, sum=21.

Let me see if there's a formula.

For n=1, 1.

For n=2, 7.

For n=3, 21.

Wait, 1, 7, 21.

Is there a pattern?

1 = 1^3.

7 = 2^3 - 1.

21 = 3^3 - 6.

Wait, 1, 7, 21.

Alternatively, 1, 7, 21 could be thought of as 1^3 + 2^3 - 0, but that doesn't seem consistent.

Wait, perhaps it's the sum of the first n odd numbers.

1, 1+6=7, 7+14=21.

Wait, no.

Alternatively, perhaps it's the sum of squares: 1^2 + 2^2 = 5, but that's not 7.

Wait, maybe it's something else.

Let me think differently.

In n=2, sum=7.

In n=3, sum=21.

Wait, 21 is 3*(2^2) + 3^2 = 12 + 9 = 21.

Wait, perhaps it's n*(n-1)^2 + n^2.

For n=2: 2*1^2 + 2^2 = 2 + 4 = 6, but in the example, it's 7.

Wait, that doesn't match.

Alternatively, perhaps it's n^3 - something.

Wait, maybe I need to find a general formula.

Let me consider that in n=2, sum=7.

Which is 2^3 + 3.

For n=3, sum=21.

Which is 3^3 + 12.

Not sure.

Alternatively, perhaps it's the sum of the first n cubes minus something.

Wait, perhaps I need to think in terms of inclusion-exclusion.

Let me consider that each row operation sets a row to sum n(n+1)/2.

Similarly, each column operation sets a column to sum n(n+1)/2.

But when both row and column operations are performed on a cell, the value is overwritten.

So, the total sum is the sum of the row operations plus the sum of the column operations minus the sum of the cells where both operations were performed.

Wait, perhaps I can model this mathematically.

Let me denote:

Let R be the set of rows operated on.

Let C be the set of columns operated on.

Let S_r = sum of sums of rows in R.

Let S_c = sum of sums of columns in C.

Let S_b = sum of values in cells where both row and column were operated on.

Then, total sum S = S_r + S_c - S_b.

I need to maximize S.

But this seems too vague.

Let me think about the maximum possible sum.

Each cell can be set to at most n, but only if it's set by the last operation that affects it.

So, to maximize the sum, I need as many cells as possible to be set to n.

But, since operations set permutations, each row or column can have only one n.

Wait, no, permutations of 1 to n include each number exactly once.

Wait, but in a permutation of 1 to n, the highest value is n, and it can be placed in any position.

So, if I set a row to a permutation with n in a certain column, and if that column is not operated on, then that cell will have n.

But if that column is also operated on, then the value in that cell will be overwritten by the column operation.

So, perhaps I need to choose which rows and columns to operate on such that the overlap is minimized.

Wait, but in the n=2 example, they achieved sum=7 by operating on rows 1 and 2, and column 1.

In this case, cell (1,1) is set by both row 1 and column 1, so its value is the one set by the last operation.

Assuming operations are performed in the order given: first set row 1 to [1,2], then row 2 to [1,2], then column 1 to [1,2].

So, cell (1,1) is first set to 1 by row 1, then set to 1 by column 1.

So, it's 1.

Cell (2,1) is set to 1 by column 1.

Cell (1,2) is set to 2 by row 1.

Cell (2,2) is set to 2 by row 2.

So, matrix is:

1 2

1 2

Sum is 1+2+1+2=6.

But in the example output, they have sum=7.

Wait, perhaps I miscalculated.

Wait, in the example output, operations are:

1 1 1 2 (type 1 on row 1 with permutation [1,2])

1 2 1 2 (type 1 on row 2 with permutation [1,2])

2 1 1 2 (type 2 on column 1 with permutation [1,2])

So, initial matrix:

0 0

0 0

After first operation (row 1 to [1,2]):

1 2

0 0

After second operation (row 2 to [1,2]):

1 2

1 