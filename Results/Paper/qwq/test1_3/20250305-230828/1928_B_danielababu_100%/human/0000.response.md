Alright, I've got this problem to solve. Let's see what it's asking for. So, Vasya has an array `a` and he wants to add a permutation `p` to it, where `p` is a permutation of numbers from 1 to n. After adding the permutation to the array, he wants to find out the maximum number of elements that become equal to the same number.

First, I need to understand what a permutation is. A permutation of length n is just a rearrangement of the numbers from 1 to n. For example, for n=3, possible permutations are [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], and [3,2,1].

So, for a given array `a`, I need to choose one such permutation `p` and add it to `a` element-wise. That is, for each index i, I do a_i := a_i + p_i. After this operation, I need to count how many times the most frequent number appears in the new array.

My task is to find the maximum possible frequency of any number after performing this operation.

Let me look at the example to get a better understanding.

In the first test case:

n = 2

a = [1, 2]

One possible permutation is p = [2, 1]. After adding, a becomes [3, 3], and the maximum frequency is 2.

In the second test case:

n = 4

a = [7, 1, 4, 1]

One possible permutation is p = [2, 3, 1, 4], resulting in a = [9, 4, 5, 5], and the maximum frequency is 2.

From these examples, it seems like the goal is to make as many elements as possible equal by adding a permutation.

I need to find a way to maximize the frequency of the most common element after this addition.

Let me think about the properties here.

Since p is a permutation of [1, 2, ..., n], each p_i is unique and lies between 1 and n.

So, for each a_i, after adding p_i, it becomes a_i + p_i.

I need to choose which p_i to add to which a_i to maximize the frequency of some target value.

But choosing a particular p_i for a_i affects the possible p_j for other a_j.

This seems tricky because permutations have to be unique.

Maybe I can think in terms of differences.

Suppose I want to make a_i + p_i equal to some target value t for as many i as possible.

Then, for each a_i, the required p_i would be t - a_i.

But p_i has to be a unique integer between 1 and n.

So, for each t, I can see how many a_i's can have p_i = t - a_i, with p_i being unique and in [1, n].

This sounds like trying to find how many a_i's can be mapped to unique p_i's such that p_i = t - a_i.

In other words, for each t, find the number of a_i's where t - a_i is between 1 and n, and all t - a_i are distinct.

This seems complicated, especially since t can be any integer, given that a_i can be up to 1e9.

I need a better approach.

Let me consider the relative ordering.

Suppose I sort the array a.

Then, if I sort the permutation p, the smallest a_i will be added to the smallest p_i, and so on.

But I'm not sure if that helps directly.

Wait a minute.

Since p is a permutation of [1, 2, ..., n], the sorted p is just [1, 2, ..., n].

So, if I sort a, and add p in sorted order, I get a new sorted array a' = a sorted plus p sorted.

But I'm not sure if that helps.

Alternatively, maybe I should look at the differences between the elements.

Let me consider that.

Suppose I sort a in ascending order.

Let's say a_sorted = [a1, a2, ..., an], where a1 <= a2 <= ... <= an.

Now, p_sorted = [1, 2, ..., n].

Then, a_i + p_i = a_i + i.

Wait, but p doesn't have to be in sorted order.

I'm getting confused.

Let me try to think differently.

Each p_i is unique and forms a permutation of [1, 2, ..., n].

So, the set of p_i's is exactly {1, 2, ..., n}, with each appearing exactly once.

I need to assign each p_i to an a_i such that a_i + p_i equals some target t, for as many i as possible.

But t can be different for different i's, and I need to maximize the frequency of the most frequent t.

This seems like a tricky optimization problem.

Maybe I can think in terms of frequency counts.

But with a_i up to 1e9, I can't really iterate over all possible t.

I need a smarter way.

Let me consider the problem in another way.

Suppose I fix a target t.

Then, for each a_i, I need p_i = t - a_i.

But p_i has to be a unique integer between 1 and n.

So, for the chosen i's, t - a_i must be distinct and within [1, n].

This sounds like I need to select a subset of a's such that t - a_i are all distinct and within [1, n].

Since p is a permutation of [1, n], the p_i's are exactly the numbers from 1 to n, each appearing exactly once.

Therefore, for the selected subset, the t - a_i must be a subset of [1, n], with no duplicates.

This seems too vague.

I need a better approach.

Let me consider the difference between a_i and p_i.

Wait, p_i is between 1 and n.

So, a_i + p_i can range from a_i + 1 to a_i + n.

Given that a_i can be up to 1e9, the range is huge.

I need to find a way to maximize the frequency of some t in a_i + p_i.

Let me think about the possible values of a_i + p_i.

Each a_i + p_i can be thought of as a_i + some unique p_i from 1 to n.

I need to assign p_i's to a_i's such that as many a_i + p_i are equal to some t.

But since p_i's are unique, and assigned to a_i's, it's like matching a_i's to p_i's such that a_i + p_i = t.

Wait, this sounds like matching in bipartite graphs, but that might be too slow.

I need a better way.

Let me consider the frequency of a_i + p_i = t.

Suppose I fix t.

Then, for each a_i, p_i must be t - a_i.

But p_i must be unique and in [1, n].

So, for the a_i's where t - a_i is in [1, n], and all t - a_i are distinct, I can assign those p_i's.

So, for each t, I can count how many a_i's satisfy t - a_i in [1, n], and all t - a_i are distinct.

I need to maximize this count over all possible t.

But iterating over all possible t up to 1e9 is not feasible.

I need a smarter way.

Let me think about the possible values of t.

Since a_i can be up to 1e9 and p_i up to n (up to 2e5), t can be up to about 1e9.

But iterating over all possible t is not practical.

I need to find a way to compute the maximum frequency without iterating over all possible t.

Let me consider the following approach.

Instead of fixing t, maybe I can look for overlaps in possible t's.

Wait, perhaps I can look at the possible t's for each a_i and see where they overlap.

For each a_i, t can be a_i + 1, a_i + 2, ..., a_i + n.

But with a_i up to 1e9, this seems too broad.

I need a different perspective.

Let me consider that p_i are unique and form a permutation.

So, I can think of p as a rearrangement of [1, 2, ..., n].

Therefore, the sum a_i + p_i is a_i plus some unique number from 1 to n.

I need to maximize the frequency of some t in the sum.

An alternative approach: think about the frequency of a_i + p_i for all possible p.

But with p being a permutation, it's difficult to iterate over all possible p, as there are n! permutations, which is too much.

I need a better way.

Let me consider the following idea.

Sort the array a.

Then, assign p_i's in a way that minimizes the differences or maximizes the overlaps.

But I'm not sure.

Wait, perhaps I can look at the differences between a_i's and see how they relate.

Let me try to think differently.

Suppose I sort the array a.

Let's say a_sorted = [a1, a2, ..., an], where a1 <= a2 <= ... <= an.

Now, I need to assign p_i's to a_i's such that a_i + p_i is as close as possible for as many i's as possible.

But p_i's are unique and range from 1 to n.

Maybe I can assign the smallest p_i to the smallest a_i to make their sum as small as possible, and so on.

But I'm not sure if that helps in maximizing the frequency of some t.

Alternatively, maybe I should assign p_i's in a way that balances the sums.

Wait, perhaps I can look for the mode in the sorted a plus sorted p.

Let me try with the first test case.

n=2

a=[1,2]

sorted a=[1,2]

sorted p=[1,2]

sums=[2,4]

But in the example, they chose p=[2,1], sums=[3,3], which is better.

So, sorting a and p in the same order gives [2,4], which has frequency 1, but assigning p in a different order gives [3,3], frequency 2.

So, sorting a and p in the same order doesn't always give the maximum frequency.

Wait, in this case, it does because p=[2,1] is a permutation.

But in general, I need to find the best p to maximize the frequency.

This seems tricky.

Let me consider another approach.

Suppose I sort the array a.

Then, I try to assign p_i's such that as many a_i + p_i as possible are equal to some t.

Let me fix t.

Then, for each a_i, p_i must be t - a_i.

But p_i must be unique and in [1,n].

So, for the a_i's where t - a_i is in [1,n], and all t - a_i are distinct, I can assign those p_i's.

So, for each t, I can count how many a_i's satisfy t - a_i in [1,n], and all t - a_i are distinct.

I need to maximize this count over all t.

But iterating over all possible t up to 1e9 is not feasible.

I need a smarter way.

Wait, maybe I can look at the differences.

Let me sort a.

Let's say a_sorted = [a1, a2, ..., an].

Now, for each a_i, p_i = t - a_i.

But p_i must be unique and in [1,n].

So, for a given t, the p_i's would be t - a_i, and they must all be distinct and in [1,n].

So, for a given t, the set of p_i's would be {t - a1, t - a2, ..., t - an}, and they must be a permutation of [1,n].

But I need to select a subset of a_i's where t - a_i are distinct and in [1,n].

I need to maximize the size of this subset over all t.

This seems similar to finding how many a_i's can be expressed as t - p_i, where p_i is unique and in [1,n].

But again, iterating over all t is not practical.

I need a better way.

Let me consider that p_i's are exactly [1,2,...,n], just in some order.

So, the set of p_i's is fixed.

I need to assign each p_i to an a_i such that a_i + p_i = t for as many i's as possible.

But t can be different for different i's, but I want as many as possible to have the same t.

Wait, maybe I can look at the frequency of a_i + p_i for all possible p.

But with p being a permutation, it's still too slow.

I need a different approach.

Let me think about the problem differently.

Suppose I fix p, then a_i + p_i are some values.

I need to choose p such that the maximum frequency of any value in a_i + p_i is maximized.

This seems difficult.

Let me consider the following idea.

Suppose I sort a in ascending order and p in descending order, then a_i + p_i might be more balanced.

But I'm not sure.

Wait, maybe I can look at the differences between a_i and a_j and see how they relate.

This seems too vague.

Let me look for a pattern or a mathematical property that can help.

Let me consider that p is a permutation of [1,2,...,n], so the sum of p_i's is n*(n+1)/2.

But I'm not sure if that helps directly.

Wait, maybe I can look at the sum a_i + p_i and see if there's a way to make them as equal as possible.

But due to the variability in a_i's, it might not be possible.

Let me consider the minimal and maximal possible sums.

The minimal sum for a_i + p_i is a_i + 1.

The maximal sum is a_i + n.

So, for each a_i, the possible sums range from a_i + 1 to a_i + n.

Now, across all a_i's, the possible sums range from min_a a_i + 1 to max_a a_i + n.

Within this range, I need to find a value t that can be achieved by as many a_i's as possible, with each t - a_i being unique and in [1,n].

This seems similar to finding how many a_i's can be mapped to t with unique p_i's.

But again, iterating over all possible t is not feasible.

I need a smarter way.

Let me consider that the p_i's are unique and form a set {1,2,...,n}.

So, for a given t, the p_i's corresponding to t - a_i must be a subset of {1,2,...,n} with no duplicates.

Therefore, for a given t, the number of a_i's for which t - a_i is in [1,n] and all t - a_i are distinct is the frequency I can achieve for t.

I need to maximize this frequency over all t.

But how to do this efficiently?

Let me consider that t - a_i must be in [1,n], which implies that t is in [a_i + 1, a_i + n].

So, for each a_i, t can be in [a_i + 1, a_i + n].

Now, I need to find a t that is in the intersection of these ranges for as many a_i's as possible.

Wait, but t can be in the range of each a_i independently.

I need to find a t that is in as many ranges [a_i + 1, a_i + n] as possible.

This sounds like finding the maximum overlap among these intervals.

Each a_i defines an interval [a_i + 1, a_i + n].

I need to find the t that is in the maximum number of these intervals.

This is a classic interval overlap problem.

To solve this, I can collect all the intervals and find the point t where the maximum number of intervals overlap.

Given that n can be up to 2e5 and a_i up to 1e9, I need an efficient way to compute this.

To handle large values efficiently, I can use a sweep line algorithm.

Here's how it works:

- For each interval [a_i + 1, a_i + n], I record two events: start at a_i + 1 and end at a_i + n + 1.

- I sort all these events and process them in order, keeping track of the current number of active intervals.

- The maximum number of active intervals at any point is the maximum frequency I can achieve.

Wait, but in this problem, since a_i can be up to 1e9, sorting all events directly would be inefficient because of the large range.

To handle this efficiently, I can use coordinate compression.

Coordinate compression maps the unique interval endpoints to a smaller, compressed index space, allowing me to process the events efficiently.

Here's how I can implement it:

1. Collect all the unique interval start and end points.

2. Sort these points and assign each a compressed index.

3. Use a sweep line to count the number of active intervals at each compressed index and find the maximum.

But with n up to 2e5, and t up to 2e4 test cases, this might be too slow overall, since 2e4 * 2e5 = 4e9 operations, which is too much.

Wait, but the problem states that the sum of n over all test cases does not exceed 2e5, so overall complexity can be O(sum_n log sum_n), which should be acceptable.

Let me outline the steps:

- For each test case:

- Read n and the array a.

- For each a_i, define the interval [a_i + 1, a_i + n].

- Collect all start points a_i + 1 and end points a_i + n + 1.

- Compress these points into a smaller index space.

- Use a sweep line algorithm to find the maximum number of overlapping intervals.

This should work.

But perhaps there's a simpler way.

Let me think again.

Since p_i are exactly [1,2,...,n], and I need to assign p_i to a_i to maximize the frequency of a_i + p_i = t.

This is equivalent to finding how many a_i + p_i can be equal to the same t.

Given that p_i are unique, this is like matching a_i's to p_i's such that a_i + p_i = t.

For each a_i, p_i = t - a_i, and p_i must be unique and in [1,n].

So, for a given t, the number of a_i's where t - a_i is in [1,n], and all t - a_i are distinct.

To maximize this over t, I need to find t where as many a_i's can have unique p_i's such that a_i + p_i = t.

This seems to be the same as finding t where the number of a_i's with t - a_i in [1,n], and all t - a_i are distinct.

This is equivalent to finding t where t - a_i is unique for each a_i, and t - a_i is in [1,n].

This sounds similar to finding t where t - a_i are distinct and within [1,n].

But I need to maximize the number of such a_i's.

This seems to be the same as finding the largest subset of a_i's where t - a_i are distinct and in [1,n].

Since p_i's are exactly [1,2,...,n], this is equivalent to assigning p_i's to a_i's such that a_i + p_i = t for as many a_i's as possible.

This is tricky.

Let me consider that t - a_i must be unique for each a_i in the subset.

So, for the selected subset of a_i's, t - a_i are distinct and in [1,n].

This means that for a given t, the t - a_i's must form a subset of [1,n] with no duplicates.

So, for each t, I can select a subset of a_i's where t - a_i are distinct and in [1,n].

I need to maximize the size of this subset over all t.

But iterating over all possible t is not feasible due to the large range.

Hence, I need a smarter way to compute this.

Let me consider that t - a_i must be in [1,n], so t is in [a_i + 1, a_i + n].

So, for each a_i, t can be in [a_i + 1, a_i + n].

I need to find t that is in the intersection of as many of these intervals as possible.

This is exactly the interval overlap problem I thought earlier.

So, I can proceed with the sweep line algorithm combined with coordinate compression to handle the large range efficiently.

Let me outline the steps in code:

- Read the number of test cases t.

- For each test case:

- Read n.

- Read the array a of size n.

- For each a_i, define the interval [a_i + 1, a_i + n].

- Collect all start points a_i + 1 and end points a_i + n + 1.

- Combine all these points into a list and sort them.

- Assign a unique index to each distinct point.

- Then, use a sweep line to count the maximum number of overlapping intervals.

This should give me the maximum frequency of t that can be achieved.

Let me consider an example to verify.

Take the first test case:

n=2

a=[1,2]

Intervals:

For a1=1: [2,3]

For a2=2: [3,4]

So, t=2 is in [2,3] from a1, but not in [3,4] from a2.

t=3 is in both [2,3] and [3,4].

So, maximum overlap is 2.

Which matches the example.

Another test case:

n=3

a=[103,102,104]

Intervals:

a1=103: [104,106]

a2=102: [103,105]

a3=104: [105,107]

Possible t:

t=104: in [104,106] and [103,105] -> two intervals

t=105: in [104,106], [103,105], [105,107] -> three intervals

So, maximum overlap is 3.

But in the output, it's 3 for this test case.

Yes, that matches.

So, the sweep line algorithm seems correct.

Now, to implement this efficiently, I need to handle the large range of a_i's.

Using coordinate compression, I can map the unique interval endpoints to a smaller range, say from 1 to m, where m is the number of unique endpoints.

Then, I can use a sweep line to count the maximum number of overlapping intervals.

Let me think about how to implement this.

First, collect all start and end points:

starts = [a_i + 1 for all i]

ends = [a_i + n + 1 for all i]

Then, combine starts and ends into a list of events.

Sort the events.

Assign a unique index to each distinct event.

Then, iterate through the sorted events, keeping a counter of active intervals.

Whenever I reach a start event, I increment the counter.

Whenever I reach an end event, I decrement the counter.

Keep track of the maximum counter value.

This will be the maximum frequency.

Let me consider the time complexity.

Collecting events: O(n)

Sorting events: O(n log n)

Processing events: O(n)

So, overall O(n log n), which is acceptable since sum of n over all test cases is up to 2e5.

Now, let's consider implementing coordinate compression.

To compress the coordinates, I can collect all unique start and end points, sort them, and assign indices.

But in the sweep line, I need to process the events in order.

So, I can combine all start and end points, sort them, and then process them in order, keeping a count of active intervals.

I need to map the original t to the compressed index, but since I only care about the maximum frequency, I don't need to keep track of t itself, just the maximum count.

Hence, coordinate compression is sufficient.

Let me try to implement this logic in code.

But first, let's look at the provided program and see if it matches this logic.

Looking at the provided program:

from bisect import bisect_left

for _ in range(func_1()):

n = func_1()

arr = sorted(list(set(func_3())))

m = max(arr)

ans = 0

for i in range(len(arr)):

a = bisect_left(arr, arr[i] + n)

d = a - i

ans = max(ans, d)

print(ans)

def func_1():

return int(input())

def func_2():

return map(int, input().split())

def func_3():

return list(map(int, input().split()))

def func_4():

return sorted(list(map(int, input().split())))

def func_5():

return map(str, input().split())

def func_6():

return list(input())

def func_7():

return sorted(list(map(str, input().split())))

def func_8(arr):

ans = []

tem = 1

for i in range(len(arr)):

tem *= arr[i]

ans.append(tem)

return ans

def func_9(arr):

ans = []

tem = 1

for i in range(len(arr)-1, -1, -1):

tem *= arr[i]

ans.append(tem)

return ans

So, the main logic is:

- Read t, the number of test cases.

- For each test case:

- Read n.

- Read the array a.

- Sort the unique elements of a.

- For each unique a_i, find the number of unique a_j's such that a_j is in [a_i, a_i + n), and take the maximum over all a_i.

Wait, let's see:

arr = sorted(list(set(func_3())))

So, arr is the sorted unique elements of a.

Then, for each i in range(len(arr)):

a = bisect_left(arr, arr[i] + n)

d = a - i

ans = max(ans, d)

So, bisect_left(arr, arr[i] + n) gives the index a where arr[a] >= arr[i] + n.

Then, d = a - i is the number of elements arr[j] in [arr[i], arr[i] + n).

So, for each i, it's counting how many unique a_j's are in [arr[i], arr[i] + n).

Then, taking the maximum over all i.

Is this equivalent to the sweep line approach I described earlier?

Wait, in the sweep line approach, I was considering intervals [a_i + 1, a_i + n] for each a_i, and finding the maximum overlap of these intervals.

But in this code, for each a_i, it's looking at the number of unique a_j's in [a_i, a_i + n).

Wait, this seems similar but not exactly the same.

In the sweep line approach, I was considering t in [a_i + 1, a_i + n], which is the same as t in [a_i + 1, a_i + n].

In this code, it's considering a_j in [a_i, a_i + n), which is a_j >= a_i and a_j < a_i + n.

But since a_j's are unique, this counts the number of a_j's in that range.

Wait, but in the sweep line approach, I was looking for the maximum number of intervals that contain a particular t.

In this code, it seems to be counting, for each a_i, how many a_j's are in [a_i, a_i + n), and taking the maximum over i.

But I'm not sure if this directly corresponds to the maximum frequency of t.

Let me consider an example.

Take the first test case:

n=2

a=[1,2]

unique a's: [1,2]

For i=0, a_i=1

bisect_left(arr, 1 + 2 = 3) = index of first element >=3, which is none, so a=2

d = 2 - 0 = 2

For i=1, a_i=2

bisect_left(arr, 2 + 2 =4) = index of first element >=4, which is none, so a=2

d = 2 -1 =1

So, ans = max(2,1) =2

Which matches the example.

Another test case:

n=3

a=[103,102,104]

unique a's: [102,103,104]

For i=0, a_i=102

bisect_left(arr, 102 + 3 =105) = index of first element >=105, which is none, so a=3

d=3-0=3

For i=1, a_i=103

bisect_left(arr,103+3=106)=3

d=3-1=2

For i=2, a_i=104

bisect_left(arr,104+3=107)=3

d=3-2=1

So, ans=max(3,2,1)=3, which matches the expected output.

Another test case:

n=5

a=[1,101,1,100,1]

unique a's: [1,100,101]

For i=0, a_i=1

bisect_left(arr,1+5=6)=index of first element >=6, which is none, so a=3

d=3-0=3

For i=1, a_i=100

bisect_left(arr,100+5=105)=3

d=3-1=2

For i=2, a_i=101

bisect_left(arr,101+5=106)=3

d=3-2=1

So, ans=max(3,2,1)=3

But in the sample output, it's 2 for this test case.

Wait, but according to the code, it would output 3, but the sample output shows 2.

Wait, perhaps there's a mistake.

Looking back at the sample input and output:

7

2

1 2

4

7 1 4 1

3

103 102 104

5

1 101 1 100 1

5

1 10 100 1000 1

2

3 1

3

1000000000 999999997 999999999

Output:

2

2

3

2

1

1

2

Wait, in the fourth test case, n=5, a=[1,101,1,100,1], the code outputs 3, but the sample output is 2.

So, there's a discrepancy here.

Let me check what the correct answer should be.

In the fourth test case:

n=5

a=[1,101,1,100,1]

We need to choose a permutation p of [1,2,3,4,5], add it to a, and find the maximum frequency of any number in the resulting array.

Let me try to find the correct answer.

Possible approach: assign p_i's to a_i's to maximize the frequency of some t.

Let me try to assign p_i's to make as many a_i + p_i equal to some t.

Suppose I choose t=102.

Then, for a_i=1, p_i=101, but p_i must be between 1 and 5, and 101 is not in [1,5]. So, invalid.

For t=101:

a_i=1: p_i=100, invalid

a_i=101: p_i=0, invalid

a_i=1: p_i=100, invalid

a_i=100: p_i=1, valid

a_i=1: p_i=100, invalid

So, only one valid assignment, which is a_i=100 + p_i=1 =101.

Similarly, for t=103:

a_i=101 + p_i=2, which is p_i=2

a_i=1 + p_i=102, invalid

a_i=1 + p_i=102, invalid

a_i=100 + p_i=3, which is p_i=3

But p_i's must be unique.

So, at most two assignments: p_i=2 and p_i=3.

So, maximum frequency is 2.

Hence, the correct answer should be 2, but the code outputs 3.

So, the code is incorrect in this case.

Wait, but according to the code, it outputs 3 for this test case.

So, the code is wrong.

Hence, Correctness: False

**Final Answer**

\[ \boxed{\text{False}} \]