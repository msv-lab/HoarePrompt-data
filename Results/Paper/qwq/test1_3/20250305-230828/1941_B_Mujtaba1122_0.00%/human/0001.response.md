Alright, I've got this problem to solve. Let's see what it's about. So, Rudolf has an array of integers, and he can perform a specific operation on it any number of times. The operation involves choosing an index i (where 2 ≤ i ≤ n-1) and modifying the elements at positions i-1, i, and i+1 by subtracting 1, 2, and 1 respectively. The goal is to make all elements of the array zero using these operations.

First, I need to understand the operation clearly. So, for any index i between 1 and n-1, inclusive, applying the operation decrements a[i-1] by 1, a[i] by 2, and a[i+1] by 1. This can be done any number of times, and any index can be chosen zero or more times.

My task is to determine whether it's possible to make all elements of the array zero after performing these operations.

Let me think about the implications of this operation. Each operation affects three consecutive elements, reducing them by 1, 2, and 1 respectively. I need to find a sequence of such operations that will zero out the entire array.

One way to approach this is to model the problem mathematically. Let's denote the number of times we perform the operation at index j as x_j. Then, for each position i in the array, the total reduction due to all operations can be expressed in terms of x_j.

For example, for position i, the reduction would be:

- x_{i-1} (from operations at index i-1)

- 2*x_i (from operations at index i)

- x_{i+1} (from operations at index i+1)

So, for each i from 1 to n, we have:

a_i - (x_{i-1} + 2*x_i + x_{i+1}) = 0

This gives us the equation:

x_{i-1} + 2*x_i + x_{i+1} = a_i

This is a system of linear equations, one for each i from 1 to n.

However, since x_j represents the number of times we perform the operation at index j, x_j must be non-negative integers.

This seems like a system of linear Diophantine equations with inequalities, which can be tricky to solve directly, especially given the constraints on the input size.

Given that n can be up to 2*10^5 and t up to 10^4, with the total sum of n over all test cases up to 2*10^5, an efficient solution is required. A O(n) per test case seems feasible.

I need to find a way to efficiently determine whether such x_j exist for each test case.

Let me consider smaller cases to see if there's a pattern or a way to simplify this.

Take n=3:

Array: [a, b, c]

Equations:

x1 + 2*x2 = a

x2 = b

2*x2 + x3 = c

From the second equation, x2 = b.

Substitute into the first and third:

b + 2*b = a => 3*b = a

And 2*b + x3 = c => x3 = c - 2*b

For x3 to be non-negative, c - 2*b >= 0.

So, for n=3, it's possible only if a = 3*b and c >= 2*b.

Similarly, for n=4:

[a, b, c, d]

Equations:

x1 + 2*x2 + x3 = a

x2 + 2*x3 + x4 = b

x3 + 2*x4 + x5 = c

x4 + 2*x5 = d

Wait, no. I think I'm miscounting.

Wait, for n=4, indices are 1,2,3,4.

Operations can be performed at i=2 and i=3.

Operation at i=2: a1 -=1, a2 -=2, a3 -=1

Operation at i=3: a2 -=1, a3 -=2, a4 -=1

So, the reductions are:

a1: x2

a2: x2 + x3

a3: x2 + 2*x3

a4: x3

So, the equations are:

x2 = a1

x2 + x3 = a2

x2 + 2*x3 = a3

x3 = a4

From the first equation: x2 = a1

From the fourth equation: x3 = a4

Substitute into the second equation: a1 + a4 = a2

And into the third equation: a1 + 2*a4 = a3

So, for n=4, it's possible only if a1 + a4 = a2 and a1 + 2*a4 = a3, with a1 and a4 being non-negative.

From these small cases, it seems there's a pattern where the operations at different indices are related, and the constraints propagate through the array.

Perhaps I can generalize this for any n.

Let me consider the operations in terms of their effects on the array.

Each operation at index i affects a[i-1], a[i], and a[i+1].

I can think of this as subtracting a certain "pattern" from the array each time an operation is performed.

To make all elements zero, I need to subtract a combination of these patterns such that the total subtraction matches the original array.

This sounds like solving a system of linear equations, but in a more intuitive way.

An alternative approach is to consider the differences between elements.

Let me consider the differences between consecutive elements.

Define d1 = a1, d2 = a2 - a1, d3 = a3 - a2, ..., dn = an - a{n-1}

But I'm not sure if this helps directly.

Wait, perhaps cumulative sums or some other transformation could simplify the problem.

Let me think differently.

Suppose I fix the number of operations at each position x_i for i from 1 to n-1.

Then, the effect on the array would be:

a1: x1

a2: x1 + x2

a3: x2 + x3

...

an-1: x{n-2} + x{n-1}

an: x{n-1}

Wait, that seems similar to the way differences accumulate.

But in our problem, the operations affect three elements at a time.

Wait, maybe I need to model it differently.

Let me consider that each operation at position i affects a[i-1], a[i], and a[i+1].

So, if I perform x_i operations at position i, then:

a[i-1] -= x_i

a[i] -= 2*x_i

a[i+1] -= x_i

I need to choose x_i such that after all these subtractions, a[j] = 0 for all j.

This gives me a system of equations:

For j from 1 to n:

sum over i such that i-1=j or i=j or i+1=j of the corresponding subtraction equals a[j]

Wait, more formally:

For j from 1 to n:

a[j] - (sum over i of the subtraction at j due to x_i) = 0

So, a[j] - (something) = 0, meaning (something) = a[j]

I need to express the subtraction at each position j in terms of the x_i's.

Let's see:

For j=1:

Only operations at i=2 affect a[1], by subtracting x_2

So, subtraction at a[1] is x_2

Similarly, for j=2:

Operations at i=2 affect a[2] by 2*x_2

Operations at i=3 affect a[2] by x_3

So, subtraction at a[2] is 2*x_2 + x_3

For j=3:

Operations at i=2 affect a[3] by x_2

Operations at i=3 affect a[3] by 2*x_3

Operations at i=4 affect a[3] by x_4

So, subtraction at a[3] is x_2 + 2*x_3 + x_4

And so on, until j=n-1 and j=n.

For j=n-1:

Operations at i=n-1 affect a[n-1] by 2*x_{n-1}

Operations at i=n-2 affect a[n-1] by x_{n-2}

So, subtraction at a[n-1] is x_{n-2} + 2*x_{n-1}

For j=n:

Only operations at i=n-1 affect a[n] by x_{n-1}

So, subtraction at a[n] is x_{n-1}

Therefore, the system of equations is:

For j from 1 to n:

a[j] - (certain sum involving x_i) = 0

Explicitly:

j=1: a[1] - x_2 = 0

j=2: a[2] - (2*x_2 + x_3) = 0

j=3: a[3] - (x_2 + 2*x_3 + x_4) = 0

...

j=k: a[k] - (x_{k-1} + 2*x_k + x_{k+1}) = 0

...

j=n-1: a[n-1] - (x_{n-2} + 2*x_{n-1}) = 0

j=n: a[n] - x_{n-1} = 0

So, we have n equations with n-1 variables (x_2 to x_n-1).

Wait, no. Wait, i is from 2 to n-1, so x_i are for i from 2 to n-1.

Wait, no, in the operation, i is from 2 to n-1, but in terms of the equations, the subtractions affect positions from 1 to n.

Wait, perhaps I need to adjust the indexing.

Let me denote x_i as the number of operations performed at position i, where i ranges from 2 to n-1.

Then, for each position j from 1 to n:

- If j=1: subtracted by x_2

- If j=2: subtracted by 2*x_2 + x_3

- If j=k (2 < k < n): subtracted by x_{k-1} + 2*x_k + x_{k+1}

- If j=n-1: subtracted by x_{n-2} + 2*x_{n-1}

- If j=n: subtracted by x_{n-1}

So, the system of equations is:

1: a[1] - x_2 = 0

2: a[2] - (2*x_2 + x_3) = 0

3: a[3] - (x_2 + 2*x_3 + x_4) = 0

...

k: a[k] - (x_{k-1} + 2*x_k + x_{k+1}) = 0

...

n-1: a[n-1] - (x_{n-2} + 2*x_{n-1}) = 0

n: a[n] - x_{n-1} = 0

This is a system of n equations with n-1 variables (x_2 to x_{n-1}).

In general, such a system may or may not have a solution, depending on the values of a[j].

To have a solution, the system must be consistent.

Given that there are n equations and n-1 variables, it's an over-determined system, which typically has no solution unless the extra equations are redundant.

However, in this specific problem, there might be a way to find a solution by exploiting the structure of the equations.

Let me try to solve the system step by step.

Starting from the first equation:

a[1] - x_2 = 0 => x_2 = a[1]

From the second equation:

a[2] - (2*x_2 + x_3) = 0 => a[2] - 2*a[1] - x_3 = 0 => x_3 = a[2] - 2*a[1]

From the third equation:

a[3] - (x_2 + 2*x_3 + x_4) = 0 => a[3] - a[1] - 2*(a[2] - 2*a[1]) - x_4 = 0

Simplify:

a[3] - a[1] - 2*a[2] + 4*a[1] - x_4 = 0 => x_4 = a[3] - a[1] - 2*a[2] + 4*a[1] = a[3] - 2*a[2] + 3*a[1]

Wait, that seems messy. Maybe there's a better way.

Alternatively, perhaps I can express x_i in terms of a_i and a_{i+1}.

Wait, maybe I need to look for a pattern or a recurrence relation.

Let me consider the general equation for j from 2 to n-1:

a[j] - (x_{j-1} + 2*x_j + x_{j+1}) = 0

So, x_{j-1} + 2*x_j + x_{j+1} = a[j]

This looks like a discretized version of a differential equation or something similar.

I recall that in numerical methods, such expressions relate to second derivatives.

But perhaps that's not helpful here.

Alternatively, maybe I can treat this as a recurrence relation and solve it accordingly.

Let me try to express x_j in terms of x_{j-1} and x_{j+1}.

From the equation:

x_{j-1} + 2*x_j + x_{j+1} = a[j]

This can be rearranged to:

2*x_j = a[j] - x_{j-1} - x_{j+1}

But this doesn't directly give me x_j, because x_{j+1} is also unknown.

Alternatively, perhaps I can use a different approach.

Let me consider the operation as subtracting a specific pattern from the array each time.

Each operation at position i subtracts [0, ..., 0, 1, 2, 1, 0, ..., 0] from the array, where the 1,2,1 are at positions i-1, i, i+1.

So, performing x_i operations at position i subtracts x_i * [0, ..., 0, 1, 2, 1, 0, ..., 0].

To make the entire array zero, the total subtraction must equal the original array.

This is equivalent to finding a combination of these patterns that sums up to the original array.

This seems similar to solving a system of linear equations, where each pattern is a vector, and their linear combination should equal the original array.

Given the constraints on n and t, I need an efficient way to determine the solvability of this system.

An alternative approach is to consider the problem in terms of invariants or properties that must hold for the array to be reducible to zero.

Let me look back at the small cases.

For n=3:

Equations:

x2 = a1

x2 + 2*x3 = a2

x3 = a3

From the first equation: x2 = a1

From the third equation: x3 = a3

Substitute into the second equation: a1 + 2*a3 = a2

So, for n=3, it's possible only if a1 + 2*a3 = a2

Similarly, for n=4:

From earlier:

x2 = a1

x3 = a4

a1 + a4 = a2

a1 + 2*a4 = a3

So, for n=4, it's possible only if a1 + a4 = a2 and a1 + 2*a4 = a3

This suggests a pattern where certain linear combinations of the array elements must hold.

Perhaps I can generalize this for any n.

Let me consider expressing a[j] in terms of x_i's and see if there's a pattern.

Wait, maybe I can use the fact that the operations can be represented as a matrix, and solvability depends on whether the original array is in the span of the operation vectors.

But given time constraints, perhaps there's a smarter way.

Let me consider the differences between consecutive elements.

Define d[i] = a[i] - a[i+1] for i from 1 to n-1.

Not sure if that helps directly.

Wait, perhaps cumulative sums.

Let me consider summing the equations.

Wait, maybe not.

An alternative idea: since each operation reduces the sum of the array by 1+2+1=4, the total sum of the array must be divisible by 4.

Wait, no, that's not necessarily true because operations can be performed multiple times, and the reductions are not independent.

Wait, the sum of the array after all operations is zero, so the initial sum must equal the total reduction.

But the total reduction is the sum over all operations of the reduction caused by each operation, which is 1 + 2 + 1 = 4 per operation.

Therefore, the sum of the array must be divisible by 4.

But is this a sufficient condition?

Wait, no, because the reductions are not necessarily additive in a way that allows any multiple of 4.

For example, in n=3, a=[1,2,1], sum is 4, which is divisible by 4.

But from earlier, for n=3, it's possible only if a1 + 2*a3 = a2, which is 1 + 2*1 = 3, which is not equal to a2=2.

So, it's not possible in this case, even though the sum is divisible by 4.

Therefore, sum divisible by 4 is not sufficient.

Hence, there must be additional constraints.

Back to the drawing board.

Let me consider the operations in reverse.

Suppose I start with all zeros and perform the operations to build up to the given array.

Each operation increases a[i-1] by 1, a[i] by 2, and a[i+1] by 1.

So, to reach the given array, I need to find a sequence of operations that, when applied to all zeros, results in the given array.

This is equivalent to finding non-negative integers x_i (for i from 2 to n-1) such that:

a[1] = x_2

a[2] = 2*x_2 + x_3

a[3] = x_2 + 2*x_3 + x_4

...

a[n-1] = x_{n-2} + 2*x_{n-1}

a[n] = x_{n-1}

This is similar to the earlier system but viewed differently.

Starting from a[n], we have x_{n-1} = a[n]

Then, from a[n-1] = x_{n-2} + 2*x_{n-1}, we can express x_{n-2} = a[n-1] - 2*x_{n-1}

But x_{n-2} must be non-negative, so a[n-1] - 2*x_{n-1} >= 0

Given that x_{n-1} = a[n], this becomes a[n-1] - 2*a[n] >= 0

Similarly, proceed backwards.

This seems promising.

Let me try to solve the system starting from the end.

Given:

x_{n-1} = a[n]

x_{n-2} = a[n-1] - 2*x_{n-1} = a[n-1] - 2*a[n]

x_{n-3} = a[n-2] - 2*x_{n-2} - x_{n-1} = a[n-2] - 2*(a[n-1] - 2*a[n]) - a[n] = a[n-2] - 2*a[n-1] + 4*a[n] - a[n] = a[n-2] - 2*a[n-1] + 3*a[n]

And so on.

This seems like a recurrence relation.

In general, for x_j, it can be expressed in terms of a[j+1], a[j+2], etc.

However, this might not be the most efficient way to compute it, especially for large n.

I need a better approach.

Let me consider the problem in terms of linear algebra.

The operations can be represented as vectors, and the problem is to express the original array as a linear combination of these operation vectors.

Given the constraints on n and t, I need an O(n) solution per test case.

An alternative idea is to consider the problem as a system where each operation affects a sliding window of three elements.

I recall that in some problems, such sliding window operations can be handled using prefix sums or similar techniques.

Let me think about prefix sums.

Define p[i] as the prefix sum up to i.

Then, the operation at position i would subtract 1 from p[i], 2 from p[i+1], and 1 from p[i+2].

Wait, not sure if that helps directly.

Wait, perhaps I need to consider the differences between prefix sums.

Let me try a different approach.

Suppose I fix x_{n-1} = a[n]

Then, x_{n-2} = a[n-1] - 2*x_{n-1} = a[n-1] - 2*a[n]

This must be non-negative, so a[n-1] - 2*a[n] >= 0

Similarly, x_{n-3} = a[n-2] - 2*x_{n-2} - x_{n-1} = a[n-2] - 2*(a[n-1] - 2*a[n]) - a[n] = a[n-2] - 2*a[n-1] + 4*a[n] - a[n] = a[n-2] - 2*a[n-1] + 3*a[n]

This must also be non-negative.

Continuing this way, I can compute x_{n-4}, x_{n-5}, and so on, up to x_2.

Finally, I need to check if all x_i are non-negative integers.

This seems feasible.

So, the algorithm would be:

1. Set x_{n-1} = a[n]

2. For j from n-2 down to 2:

x_j = a[j] - 2*x_{j+1} - x_{j+2}

3. Check if all x_j >= 0

4. Additionally, check if x_2 = a[1]

Because from the first equation: x_2 = a[1]

So, in the end, x_2 computed from the above process should equal a[1].

If all x_j are non-negative and x_2 = a[1], then it's possible; otherwise, not.

Wait, but in the above process, x_{n-1} is set to a[n], and x_{n-2} is computed based on a[n-1] and x_{n-1}, and so on.

Then, x_2 is computed based on a[2] and the previous x_j's.

But from the first equation, x_2 should equal a[1].

So, I need to ensure that the computed x_2 equals a[1].

If it does, and all x_j are non-negative, then it's possible.

Otherwise, it's not.

This seems like a viable approach.

Let me test it with the sample input.

Sample Input:

7

5

1 3 5 5 2

5

2 4 4 5 1

5

0 1 3 3 1

6

5 6 0 2 3 0

4

1 2 7 2

3

7 1 0

4

1 1 1 1

Sample Output:

YES

NO

YES

NO

NO

NO

NO

Let's take the first test case:

n=5, a=[1,3,5,5,2]

Set x4 = a[5] = 2

Then x3 = a[4] - 2*x4 = 5 - 2*2 = 1

x2 = a[3] - 2*x3 - x4 = 5 - 2*1 - 2 = 5 - 2 - 2 = 1

Now, check if x2 = a[1], which is 1 == 1, yes.

All x_j >= 0: x2=1, x3=1, x4=2, all non-negative.

So, YES.

Second test case:

n=5, a=[2,4,4,5,1]

Set x4 = 1

x3 = 5 - 2*1 = 3

x2 = 4 - 2*3 -1 = 4 - 6 -1 = -3

x2 is negative, so NO.

Third test case:

n=5, a=[0,1,3,3,1]

Set x4 =1

x3 =3 -2*1 =1

x2=3 -2*1 -1=3-2-1=0

Check x2 == a[1] =0, yes.

All x_j >=0: x2=0, x3=1, x4=1.

So, YES.

Fourth test case:

n=6, a=[5,6,0,2,3,0]

Set x5=0

x4=3 -2*0=3

x3=2 -2*3 -0=2-6-0=-4

Negative x3, so NO.

Fifth test case:

n=4, a=[1,2,7,2]

Set x3=2

x2=7 -2*2=3

Check x2 == a[1]=2, but 3 !=2, so NO.

Sixth test case:

n=3, a=[7,1,0]

Set x2=0

Check x2 == a[1]=1, but 0 !=1, so NO.

Seventh test case:

n=4, a=[1,1,1,1]

Set x3=1

x2=1 -2*1= -1

Negative x2, so NO.

This matches the sample output.

Therefore, this approach seems correct.

Now, implement this efficiently.

Given the constraints, I need to process up to 10^4 test cases, each with up to 2*10^5 elements, but the total sum of n over all test cases is up to 2*10^5, so it's manageable.

I'll need to read all inputs first, process them one by one, and output the results.

Implementing the algorithm