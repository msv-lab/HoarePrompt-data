{
    "total_valid_rows": {
        "value": 27,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "10",
        "agreement_percentage": 37.03703703703704,
        "mcc": 0,
        "accuracy": 0.37037037037037035,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "11",
        "agreement_percentage": 40.74074074074074,
        "mcc": 0.02711630722733202,
        "accuracy": 0.4074074074074074,
        "precision": 0.6666666666666666,
        "recall": 0.11764705882352941,
        "f1_score": 0.2,
        "balanced_accuracy": 0.5088235294117647,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "17",
        "agreement_percentage": 62.96296296296296,
        "mcc": 0.11194627867626022,
        "accuracy": 0.6296296296296297,
        "precision": 0.6521739130434783,
        "recall": 0.8823529411764706,
        "f1_score": 0.75,
        "balanced_accuracy": 0.5411764705882353,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "13",
        "agreement_percentage": 48.148148148148145,
        "mcc": -0.31984651050360063,
        "accuracy": 0.48148148148148145,
        "precision": 0.5652173913043478,
        "recall": 0.7647058823529411,
        "f1_score": 0.65,
        "balanced_accuracy": 0.38235294117647056,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "18",
        "agreement_percentage": 66.66666666666666,
        "mcc": 0.2557041559783794,
        "accuracy": 0.6666666666666666,
        "precision": 0.6538461538461539,
        "recall": 1.0,
        "f1_score": 0.7906976744186047,
        "balanced_accuracy": 0.55,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "12",
        "agreement_percentage": 44.44444444444444,
        "mcc": -0.2169304578186562,
        "accuracy": 0.4444444444444444,
        "precision": 0.5555555555555556,
        "recall": 0.5882352941176471,
        "f1_score": 0.5714285714285715,
        "balanced_accuracy": 0.3941176470588236,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "14",
        "agreement_percentage": 51.85185185185185,
        "mcc": -0.16819265754924004,
        "accuracy": 0.5185185185185185,
        "precision": 0.5909090909090909,
        "recall": 0.7647058823529411,
        "f1_score": 0.6666666666666667,
        "balanced_accuracy": 0.43235294117647055,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "18",
        "agreement_percentage": 66.66666666666666,
        "mcc": 0.21693045781865616,
        "accuracy": 0.6666666666666666,
        "precision": 0.6666666666666666,
        "recall": 0.9411764705882353,
        "f1_score": 0.7804878048780487,
        "balanced_accuracy": 0.5705882352941176,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "17",
        "agreement_percentage": 62.96296296296296,
        "mcc": 0.11194627867626022,
        "accuracy": 0.6296296296296297,
        "precision": 0.6521739130434783,
        "recall": 0.8823529411764706,
        "f1_score": 0.75,
        "balanced_accuracy": 0.5411764705882353,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "18",
        "agreement_percentage": 66.66666666666666,
        "mcc": 0.24631741494982246,
        "accuracy": 0.6666666666666666,
        "precision": 0.7,
        "recall": 0.8235294117647058,
        "f1_score": 0.7567567567567567,
        "balanced_accuracy": 0.611764705882353,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "16",
        "agreement_percentage": 59.25925925925925,
        "mcc": 0.18192392764355278,
        "accuracy": 0.5925925925925926,
        "precision": 0.7142857142857143,
        "recall": 0.5882352941176471,
        "f1_score": 0.6451612903225806,
        "balanced_accuracy": 0.5941176470588235,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "14",
        "agreement_percentage": 51.85185185185185,
        "mcc": -0.011562432251572007,
        "accuracy": 0.5185185185185185,
        "precision": 0.625,
        "recall": 0.5882352941176471,
        "f1_score": 0.6060606060606061,
        "balanced_accuracy": 0.49411764705882355,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "17",
        "agreement_percentage": 62.96296296296296,
        "mcc": 0.27857101420419017,
        "accuracy": 0.6296296296296297,
        "precision": 0.7692307692307693,
        "recall": 0.5882352941176471,
        "f1_score": 0.6666666666666667,
        "balanced_accuracy": 0.6441176470588235,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}