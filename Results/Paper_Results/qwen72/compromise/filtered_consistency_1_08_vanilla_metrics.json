{
    "total_valid_rows": {
        "value": 133,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "51",
        "agreement_percentage": 38.34586466165413,
        "mcc": 0.04322928132781762,
        "accuracy": 0.38345864661654133,
        "precision": 0.75,
        "recall": 0.03571428571428571,
        "f1_score": 0.06818181818181818,
        "balanced_accuracy": 0.5076530612244898,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "54",
        "agreement_percentage": 40.6015037593985,
        "mcc": 0.025934251837061547,
        "accuracy": 0.40601503759398494,
        "precision": 0.6666666666666666,
        "recall": 0.11904761904761904,
        "f1_score": 0.20202020202020202,
        "balanced_accuracy": 0.5085034013605442,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "83",
        "agreement_percentage": 62.40601503759399,
        "mcc": 0.08908708063747481,
        "accuracy": 0.6240601503759399,
        "precision": 0.6491228070175439,
        "recall": 0.8809523809523809,
        "f1_score": 0.7474747474747475,
        "balanced_accuracy": 0.532312925170068,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "75",
        "agreement_percentage": 56.390977443609025,
        "mcc": -0.04829546044006792,
        "accuracy": 0.5639097744360902,
        "precision": 0.6203703703703703,
        "recall": 0.7976190476190477,
        "f1_score": 0.6979166666666666,
        "balanced_accuracy": 0.4804421768707483,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "83",
        "agreement_percentage": 62.40601503759399,
        "mcc": 0.04245918092377111,
        "accuracy": 0.6240601503759399,
        "precision": 0.6370967741935484,
        "recall": 0.9404761904761905,
        "f1_score": 0.7596153846153847,
        "balanced_accuracy": 0.5110544217687075,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "67",
        "agreement_percentage": 50.37593984962406,
        "mcc": -0.07551180974581614,
        "accuracy": 0.5037593984962406,
        "precision": 0.6046511627906976,
        "recall": 0.6190476190476191,
        "f1_score": 0.611764705882353,
        "balanced_accuracy": 0.46258503401360546,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "75",
        "agreement_percentage": 56.390977443609025,
        "mcc": -0.06073767001317861,
        "accuracy": 0.5639097744360902,
        "precision": 0.6181818181818182,
        "recall": 0.8095238095238095,
        "f1_score": 0.7010309278350516,
        "balanced_accuracy": 0.47619047619047616,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "78",
        "agreement_percentage": 58.64661654135338,
        "mcc": 0.01654900095921012,
        "accuracy": 0.5864661654135338,
        "precision": 0.6355140186915887,
        "recall": 0.8095238095238095,
        "f1_score": 0.712041884816754,
        "balanced_accuracy": 0.5068027210884354,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "83",
        "agreement_percentage": 62.40601503759399,
        "mcc": 0.11128953927493912,
        "accuracy": 0.6240601503759399,
        "precision": 0.6574074074074074,
        "recall": 0.8452380952380952,
        "f1_score": 0.7395833333333334,
        "balanced_accuracy": 0.5450680272108843,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "79",
        "agreement_percentage": 59.3984962406015,
        "mcc": 0.074520075851043,
        "accuracy": 0.5939849624060151,
        "precision": 0.6530612244897959,
        "recall": 0.7619047619047619,
        "f1_score": 0.7032967032967032,
        "balanced_accuracy": 0.5340136054421769,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "65",
        "agreement_percentage": 48.87218045112782,
        "mcc": 0.01993894736568152,
        "accuracy": 0.48872180451127817,
        "precision": 0.6428571428571429,
        "recall": 0.42857142857142855,
        "f1_score": 0.5142857142857143,
        "balanced_accuracy": 0.5102040816326531,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "63",
        "agreement_percentage": 47.368421052631575,
        "mcc": -0.011631052629980886,
        "accuracy": 0.47368421052631576,
        "precision": 0.625,
        "recall": 0.4166666666666667,
        "f1_score": 0.5,
        "balanced_accuracy": 0.49404761904761907,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "62",
        "agreement_percentage": 46.616541353383454,
        "mcc": -0.00674882759848957,
        "accuracy": 0.46616541353383456,
        "precision": 0.6274509803921569,
        "recall": 0.38095238095238093,
        "f1_score": 0.47407407407407404,
        "balanced_accuracy": 0.4965986394557823,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}