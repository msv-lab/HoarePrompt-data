{
    "total_valid_rows": {
        "value": 23,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "9",
        "agreement_percentage": 39.130434782608695,
        "mcc": 0,
        "accuracy": 0.391304347826087,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "9",
        "agreement_percentage": 39.130434782608695,
        "mcc": 0,
        "accuracy": 0.391304347826087,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "14",
        "agreement_percentage": 60.86956521739131,
        "mcc": 0.13231403100624078,
        "accuracy": 0.6086956521739131,
        "precision": 0.6470588235294118,
        "recall": 0.7857142857142857,
        "f1_score": 0.7096774193548386,
        "balanced_accuracy": 0.5595238095238095,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "15",
        "agreement_percentage": 65.21739130434783,
        "mcc": 0.2253744679276044,
        "accuracy": 0.6521739130434783,
        "precision": 0.6666666666666666,
        "recall": 0.8571428571428571,
        "f1_score": 0.75,
        "balanced_accuracy": 0.5952380952380952,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "11",
        "agreement_percentage": 47.82608695652174,
        "mcc": -0.2065932622669707,
        "accuracy": 0.4782608695652174,
        "precision": 0.5555555555555556,
        "recall": 0.7142857142857143,
        "f1_score": 0.6250000000000001,
        "balanced_accuracy": 0.4126984126984127,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "10",
        "agreement_percentage": 43.47826086956522,
        "mcc": -0.0873015873015873,
        "accuracy": 0.43478260869565216,
        "precision": 0.5555555555555556,
        "recall": 0.35714285714285715,
        "f1_score": 0.43478260869565216,
        "balanced_accuracy": 0.4563492063492064,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "13",
        "agreement_percentage": 56.52173913043478,
        "mcc": 0.05050762722761054,
        "accuracy": 0.5652173913043478,
        "precision": 0.625,
        "recall": 0.7142857142857143,
        "f1_score": 0.6666666666666666,
        "balanced_accuracy": 0.5238095238095238,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "13",
        "agreement_percentage": 56.52173913043478,
        "mcc": 0.00939060283031685,
        "accuracy": 0.5652173913043478,
        "precision": 0.6111111111111112,
        "recall": 0.7857142857142857,
        "f1_score": 0.6875000000000001,
        "balanced_accuracy": 0.503968253968254,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "14",
        "agreement_percentage": 60.86956521739131,
        "mcc": 0.13231403100624078,
        "accuracy": 0.6086956521739131,
        "precision": 0.6470588235294118,
        "recall": 0.7857142857142857,
        "f1_score": 0.7096774193548386,
        "balanced_accuracy": 0.5595238095238095,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "11",
        "agreement_percentage": 47.82608695652174,
        "mcc": -0.1431049438115632,
        "accuracy": 0.4782608695652174,
        "precision": 0.5625,
        "recall": 0.6428571428571429,
        "f1_score": 0.6000000000000001,
        "balanced_accuracy": 0.43253968253968256,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "13",
        "agreement_percentage": 56.52173913043478,
        "mcc": 0.21144501580551553,
        "accuracy": 0.5652173913043478,
        "precision": 0.75,
        "recall": 0.42857142857142855,
        "f1_score": 0.5454545454545454,
        "balanced_accuracy": 0.6031746031746031,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "12",
        "agreement_percentage": 52.17391304347826,
        "mcc": 0.054278245606577465,
        "accuracy": 0.5217391304347826,
        "precision": 0.6363636363636364,
        "recall": 0.5,
        "f1_score": 0.56,
        "balanced_accuracy": 0.5277777777777778,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "13",
        "agreement_percentage": 56.52173913043478,
        "mcc": 0.1640825308284734,
        "accuracy": 0.5652173913043478,
        "precision": 0.7,
        "recall": 0.5,
        "f1_score": 0.5833333333333334,
        "balanced_accuracy": 0.5833333333333333,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}