{
    "total_valid_rows": {
        "value": 87,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "50",
        "agreement_percentage": 57.47126436781609,
        "mcc": 0.29242326110684774,
        "accuracy": 0.5747126436781609,
        "precision": 1.0,
        "recall": 0.1590909090909091,
        "f1_score": 0.2745098039215686,
        "balanced_accuracy": 0.5795454545454546,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "48",
        "agreement_percentage": 55.172413793103445,
        "mcc": 0.16856684414859063,
        "accuracy": 0.5517241379310345,
        "precision": 0.7272727272727273,
        "recall": 0.18181818181818182,
        "f1_score": 0.2909090909090909,
        "balanced_accuracy": 0.5560253699788583,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "49",
        "agreement_percentage": 56.32183908045977,
        "mcc": 0.12599274756046933,
        "accuracy": 0.5632183908045977,
        "precision": 0.5652173913043478,
        "recall": 0.5909090909090909,
        "f1_score": 0.5777777777777778,
        "balanced_accuracy": 0.5628964059196617,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "55",
        "agreement_percentage": 63.2183908045977,
        "mcc": 0.2646158502796509,
        "accuracy": 0.632183908045977,
        "precision": 0.625,
        "recall": 0.6818181818181818,
        "f1_score": 0.6521739130434783,
        "balanced_accuracy": 0.6316067653276956,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "55",
        "agreement_percentage": 63.2183908045977,
        "mcc": 0.2641612648431689,
        "accuracy": 0.632183908045977,
        "precision": 0.6304347826086957,
        "recall": 0.6590909090909091,
        "f1_score": 0.6444444444444444,
        "balanced_accuracy": 0.6318710359408033,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "46",
        "agreement_percentage": 52.87356321839081,
        "mcc": 0.06682943484365403,
        "accuracy": 0.5287356321839081,
        "precision": 0.5555555555555556,
        "recall": 0.3409090909090909,
        "f1_score": 0.4225352112676057,
        "balanced_accuracy": 0.5309196617336152,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "50",
        "agreement_percentage": 57.47126436781609,
        "mcc": 0.1528690627487934,
        "accuracy": 0.5747126436781609,
        "precision": 0.5945945945945946,
        "recall": 0.5,
        "f1_score": 0.5432098765432098,
        "balanced_accuracy": 0.5755813953488372,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "47",
        "agreement_percentage": 54.02298850574713,
        "mcc": 0.08658450670786945,
        "accuracy": 0.5402298850574713,
        "precision": 0.5625,
        "recall": 0.4090909090909091,
        "f1_score": 0.47368421052631576,
        "balanced_accuracy": 0.5417547568710359,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "51",
        "agreement_percentage": 58.620689655172406,
        "mcc": 0.1752852989234798,
        "accuracy": 0.5862068965517241,
        "precision": 0.6052631578947368,
        "recall": 0.5227272727272727,
        "f1_score": 0.5609756097560975,
        "balanced_accuracy": 0.5869450317124736,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "50",
        "agreement_percentage": 57.47126436781609,
        "mcc": 0.15946391281436473,
        "accuracy": 0.5747126436781609,
        "precision": 0.6129032258064516,
        "recall": 0.4318181818181818,
        "f1_score": 0.5066666666666667,
        "balanced_accuracy": 0.5763742071881607,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "52",
        "agreement_percentage": 59.77011494252874,
        "mcc": 0.2213159911060485,
        "accuracy": 0.5977011494252874,
        "precision": 0.68,
        "recall": 0.38636363636363635,
        "f1_score": 0.4927536231884058,
        "balanced_accuracy": 0.6001585623678647,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "48",
        "agreement_percentage": 55.172413793103445,
        "mcc": 0.12343910077577086,
        "accuracy": 0.5517241379310345,
        "precision": 0.6086956521739131,
        "recall": 0.3181818181818182,
        "f1_score": 0.41791044776119407,
        "balanced_accuracy": 0.5544397463002114,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "50",
        "agreement_percentage": 57.47126436781609,
        "mcc": 0.18155371886828137,
        "accuracy": 0.5747126436781609,
        "precision": 0.6666666666666666,
        "recall": 0.3181818181818182,
        "f1_score": 0.43076923076923074,
        "balanced_accuracy": 0.5776955602536998,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}