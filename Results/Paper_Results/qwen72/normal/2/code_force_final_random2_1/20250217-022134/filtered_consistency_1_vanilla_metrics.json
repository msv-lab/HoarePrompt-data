{
    "total_valid_rows": {
        "value": 29,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "15",
        "agreement_percentage": 51.724137931034484,
        "mcc": 0.18257418583505539,
        "accuracy": 0.5172413793103449,
        "precision": 1.0,
        "recall": 0.06666666666666667,
        "f1_score": 0.125,
        "balanced_accuracy": 0.5333333333333333,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "12",
        "agreement_percentage": 41.37931034482759,
        "mcc": -0.17569105537498347,
        "accuracy": 0.41379310344827586,
        "precision": 0.375,
        "recall": 0.2,
        "f1_score": 0.26086956521739135,
        "balanced_accuracy": 0.4214285714285715,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "14",
        "agreement_percentage": 48.275862068965516,
        "mcc": -0.101574900036674,
        "accuracy": 0.4827586206896552,
        "precision": 0.5,
        "recall": 0.8666666666666667,
        "f1_score": 0.6341463414634146,
        "balanced_accuracy": 0.46904761904761905,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "16",
        "agreement_percentage": 55.172413793103445,
        "mcc": 0.1956151991089879,
        "accuracy": 0.5517241379310345,
        "precision": 0.5357142857142857,
        "recall": 1.0,
        "f1_score": 0.6976744186046512,
        "balanced_accuracy": 0.5357142857142857,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "16",
        "agreement_percentage": 55.172413793103445,
        "mcc": 0.1956151991089879,
        "accuracy": 0.5517241379310345,
        "precision": 0.5357142857142857,
        "recall": 1.0,
        "f1_score": 0.6976744186046512,
        "balanced_accuracy": 0.5357142857142857,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "14",
        "agreement_percentage": 48.275862068965516,
        "mcc": -0.05143444998736397,
        "accuracy": 0.4827586206896552,
        "precision": 0.5,
        "recall": 0.6666666666666666,
        "f1_score": 0.5714285714285715,
        "balanced_accuracy": 0.47619047619047616,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "15",
        "agreement_percentage": 51.724137931034484,
        "mcc": 0.013801311186847083,
        "accuracy": 0.5172413793103449,
        "precision": 0.52,
        "recall": 0.8666666666666667,
        "f1_score": 0.65,
        "balanced_accuracy": 0.5047619047619047,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "15",
        "agreement_percentage": 51.724137931034484,
        "mcc": 0.00939060283031685,
        "accuracy": 0.5172413793103449,
        "precision": 0.5185185185185185,
        "recall": 0.9333333333333333,
        "f1_score": 0.6666666666666667,
        "balanced_accuracy": 0.5023809523809524,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "15",
        "agreement_percentage": 51.724137931034484,
        "mcc": 0.013801311186847083,
        "accuracy": 0.5172413793103449,
        "precision": 0.52,
        "recall": 0.8666666666666667,
        "f1_score": 0.65,
        "balanced_accuracy": 0.5047619047619047,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "16",
        "agreement_percentage": 55.172413793103445,
        "mcc": 0.12501526158359877,
        "accuracy": 0.5517241379310345,
        "precision": 0.5384615384615384,
        "recall": 0.9333333333333333,
        "f1_score": 0.6829268292682926,
        "balanced_accuracy": 0.5380952380952381,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "12",
        "agreement_percentage": 41.37931034482759,
        "mcc": -0.17569105537498347,
        "accuracy": 0.41379310344827586,
        "precision": 0.375,
        "recall": 0.2,
        "f1_score": 0.26086956521739135,
        "balanced_accuracy": 0.4214285714285715,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "12",
        "agreement_percentage": 41.37931034482759,
        "mcc": -0.17569105537498347,
        "accuracy": 0.41379310344827586,
        "precision": 0.375,
        "recall": 0.2,
        "f1_score": 0.26086956521739135,
        "balanced_accuracy": 0.4214285714285715,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "12",
        "agreement_percentage": 41.37931034482759,
        "mcc": -0.17021289926939803,
        "accuracy": 0.41379310344827586,
        "precision": 0.4,
        "recall": 0.26666666666666666,
        "f1_score": 0.32,
        "balanced_accuracy": 0.419047619047619,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}