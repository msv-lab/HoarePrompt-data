{
    "total_valid_rows": {
        "value": 19,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "6",
        "agreement_percentage": 31.57894736842105,
        "mcc": 0,
        "accuracy": 0.3157894736842105,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "8",
        "agreement_percentage": 42.10526315789473,
        "mcc": 0.2330206912141852,
        "accuracy": 0.42105263157894735,
        "precision": 1.0,
        "recall": 0.15384615384615385,
        "f1_score": 0.2666666666666667,
        "balanced_accuracy": 0.5769230769230769,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "14",
        "agreement_percentage": 73.68421052631578,
        "mcc": 0.3469443332443555,
        "accuracy": 0.7368421052631579,
        "precision": 0.7222222222222222,
        "recall": 1.0,
        "f1_score": 0.8387096774193548,
        "balanced_accuracy": 0.5833333333333334,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "12",
        "agreement_percentage": 63.1578947368421,
        "mcc": 0.016343011261515335,
        "accuracy": 0.631578947368421,
        "precision": 0.6875,
        "recall": 0.8461538461538461,
        "f1_score": 0.7586206896551724,
        "balanced_accuracy": 0.5064102564102564,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "14",
        "agreement_percentage": 73.68421052631578,
        "mcc": 0.3469443332443555,
        "accuracy": 0.7368421052631579,
        "precision": 0.7222222222222222,
        "recall": 1.0,
        "f1_score": 0.8387096774193548,
        "balanced_accuracy": 0.5833333333333334,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "14",
        "agreement_percentage": 73.68421052631578,
        "mcc": 0.4893451639269458,
        "accuracy": 0.7368421052631579,
        "precision": 0.9,
        "recall": 0.6923076923076923,
        "f1_score": 0.7826086956521738,
        "balanced_accuracy": 0.7628205128205128,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "14",
        "agreement_percentage": 73.68421052631578,
        "mcc": 0.3469443332443555,
        "accuracy": 0.7368421052631579,
        "precision": 0.7222222222222222,
        "recall": 1.0,
        "f1_score": 0.8387096774193548,
        "balanced_accuracy": 0.5833333333333334,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "13",
        "agreement_percentage": 68.42105263157895,
        "mcc": 0.13592873654160803,
        "accuracy": 0.6842105263157895,
        "precision": 0.7058823529411765,
        "recall": 0.9230769230769231,
        "f1_score": 0.8000000000000002,
        "balanced_accuracy": 0.5448717948717949,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "15",
        "agreement_percentage": 78.94736842105263,
        "mcc": 0.5048781642974013,
        "accuracy": 0.7894736842105263,
        "precision": 0.7647058823529411,
        "recall": 1.0,
        "f1_score": 0.8666666666666666,
        "balanced_accuracy": 0.6666666666666666,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "15",
        "agreement_percentage": 78.94736842105263,
        "mcc": 0.48238191061886604,
        "accuracy": 0.7894736842105263,
        "precision": 0.8,
        "recall": 0.9230769230769231,
        "f1_score": 0.8571428571428571,
        "balanced_accuracy": 0.7115384615384616,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "7",
        "agreement_percentage": 36.84210526315789,
        "mcc": -0.10826639239215334,
        "accuracy": 0.3684210526315789,
        "precision": 0.6,
        "recall": 0.23076923076923078,
        "f1_score": 0.33333333333333337,
        "balanced_accuracy": 0.4487179487179487,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "11",
        "agreement_percentage": 57.89473684210527,
        "mcc": 0.28414557138675545,
        "accuracy": 0.5789473684210527,
        "precision": 0.8571428571428571,
        "recall": 0.46153846153846156,
        "f1_score": 0.6,
        "balanced_accuracy": 0.6474358974358975,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "12",
        "agreement_percentage": 63.1578947368421,
        "mcc": 0.35003329844931896,
        "accuracy": 0.631578947368421,
        "precision": 0.875,
        "recall": 0.5384615384615384,
        "f1_score": 0.6666666666666667,
        "balanced_accuracy": 0.6858974358974359,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}