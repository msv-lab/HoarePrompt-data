{
    "total_valid_rows": {
        "value": 23,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "12",
        "agreement_percentage": 52.17391304347826,
        "mcc": 0,
        "accuracy": 0.5217391304347826,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "9",
        "agreement_percentage": 39.130434782608695,
        "mcc": -0.37080992435478316,
        "accuracy": 0.391304347826087,
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.375,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "11",
        "agreement_percentage": 47.82608695652174,
        "mcc": -0.01996807659577179,
        "accuracy": 0.4782608695652174,
        "precision": 0.47368421052631576,
        "recall": 0.8181818181818182,
        "f1_score": 0.6,
        "balanced_accuracy": 0.49242424242424243,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "10",
        "agreement_percentage": 43.47826086956522,
        "mcc": -0.1284457725980754,
        "accuracy": 0.43478260869565216,
        "precision": 0.4444444444444444,
        "recall": 0.7272727272727273,
        "f1_score": 0.5517241379310345,
        "balanced_accuracy": 0.44696969696969696,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "11",
        "agreement_percentage": 47.82608695652174,
        "mcc": 0,
        "accuracy": 0.4782608695652174,
        "precision": 0.4782608695652174,
        "recall": 1.0,
        "f1_score": 0.6470588235294118,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "8",
        "agreement_percentage": 34.78260869565217,
        "mcc": -0.3394638275806278,
        "accuracy": 0.34782608695652173,
        "precision": 0.3888888888888889,
        "recall": 0.6363636363636364,
        "f1_score": 0.4827586206896552,
        "balanced_accuracy": 0.35984848484848486,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "8",
        "agreement_percentage": 34.78260869565217,
        "mcc": -0.3394638275806278,
        "accuracy": 0.34782608695652173,
        "precision": 0.3888888888888889,
        "recall": 0.6363636363636364,
        "f1_score": 0.4827586206896552,
        "balanced_accuracy": 0.35984848484848486,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "12",
        "agreement_percentage": 52.17391304347826,
        "mcc": 0.0657951694959769,
        "accuracy": 0.5217391304347826,
        "precision": 0.5,
        "recall": 0.7272727272727273,
        "f1_score": 0.5925925925925926,
        "balanced_accuracy": 0.5303030303030303,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "13",
        "agreement_percentage": 56.52173913043478,
        "mcc": 0.13740858372430334,
        "accuracy": 0.5652173913043478,
        "precision": 0.5384615384615384,
        "recall": 0.6363636363636364,
        "f1_score": 0.5833333333333334,
        "balanced_accuracy": 0.5681818181818181,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "14",
        "agreement_percentage": 60.86956521739131,
        "mcc": 0.2196969696969697,
        "accuracy": 0.6086956521739131,
        "precision": 0.5833333333333334,
        "recall": 0.6363636363636364,
        "f1_score": 0.6086956521739131,
        "balanced_accuracy": 0.6098484848484849,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "7",
        "agreement_percentage": 30.434782608695656,
        "mcc": -0.44411739409784406,
        "accuracy": 0.30434782608695654,
        "precision": 0.14285714285714285,
        "recall": 0.09090909090909091,
        "f1_score": 0.1111111111111111,
        "balanced_accuracy": 0.29545454545454547,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "6",
        "agreement_percentage": 26.08695652173913,
        "mcc": -0.5687964589945211,
        "accuracy": 0.2608695652173913,
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.25,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "6",
        "agreement_percentage": 26.08695652173913,
        "mcc": -0.4885638532419674,
        "accuracy": 0.2608695652173913,
        "precision": 0.2,
        "recall": 0.18181818181818182,
        "f1_score": 0.1904761904761905,
        "balanced_accuracy": 0.25757575757575757,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}