{
    "total_valid_rows": {
        "value": 42,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "19",
        "agreement_percentage": 45.23809523809524,
        "mcc": 0,
        "accuracy": 0.4523809523809524,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "19",
        "agreement_percentage": 45.23809523809524,
        "mcc": 0,
        "accuracy": 0.4523809523809524,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "27",
        "agreement_percentage": 64.28571428571429,
        "mcc": 0.35696473595396144,
        "accuracy": 0.6428571428571429,
        "precision": 0.6052631578947368,
        "recall": 1.0,
        "f1_score": 0.7540983606557378,
        "balanced_accuracy": 0.6052631578947368,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "26",
        "agreement_percentage": 61.904761904761905,
        "mcc": 0.25674162013381635,
        "accuracy": 0.6190476190476191,
        "precision": 0.5945945945945946,
        "recall": 0.9565217391304348,
        "f1_score": 0.7333333333333334,
        "balanced_accuracy": 0.5835240274599542,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "22",
        "agreement_percentage": 52.38095238095239,
        "mcc": -0.14194527943608679,
        "accuracy": 0.5238095238095238,
        "precision": 0.5365853658536586,
        "recall": 0.9565217391304348,
        "f1_score": 0.6875000000000001,
        "balanced_accuracy": 0.4782608695652174,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "28",
        "agreement_percentage": 66.66666666666666,
        "mcc": 0.32723112128146453,
        "accuracy": 0.6666666666666666,
        "precision": 0.6956521739130435,
        "recall": 0.6956521739130435,
        "f1_score": 0.6956521739130435,
        "balanced_accuracy": 0.6636155606407322,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "26",
        "agreement_percentage": 61.904761904761905,
        "mcc": 0.23532440241230695,
        "accuracy": 0.6190476190476191,
        "precision": 0.6,
        "recall": 0.9130434782608695,
        "f1_score": 0.7241379310344828,
        "balanced_accuracy": 0.5881006864988558,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "23",
        "agreement_percentage": 54.761904761904766,
        "mcc": 0.031040411822083606,
        "accuracy": 0.5476190476190477,
        "precision": 0.5526315789473685,
        "recall": 0.9130434782608695,
        "f1_score": 0.6885245901639344,
        "balanced_accuracy": 0.5091533180778032,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "25",
        "agreement_percentage": 59.523809523809526,
        "mcc": 0.17576247754451405,
        "accuracy": 0.5952380952380952,
        "precision": 0.5833333333333334,
        "recall": 0.9130434782608695,
        "f1_score": 0.7118644067796611,
        "balanced_accuracy": 0.5617848970251715,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "23",
        "agreement_percentage": 54.761904761904766,
        "mcc": 0.03905832834322535,
        "accuracy": 0.5476190476190477,
        "precision": 0.5555555555555556,
        "recall": 0.8695652173913043,
        "f1_score": 0.6779661016949152,
        "balanced_accuracy": 0.5137299771167048,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "28",
        "agreement_percentage": 66.66666666666666,
        "mcc": 0.37794525235915966,
        "accuracy": 0.6666666666666666,
        "precision": 0.8,
        "recall": 0.5217391304347826,
        "f1_score": 0.6315789473684211,
        "balanced_accuracy": 0.6819221967963387,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "22",
        "agreement_percentage": 52.38095238095239,
        "mcc": 0.10621013203647137,
        "accuracy": 0.5238095238095238,
        "precision": 0.6363636363636364,
        "recall": 0.30434782608695654,
        "f1_score": 0.411764705882353,
        "balanced_accuracy": 0.5469107551487414,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "26",
        "agreement_percentage": 61.904761904761905,
        "mcc": 0.2981082373987417,
        "accuracy": 0.6190476190476191,
        "precision": 0.7692307692307693,
        "recall": 0.43478260869565216,
        "f1_score": 0.5555555555555555,
        "balanced_accuracy": 0.6384439359267734,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}