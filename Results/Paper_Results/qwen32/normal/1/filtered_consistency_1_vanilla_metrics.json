{
    "total_valid_rows": {
        "value": 61,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "36",
        "agreement_percentage": 59.01639344262295,
        "mcc": 0.17424594240346214,
        "accuracy": 0.5901639344262295,
        "precision": 0.75,
        "recall": 0.5853658536585366,
        "f1_score": 0.6575342465753423,
        "balanced_accuracy": 0.5926829268292683,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "26",
        "agreement_percentage": 42.62295081967213,
        "mcc": -0.08086036207099133,
        "accuracy": 0.4262295081967213,
        "precision": 0.625,
        "recall": 0.36585365853658536,
        "f1_score": 0.4615384615384615,
        "balanced_accuracy": 0.4579268292682927,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "42",
        "agreement_percentage": 68.85245901639344,
        "mcc": 0.24993459731277484,
        "accuracy": 0.6885245901639344,
        "precision": 0.7391304347826086,
        "recall": 0.8292682926829268,
        "f1_score": 0.7816091954022988,
        "balanced_accuracy": 0.6146341463414634,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "38",
        "agreement_percentage": 62.295081967213115,
        "mcc": 0.15543296839958126,
        "accuracy": 0.6229508196721312,
        "precision": 0.725,
        "recall": 0.7073170731707317,
        "f1_score": 0.7160493827160495,
        "balanced_accuracy": 0.5786585365853658,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "30",
        "agreement_percentage": 49.18032786885246,
        "mcc": -0.03553700141123241,
        "accuracy": 0.4918032786885246,
        "precision": 0.65625,
        "recall": 0.5121951219512195,
        "f1_score": 0.5753424657534246,
        "balanced_accuracy": 0.48109756097560974,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "23",
        "agreement_percentage": 37.704918032786885,
        "mcc": -0.15543296839958126,
        "accuracy": 0.3770491803278688,
        "precision": 0.5714285714285714,
        "recall": 0.2926829268292683,
        "f1_score": 0.3870967741935484,
        "balanced_accuracy": 0.4213414634146342,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "41",
        "agreement_percentage": 67.21311475409836,
        "mcc": 0.23723807839871372,
        "accuracy": 0.6721311475409836,
        "precision": 0.7441860465116279,
        "recall": 0.7804878048780488,
        "f1_score": 0.761904761904762,
        "balanced_accuracy": 0.6152439024390244,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "29",
        "agreement_percentage": 47.540983606557376,
        "mcc": -0.03439064652699911,
        "accuracy": 0.47540983606557374,
        "precision": 0.6551724137931034,
        "recall": 0.4634146341463415,
        "f1_score": 0.5428571428571429,
        "balanced_accuracy": 0.4817073170731707,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "28",
        "agreement_percentage": 45.90163934426229,
        "mcc": -0.0335714713412936,
        "accuracy": 0.45901639344262296,
        "precision": 0.6538461538461539,
        "recall": 0.4146341463414634,
        "f1_score": 0.5074626865671641,
        "balanced_accuracy": 0.4823170731707317,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "31",
        "agreement_percentage": 50.81967213114754,
        "mcc": 0.011451215811497927,
        "accuracy": 0.5081967213114754,
        "precision": 0.6774193548387096,
        "recall": 0.5121951219512195,
        "f1_score": 0.5833333333333334,
        "balanced_accuracy": 0.5060975609756098,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "26",
        "agreement_percentage": 42.62295081967213,
        "mcc": -0.032926829268292684,
        "accuracy": 0.4262295081967213,
        "precision": 0.65,
        "recall": 0.3170731707317073,
        "f1_score": 0.42622950819672134,
        "balanced_accuracy": 0.48353658536585364,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "32",
        "agreement_percentage": 52.459016393442624,
        "mcc": 0.10766023568070018,
        "accuracy": 0.5245901639344263,
        "precision": 0.7307692307692307,
        "recall": 0.4634146341463415,
        "f1_score": 0.5671641791044776,
        "balanced_accuracy": 0.5567073170731708,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "28",
        "agreement_percentage": 45.90163934426229,
        "mcc": -0.009375114443013487,
        "accuracy": 0.45901639344262296,
        "precision": 0.6666666666666666,
        "recall": 0.3902439024390244,
        "f1_score": 0.4923076923076923,
        "balanced_accuracy": 0.4951219512195122,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}