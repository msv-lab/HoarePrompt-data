{
    "total_valid_rows": {
        "value": 284,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "156",
        "agreement_percentage": 54.929577464788736,
        "mcc": 0.09303580673878313,
        "accuracy": 0.5492957746478874,
        "precision": 0.56,
        "recall": 0.30656934306569344,
        "f1_score": 0.3962264150943396,
        "balanced_accuracy": 0.5410397735736631,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "153",
        "agreement_percentage": 53.87323943661971,
        "mcc": 0.08256456989701981,
        "accuracy": 0.5387323943661971,
        "precision": 0.6071428571428571,
        "recall": 0.12408759124087591,
        "f1_score": 0.20606060606060606,
        "balanced_accuracy": 0.5246288296340434,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "165",
        "agreement_percentage": 58.098591549295776,
        "mcc": 0.15852782331659282,
        "accuracy": 0.5809859154929577,
        "precision": 0.575,
        "recall": 0.5036496350364964,
        "f1_score": 0.5369649805447472,
        "balanced_accuracy": 0.5783554297631461,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "164",
        "agreement_percentage": 57.74647887323944,
        "mcc": 0.15118417987583524,
        "accuracy": 0.5774647887323944,
        "precision": 0.5726495726495726,
        "recall": 0.48905109489051096,
        "f1_score": 0.5275590551181103,
        "balanced_accuracy": 0.5744575202343711,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "150",
        "agreement_percentage": 52.816901408450704,
        "mcc": 0.04588174955074341,
        "accuracy": 0.528169014084507,
        "precision": 0.5180722891566265,
        "recall": 0.31386861313868614,
        "f1_score": 0.390909090909091,
        "balanced_accuracy": 0.5208798848006356,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "154",
        "agreement_percentage": 54.22535211267606,
        "mcc": 0.0955050963876577,
        "accuracy": 0.5422535211267606,
        "precision": 0.6296296296296297,
        "recall": 0.12408759124087591,
        "f1_score": 0.20731707317073172,
        "balanced_accuracy": 0.5280301901782611,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "164",
        "agreement_percentage": 57.74647887323944,
        "mcc": 0.15097107270951265,
        "accuracy": 0.5774647887323944,
        "precision": 0.5779816513761468,
        "recall": 0.45985401459854014,
        "f1_score": 0.5121951219512195,
        "balanced_accuracy": 0.5734644222652565,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "156",
        "agreement_percentage": 54.929577464788736,
        "mcc": 0.09357250536897858,
        "accuracy": 0.5492957746478874,
        "precision": 0.5633802816901409,
        "recall": 0.291970802919708,
        "f1_score": 0.3846153846153846,
        "balanced_accuracy": 0.5405432245891058,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "152",
        "agreement_percentage": 53.52112676056338,
        "mcc": 0.06102554697976864,
        "accuracy": 0.5352112676056338,
        "precision": 0.5352112676056338,
        "recall": 0.2773722627737226,
        "f1_score": 0.36538461538461536,
        "balanced_accuracy": 0.5264412334276776,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "152",
        "agreement_percentage": 53.52112676056338,
        "mcc": 0.0612122724899736,
        "accuracy": 0.5352112676056338,
        "precision": 0.5396825396825397,
        "recall": 0.24817518248175183,
        "f1_score": 0.33999999999999997,
        "balanced_accuracy": 0.525448135458563,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "157",
        "agreement_percentage": 55.28169014084507,
        "mcc": 0.10333060446211872,
        "accuracy": 0.5528169014084507,
        "precision": 0.578125,
        "recall": 0.27007299270072993,
        "f1_score": 0.3681592039800995,
        "balanced_accuracy": 0.5431997616564874,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "154",
        "agreement_percentage": 54.22535211267606,
        "mcc": 0.07817255091646384,
        "accuracy": 0.5422535211267606,
        "precision": 0.5555555555555556,
        "recall": 0.25547445255474455,
        "f1_score": 0.35000000000000003,
        "balanced_accuracy": 0.532499131039277,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "158",
        "agreement_percentage": 55.633802816901415,
        "mcc": 0.11745538365847347,
        "accuracy": 0.5563380281690141,
        "precision": 0.6078431372549019,
        "recall": 0.22627737226277372,
        "f1_score": 0.32978723404255317,
        "balanced_accuracy": 0.5451114752470331,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}