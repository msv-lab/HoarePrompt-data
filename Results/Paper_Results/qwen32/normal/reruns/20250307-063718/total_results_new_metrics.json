{
    "total_valid_rows": {
        "value": 139,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "74",
        "agreement_percentage": 53.23741007194245,
        "mcc": 0.05697971488846494,
        "accuracy": 0.5323741007194245,
        "precision": 0.52,
        "recall": 0.3880597014925373,
        "f1_score": 0.4444444444444445,
        "balanced_accuracy": 0.527363184079602,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "78",
        "agreement_percentage": 56.11510791366906,
        "mcc": 0.12096673519824604,
        "accuracy": 0.5611510791366906,
        "precision": 0.5882352941176471,
        "recall": 0.29850746268656714,
        "f1_score": 0.396039603960396,
        "balanced_accuracy": 0.5520315091210614,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "70",
        "agreement_percentage": 50.35971223021583,
        "mcc": 0.016207751981503087,
        "accuracy": 0.5035971223021583,
        "precision": 0.4883720930232558,
        "recall": 0.6268656716417911,
        "f1_score": 0.5490196078431372,
        "balanced_accuracy": 0.50787728026534,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "81",
        "agreement_percentage": 58.27338129496403,
        "mcc": 0.17211036071354946,
        "accuracy": 0.5827338129496403,
        "precision": 0.5569620253164557,
        "recall": 0.6567164179104478,
        "f1_score": 0.6027397260273972,
        "balanced_accuracy": 0.5853026533996684,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "78",
        "agreement_percentage": 56.11510791366906,
        "mcc": 0.12163283265795888,
        "accuracy": 0.5611510791366906,
        "precision": 0.5441176470588235,
        "recall": 0.5522388059701493,
        "f1_score": 0.5481481481481482,
        "balanced_accuracy": 0.5608416252072969,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "77",
        "agreement_percentage": 55.39568345323741,
        "mcc": 0.10380897803157796,
        "accuracy": 0.5539568345323741,
        "precision": 0.5714285714285714,
        "recall": 0.29850746268656714,
        "f1_score": 0.392156862745098,
        "balanced_accuracy": 0.5450870646766168,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "68",
        "agreement_percentage": 48.92086330935252,
        "mcc": -0.01930664276449966,
        "accuracy": 0.4892086330935252,
        "precision": 0.47297297297297297,
        "recall": 0.5223880597014925,
        "f1_score": 0.4964539007092198,
        "balanced_accuracy": 0.4903606965174129,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "77",
        "agreement_percentage": 55.39568345323741,
        "mcc": 0.10507772408617913,
        "accuracy": 0.5539568345323741,
        "precision": 0.5396825396825397,
        "recall": 0.5074626865671642,
        "f1_score": 0.5230769230769231,
        "balanced_accuracy": 0.5523424543946932,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "74",
        "agreement_percentage": 53.23741007194245,
        "mcc": 0.06213651906170463,
        "accuracy": 0.5323741007194245,
        "precision": 0.515625,
        "recall": 0.4925373134328358,
        "f1_score": 0.5038167938931298,
        "balanced_accuracy": 0.5309908789386402,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "83",
        "agreement_percentage": 59.71223021582733,
        "mcc": 0.1911261842741691,
        "accuracy": 0.5971223021582733,
        "precision": 0.5932203389830508,
        "recall": 0.5223880597014925,
        "f1_score": 0.5555555555555555,
        "balanced_accuracy": 0.5945273631840795,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "78",
        "agreement_percentage": 56.11510791366906,
        "mcc": 0.11710827735326762,
        "accuracy": 0.5611510791366906,
        "precision": 0.5652173913043478,
        "recall": 0.3880597014925373,
        "f1_score": 0.46017699115044247,
        "balanced_accuracy": 0.5551409618573797,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "74",
        "agreement_percentage": 53.23741007194245,
        "mcc": 0.0559125985859586,
        "accuracy": 0.5323741007194245,
        "precision": 0.5217391304347826,
        "recall": 0.3582089552238806,
        "f1_score": 0.4247787610619469,
        "balanced_accuracy": 0.5263266998341625,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "81",
        "agreement_percentage": 58.27338129496403,
        "mcc": 0.16268305582247883,
        "accuracy": 0.5827338129496403,
        "precision": 0.5957446808510638,
        "recall": 0.417910447761194,
        "f1_score": 0.4912280701754387,
        "balanced_accuracy": 0.5770107794361525,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}