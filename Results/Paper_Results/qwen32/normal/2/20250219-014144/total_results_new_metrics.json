{
    "total_valid_rows": {
        "value": 79,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "45",
        "agreement_percentage": 56.9620253164557,
        "mcc": 0.0928840728025648,
        "accuracy": 0.569620253164557,
        "precision": 0.5,
        "recall": 0.35294117647058826,
        "f1_score": 0.41379310344827586,
        "balanced_accuracy": 0.5431372549019607,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "44",
        "agreement_percentage": 55.69620253164557,
        "mcc": 0.04252337623601464,
        "accuracy": 0.5569620253164557,
        "precision": 0.47058823529411764,
        "recall": 0.23529411764705882,
        "f1_score": 0.3137254901960785,
        "balanced_accuracy": 0.5176470588235295,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "46",
        "agreement_percentage": 58.22784810126582,
        "mcc": 0.1575923206924179,
        "accuracy": 0.5822784810126582,
        "precision": 0.5135135135135135,
        "recall": 0.5588235294117647,
        "f1_score": 0.5352112676056339,
        "balanced_accuracy": 0.5794117647058823,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "52",
        "agreement_percentage": 65.82278481012658,
        "mcc": 0.34248366013071896,
        "accuracy": 0.6582278481012658,
        "precision": 0.5777777777777777,
        "recall": 0.7647058823529411,
        "f1_score": 0.6582278481012658,
        "balanced_accuracy": 0.6712418300653594,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "46",
        "agreement_percentage": 58.22784810126582,
        "mcc": 0.1511408669655268,
        "accuracy": 0.5822784810126582,
        "precision": 0.5142857142857142,
        "recall": 0.5294117647058824,
        "f1_score": 0.5217391304347826,
        "balanced_accuracy": 0.5758169934640522,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "42",
        "agreement_percentage": 53.16455696202531,
        "mcc": -0.010600586509899276,
        "accuracy": 0.5316455696202531,
        "precision": 0.42105263157894735,
        "recall": 0.23529411764705882,
        "f1_score": 0.3018867924528302,
        "balanced_accuracy": 0.4954248366013072,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "43",
        "agreement_percentage": 54.43037974683544,
        "mcc": 0.06394433875790016,
        "accuracy": 0.5443037974683544,
        "precision": 0.46875,
        "recall": 0.4411764705882353,
        "f1_score": 0.45454545454545453,
        "balanced_accuracy": 0.5316993464052288,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "45",
        "agreement_percentage": 56.9620253164557,
        "mcc": 0.11002200660220077,
        "accuracy": 0.569620253164557,
        "precision": 0.5,
        "recall": 0.4411764705882353,
        "f1_score": 0.46875,
        "balanced_accuracy": 0.553921568627451,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "49",
        "agreement_percentage": 62.0253164556962,
        "mcc": 0.21537641292430817,
        "accuracy": 0.620253164556962,
        "precision": 0.5666666666666667,
        "recall": 0.5,
        "f1_score": 0.53125,
        "balanced_accuracy": 0.6055555555555556,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "48",
        "agreement_percentage": 60.75949367088608,
        "mcc": 0.1866444495616596,
        "accuracy": 0.6075949367088608,
        "precision": 0.5517241379310345,
        "recall": 0.47058823529411764,
        "f1_score": 0.507936507936508,
        "balanced_accuracy": 0.5908496732026144,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "51",
        "agreement_percentage": 64.55696202531645,
        "mcc": 0.26170575463335727,
        "accuracy": 0.6455696202531646,
        "precision": 0.6153846153846154,
        "recall": 0.47058823529411764,
        "f1_score": 0.5333333333333333,
        "balanced_accuracy": 0.6241830065359477,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "51",
        "agreement_percentage": 64.55696202531645,
        "mcc": 0.26170575463335727,
        "accuracy": 0.6455696202531646,
        "precision": 0.6153846153846154,
        "recall": 0.47058823529411764,
        "f1_score": 0.5333333333333333,
        "balanced_accuracy": 0.6241830065359477,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "48",
        "agreement_percentage": 60.75949367088608,
        "mcc": 0.17452692522120136,
        "accuracy": 0.6075949367088608,
        "precision": 0.5652173913043478,
        "recall": 0.38235294117647056,
        "f1_score": 0.45614035087719296,
        "balanced_accuracy": 0.5800653594771241,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}