{
    "total_valid_rows": {
        "value": 126,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "63",
        "agreement_percentage": 50.0,
        "mcc": 0.023736970495661876,
        "accuracy": 0.5,
        "precision": 0.6551724137931034,
        "recall": 0.4691358024691358,
        "f1_score": 0.5467625899280575,
        "balanced_accuracy": 0.5123456790123457,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "55",
        "agreement_percentage": 43.65079365079365,
        "mcc": 0.027777777777777776,
        "accuracy": 0.4365079365079365,
        "precision": 0.6666666666666666,
        "recall": 0.24691358024691357,
        "f1_score": 0.36036036036036034,
        "balanced_accuracy": 0.5123456790123457,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "69",
        "agreement_percentage": 54.761904761904766,
        "mcc": -0.04264620140048009,
        "accuracy": 0.5476190476190477,
        "precision": 0.6304347826086957,
        "recall": 0.7160493827160493,
        "f1_score": 0.6705202312138728,
        "balanced_accuracy": 0.4802469135802469,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "67",
        "agreement_percentage": 53.17460317460318,
        "mcc": -0.07996162762590016,
        "accuracy": 0.5317460317460317,
        "precision": 0.6195652173913043,
        "recall": 0.7037037037037037,
        "f1_score": 0.6589595375722543,
        "balanced_accuracy": 0.46296296296296297,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "60",
        "agreement_percentage": 47.61904761904761,
        "mcc": -0.07844146747076898,
        "accuracy": 0.47619047619047616,
        "precision": 0.6086956521739131,
        "recall": 0.5185185185185185,
        "f1_score": 0.5599999999999999,
        "balanced_accuracy": 0.45925925925925926,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "48",
        "agreement_percentage": 38.095238095238095,
        "mcc": -0.09514987095307503,
        "accuracy": 0.38095238095238093,
        "precision": 0.5555555555555556,
        "recall": 0.18518518518518517,
        "f1_score": 0.2777777777777778,
        "balanced_accuracy": 0.45925925925925926,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "79",
        "agreement_percentage": 62.698412698412696,
        "mcc": 0.18365053523845976,
        "accuracy": 0.626984126984127,
        "precision": 0.7073170731707317,
        "recall": 0.7160493827160493,
        "f1_score": 0.7116564417177914,
        "balanced_accuracy": 0.591358024691358,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "62",
        "agreement_percentage": 49.2063492063492,
        "mcc": -0.01656346649999844,
        "accuracy": 0.49206349206349204,
        "precision": 0.6349206349206349,
        "recall": 0.49382716049382713,
        "f1_score": 0.5555555555555555,
        "balanced_accuracy": 0.49135802469135803,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "57",
        "agreement_percentage": 45.23809523809524,
        "mcc": -0.06666666666666667,
        "accuracy": 0.4523809523809524,
        "precision": 0.6071428571428571,
        "recall": 0.41975308641975306,
        "f1_score": 0.4963503649635036,
        "balanced_accuracy": 0.46543209876543207,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "58",
        "agreement_percentage": 46.03174603174603,
        "mcc": -0.07338948517027162,
        "accuracy": 0.4603174603174603,
        "precision": 0.6065573770491803,
        "recall": 0.4567901234567901,
        "f1_score": 0.5211267605633803,
        "balanced_accuracy": 0.46172839506172836,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "67",
        "agreement_percentage": 53.17460317460318,
        "mcc": 0.1305857250198021,
        "accuracy": 0.5317460317460317,
        "precision": 0.72,
        "recall": 0.4444444444444444,
        "f1_score": 0.5496183206106869,
        "balanced_accuracy": 0.5666666666666667,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "61",
        "agreement_percentage": 48.41269841269841,
        "mcc": 0.04914731871829904,
        "accuracy": 0.48412698412698413,
        "precision": 0.6739130434782609,
        "recall": 0.38271604938271603,
        "f1_score": 0.4881889763779527,
        "balanced_accuracy": 0.5246913580246914,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "60",
        "agreement_percentage": 47.61904761904761,
        "mcc": 0.04741044919311832,
        "accuracy": 0.47619047619047616,
        "precision": 0.6744186046511628,
        "recall": 0.35802469135802467,
        "f1_score": 0.46774193548387094,
        "balanced_accuracy": 0.5234567901234568,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}