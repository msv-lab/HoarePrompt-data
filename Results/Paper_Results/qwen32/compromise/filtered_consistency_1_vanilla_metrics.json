{
    "total_valid_rows": {
        "value": 333,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "178",
        "agreement_percentage": 53.453453453453456,
        "mcc": 0.07576653523221229,
        "accuracy": 0.5345345345345346,
        "precision": 0.6503067484662577,
        "recall": 0.5196078431372549,
        "f1_score": 0.5776566757493188,
        "balanced_accuracy": 0.5388736890104879,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "141",
        "agreement_percentage": 42.34234234234234,
        "mcc": -0.07075321884979688,
        "accuracy": 0.42342342342342343,
        "precision": 0.56,
        "recall": 0.27450980392156865,
        "f1_score": 0.368421052631579,
        "balanced_accuracy": 0.46671226630186957,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "183",
        "agreement_percentage": 54.95495495495496,
        "mcc": -0.019804321448237037,
        "accuracy": 0.5495495495495496,
        "precision": 0.6071428571428571,
        "recall": 0.75,
        "f1_score": 0.6710526315789472,
        "balanced_accuracy": 0.49127906976744184,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "194",
        "agreement_percentage": 58.25825825825825,
        "mcc": 0.07649624689903606,
        "accuracy": 0.5825825825825826,
        "precision": 0.6359832635983264,
        "recall": 0.7450980392156863,
        "f1_score": 0.6862302483069977,
        "balanced_accuracy": 0.5353397172822618,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "167",
        "agreement_percentage": 50.150150150150154,
        "mcc": -0.03848374919298792,
        "accuracy": 0.5015015015015015,
        "precision": 0.5969387755102041,
        "recall": 0.5735294117647058,
        "f1_score": 0.5850000000000001,
        "balanced_accuracy": 0.48056315549475603,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "139",
        "agreement_percentage": 41.74174174174174,
        "mcc": -0.07389683647292822,
        "accuracy": 0.4174174174174174,
        "precision": 0.5543478260869565,
        "recall": 0.25,
        "f1_score": 0.34459459459459457,
        "balanced_accuracy": 0.46608527131782945,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "203",
        "agreement_percentage": 60.96096096096096,
        "mcc": 0.1436161454467581,
        "accuracy": 0.6096096096096096,
        "precision": 0.6581196581196581,
        "recall": 0.7549019607843137,
        "f1_score": 0.7031963470319635,
        "balanced_accuracy": 0.5673734610123119,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "172",
        "agreement_percentage": 51.651651651651655,
        "mcc": 0.016596278282317658,
        "accuracy": 0.5165165165165165,
        "precision": 0.6201117318435754,
        "recall": 0.5441176470588235,
        "f1_score": 0.5796344647519581,
        "balanced_accuracy": 0.5084929320565436,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "159",
        "agreement_percentage": 47.74774774774775,
        "mcc": -0.034476680313556315,
        "accuracy": 0.4774774774774775,
        "precision": 0.5949367088607594,
        "recall": 0.46078431372549017,
        "f1_score": 0.5193370165745855,
        "balanced_accuracy": 0.4823301413588691,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "161",
        "agreement_percentage": 48.348348348348345,
        "mcc": -0.01936473828153626,
        "accuracy": 0.48348348348348347,
        "precision": 0.6025641025641025,
        "recall": 0.46078431372549017,
        "f1_score": 0.5222222222222221,
        "balanced_accuracy": 0.49008207934336523,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "162",
        "agreement_percentage": 48.64864864864865,
        "mcc": 0.004936500361282701,
        "accuracy": 0.4864864864864865,
        "precision": 0.6153846153846154,
        "recall": 0.43137254901960786,
        "f1_score": 0.5072046109510087,
        "balanced_accuracy": 0.5025079799361605,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "170",
        "agreement_percentage": 51.051051051051054,
        "mcc": 0.06651033917413796,
        "accuracy": 0.5105105105105106,
        "precision": 0.6518518518518519,
        "recall": 0.43137254901960786,
        "f1_score": 0.5191740412979351,
        "balanced_accuracy": 0.533515731874145,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "150",
        "agreement_percentage": 45.04504504504504,
        "mcc": -0.04824899772156687,
        "accuracy": 0.45045045045045046,
        "precision": 0.5826771653543307,
        "recall": 0.3627450980392157,
        "f1_score": 0.4471299093655589,
        "balanced_accuracy": 0.47594619243046055,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}