{
    "total_valid_rows": {
        "value": 1636,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "937",
        "agreement_percentage": 57.27383863080685,
        "mcc": 0.1583439737718782,
        "accuracy": 0.5727383863080685,
        "precision": 0.6202020202020202,
        "recall": 0.3753056234718826,
        "f1_score": 0.46763137852246767,
        "balanced_accuracy": 0.5727383863080685,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "893",
        "agreement_percentage": 54.584352078239604,
        "mcc": 0.12154538002487762,
        "accuracy": 0.5458435207823961,
        "precision": 0.6334519572953736,
        "recall": 0.2176039119804401,
        "f1_score": 0.3239308462238399,
        "balanced_accuracy": 0.5458435207823961,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "956",
        "agreement_percentage": 58.43520782396088,
        "mcc": 0.16878943999509002,
        "accuracy": 0.5843520782396088,
        "precision": 0.5871212121212122,
        "recall": 0.5684596577017115,
        "f1_score": 0.5776397515527951,
        "balanced_accuracy": 0.5843520782396088,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "975",
        "agreement_percentage": 59.59657701711492,
        "mcc": 0.19233568003567955,
        "accuracy": 0.5959657701711492,
        "precision": 0.6026143790849673,
        "recall": 0.5635696821515892,
        "f1_score": 0.5824384080859127,
        "balanced_accuracy": 0.5959657701711492,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "923",
        "agreement_percentage": 56.41809290953545,
        "mcc": 0.13313182583435543,
        "accuracy": 0.5641809290953546,
        "precision": 0.5873544093178037,
        "recall": 0.4315403422982885,
        "f1_score": 0.49753347427766037,
        "balanced_accuracy": 0.5641809290953546,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "898",
        "agreement_percentage": 54.88997555012225,
        "mcc": 0.12669334370301502,
        "accuracy": 0.5488997555012225,
        "precision": 0.6342281879194631,
        "recall": 0.2310513447432763,
        "f1_score": 0.33870967741935487,
        "balanced_accuracy": 0.5488997555012225,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "975",
        "agreement_percentage": 59.59657701711492,
        "mcc": 0.19329537957360587,
        "accuracy": 0.5959657701711492,
        "precision": 0.608876560332871,
        "recall": 0.5366748166259169,
        "f1_score": 0.5705003248862898,
        "balanced_accuracy": 0.5959657701711492,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "940",
        "agreement_percentage": 57.457212713936435,
        "mcc": 0.15799927849567044,
        "accuracy": 0.5745721271393643,
        "precision": 0.6113138686131386,
        "recall": 0.4095354523227384,
        "f1_score": 0.4904831625183016,
        "balanced_accuracy": 0.5745721271393643,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "919",
        "agreement_percentage": 56.173594132029336,
        "mcc": 0.13306774984699415,
        "accuracy": 0.5617359413202934,
        "precision": 0.5984405458089669,
        "recall": 0.3753056234718826,
        "f1_score": 0.4613072877535687,
        "balanced_accuracy": 0.5617359413202934,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "929",
        "agreement_percentage": 56.784841075794624,
        "mcc": 0.14753087641830182,
        "accuracy": 0.5678484107579462,
        "precision": 0.6116700201207244,
        "recall": 0.37163814180929094,
        "f1_score": 0.46235741444866923,
        "balanced_accuracy": 0.5678484107579462,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "934",
        "agreement_percentage": 57.090464547677264,
        "mcc": 0.16084326202959942,
        "accuracy": 0.5709046454767727,
        "precision": 0.6342592592592593,
        "recall": 0.33496332518337407,
        "f1_score": 0.43839999999999996,
        "balanced_accuracy": 0.5709046454767727,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "932",
        "agreement_percentage": 56.96821515892421,
        "mcc": 0.15878422974111842,
        "accuracy": 0.5696821515892421,
        "precision": 0.6338028169014085,
        "recall": 0.33007334963325186,
        "f1_score": 0.4340836012861736,
        "balanced_accuracy": 0.5696821515892421,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "911",
        "agreement_percentage": 55.68459657701712,
        "mcc": 0.13376615594021485,
        "accuracy": 0.5568459657701712,
        "precision": 0.6201550387596899,
        "recall": 0.293398533007335,
        "f1_score": 0.39834024896265563,
        "balanced_accuracy": 0.5568459657701712,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}