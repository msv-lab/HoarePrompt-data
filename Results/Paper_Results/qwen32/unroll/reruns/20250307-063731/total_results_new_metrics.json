{
    "total_valid_rows": {
        "value": 269,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "159",
        "agreement_percentage": 59.10780669144982,
        "mcc": 0.1796830949509731,
        "accuracy": 0.5910780669144982,
        "precision": 0.6,
        "recall": 0.46153846153846156,
        "f1_score": 0.5217391304347826,
        "balanced_accuracy": 0.5868843386828999,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "144",
        "agreement_percentage": 53.53159851301115,
        "mcc": 0.06660710446158433,
        "accuracy": 0.5353159851301115,
        "precision": 0.5641025641025641,
        "recall": 0.16923076923076924,
        "f1_score": 0.2603550295857988,
        "balanced_accuracy": 0.5234643054786939,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "163",
        "agreement_percentage": 60.594795539033456,
        "mcc": 0.21491584690453086,
        "accuracy": 0.6059479553903345,
        "precision": 0.5833333333333334,
        "recall": 0.6461538461538462,
        "f1_score": 0.6131386861313869,
        "balanced_accuracy": 0.6072495849474266,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "152",
        "agreement_percentage": 56.50557620817844,
        "mcc": 0.13320429860534275,
        "accuracy": 0.5650557620817844,
        "precision": 0.5448275862068965,
        "recall": 0.6076923076923076,
        "f1_score": 0.5745454545454545,
        "balanced_accuracy": 0.5664360819037078,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "143",
        "agreement_percentage": 53.159851301115246,
        "mcc": 0.0599730211916117,
        "accuracy": 0.5315985130111525,
        "precision": 0.5166666666666667,
        "recall": 0.47692307692307695,
        "f1_score": 0.4960000000000001,
        "balanced_accuracy": 0.5298284449363586,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "150",
        "agreement_percentage": 55.762081784386616,
        "mcc": 0.13216178635245884,
        "accuracy": 0.5576208178438662,
        "precision": 0.6486486486486487,
        "recall": 0.18461538461538463,
        "f1_score": 0.2874251497005988,
        "balanced_accuracy": 0.5455451023796347,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "158",
        "agreement_percentage": 58.7360594795539,
        "mcc": 0.17445657341733967,
        "accuracy": 0.587360594795539,
        "precision": 0.5714285714285714,
        "recall": 0.5846153846153846,
        "f1_score": 0.5779467680608366,
        "balanced_accuracy": 0.5872717210846707,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "146",
        "agreement_percentage": 54.27509293680297,
        "mcc": 0.08189026084130341,
        "accuracy": 0.5427509293680297,
        "precision": 0.5299145299145299,
        "recall": 0.47692307692307695,
        "f1_score": 0.5020242914979758,
        "balanced_accuracy": 0.5406198118428335,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "143",
        "agreement_percentage": 53.159851301115246,
        "mcc": 0.05810671723889978,
        "accuracy": 0.5315985130111525,
        "precision": 0.5181818181818182,
        "recall": 0.43846153846153846,
        "f1_score": 0.47500000000000003,
        "balanced_accuracy": 0.5285832872163807,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "135",
        "agreement_percentage": 50.18587360594795,
        "mcc": -0.004502872951836099,
        "accuracy": 0.5018587360594795,
        "precision": 0.4803921568627451,
        "recall": 0.3769230769230769,
        "f1_score": 0.42241379310344823,
        "balanced_accuracy": 0.49781405644715,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "153",
        "agreement_percentage": 56.877323420074354,
        "mcc": 0.13410012220747036,
        "accuracy": 0.5687732342007435,
        "precision": 0.5777777777777777,
        "recall": 0.4,
        "f1_score": 0.4727272727272727,
        "balanced_accuracy": 0.5633093525179856,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "153",
        "agreement_percentage": 56.877323420074354,
        "mcc": 0.1346083529841689,
        "accuracy": 0.5687732342007435,
        "precision": 0.5813953488372093,
        "recall": 0.38461538461538464,
        "f1_score": 0.46296296296296297,
        "balanced_accuracy": 0.5628112894299945,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "152",
        "agreement_percentage": 56.50557620817844,
        "mcc": 0.12864820505197583,
        "accuracy": 0.5650557620817844,
        "precision": 0.5866666666666667,
        "recall": 0.3384615384615385,
        "f1_score": 0.4292682926829268,
        "balanced_accuracy": 0.5577199778638628,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}