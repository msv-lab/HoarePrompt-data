{
    "total_valid_rows": {
        "value": 23,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "8",
        "agreement_percentage": 34.78260869565217,
        "mcc": -0.31298621848313535,
        "accuracy": 0.34782608695652173,
        "precision": 0.38461538461538464,
        "recall": 0.4166666666666667,
        "f1_score": 0.4,
        "balanced_accuracy": 0.3446969696969697,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "7",
        "agreement_percentage": 30.434782608695656,
        "mcc": -0.38932432055219274,
        "accuracy": 0.30434782608695654,
        "precision": 0.3,
        "recall": 0.25,
        "f1_score": 0.2727272727272727,
        "balanced_accuracy": 0.3068181818181818,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "8",
        "agreement_percentage": 34.78260869565217,
        "mcc": -0.3337119062359573,
        "accuracy": 0.34782608695652173,
        "precision": 0.4,
        "recall": 0.5,
        "f1_score": 0.4444444444444445,
        "balanced_accuracy": 0.34090909090909094,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "11",
        "agreement_percentage": 47.82608695652174,
        "mcc": -0.11236664374387369,
        "accuracy": 0.4782608695652174,
        "precision": 0.5,
        "recall": 0.8333333333333334,
        "f1_score": 0.625,
        "balanced_accuracy": 0.46212121212121215,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "10",
        "agreement_percentage": 43.47826086956522,
        "mcc": -0.20966480425560383,
        "accuracy": 0.43478260869565216,
        "precision": 0.47368421052631576,
        "recall": 0.75,
        "f1_score": 0.5806451612903226,
        "balanced_accuracy": 0.42045454545454547,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "8",
        "agreement_percentage": 34.78260869565217,
        "mcc": -0.302407368379503,
        "accuracy": 0.34782608695652173,
        "precision": 0.3333333333333333,
        "recall": 0.25,
        "f1_score": 0.28571428571428575,
        "balanced_accuracy": 0.3522727272727273,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "9",
        "agreement_percentage": 39.130434782608695,
        "mcc": -0.2935903373670295,
        "accuracy": 0.391304347826087,
        "precision": 0.4444444444444444,
        "recall": 0.6666666666666666,
        "f1_score": 0.5333333333333333,
        "balanced_accuracy": 0.3787878787878788,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "9",
        "agreement_percentage": 39.130434782608695,
        "mcc": -0.2935903373670295,
        "accuracy": 0.391304347826087,
        "precision": 0.4444444444444444,
        "recall": 0.6666666666666666,
        "f1_score": 0.5333333333333333,
        "balanced_accuracy": 0.3787878787878788,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "11",
        "agreement_percentage": 47.82608695652174,
        "mcc": -0.0657951694959769,
        "accuracy": 0.4782608695652174,
        "precision": 0.5,
        "recall": 0.6666666666666666,
        "f1_score": 0.5714285714285715,
        "balanced_accuracy": 0.46969696969696967,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "11",
        "agreement_percentage": 47.82608695652174,
        "mcc": -0.0657951694959769,
        "accuracy": 0.4782608695652174,
        "precision": 0.5,
        "recall": 0.6666666666666666,
        "f1_score": 0.5714285714285715,
        "balanced_accuracy": 0.46969696969696967,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "10",
        "agreement_percentage": 43.47826086956522,
        "mcc": -0.15096490996388545,
        "accuracy": 0.43478260869565216,
        "precision": 0.4666666666666667,
        "recall": 0.5833333333333334,
        "f1_score": 0.5185185185185186,
        "balanced_accuracy": 0.42803030303030304,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "9",
        "agreement_percentage": 39.130434782608695,
        "mcc": -0.2326210525996177,
        "accuracy": 0.391304347826087,
        "precision": 0.42857142857142855,
        "recall": 0.5,
        "f1_score": 0.4615384615384615,
        "balanced_accuracy": 0.38636363636363635,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "7",
        "agreement_percentage": 30.434782608695656,
        "mcc": -0.38932432055219274,
        "accuracy": 0.30434782608695654,
        "precision": 0.3,
        "recall": 0.25,
        "f1_score": 0.2727272727272727,
        "balanced_accuracy": 0.3068181818181818,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}