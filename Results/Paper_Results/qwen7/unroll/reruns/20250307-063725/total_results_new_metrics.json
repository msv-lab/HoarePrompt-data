{
    "total_valid_rows": {
        "value": 243,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "133",
        "agreement_percentage": 54.73251028806584,
        "mcc": 0.11611743720274666,
        "accuracy": 0.5473251028806584,
        "precision": 0.8333333333333334,
        "recall": 0.043859649122807015,
        "f1_score": 0.08333333333333333,
        "balanced_accuracy": 0.5180538555691554,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "134",
        "agreement_percentage": 55.144032921810705,
        "mcc": 0.10152480466745517,
        "accuracy": 0.551440329218107,
        "precision": 0.6666666666666666,
        "recall": 0.08771929824561403,
        "f1_score": 0.15503875968992248,
        "balanced_accuracy": 0.5244798041615667,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "131",
        "agreement_percentage": 53.90946502057613,
        "mcc": 0.10853160955894302,
        "accuracy": 0.5390946502057613,
        "precision": 0.5060240963855421,
        "recall": 0.7368421052631579,
        "f1_score": 0.6,
        "balanced_accuracy": 0.5505915952672378,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "126",
        "agreement_percentage": 51.85185185185185,
        "mcc": 0.061958545122116675,
        "accuracy": 0.5185185185185185,
        "precision": 0.49079754601226994,
        "recall": 0.7017543859649122,
        "f1_score": 0.5776173285198555,
        "balanced_accuracy": 0.529171766625867,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "137",
        "agreement_percentage": 56.37860082304527,
        "mcc": 0.14322898054808822,
        "accuracy": 0.5637860082304527,
        "precision": 0.5273972602739726,
        "recall": 0.6754385964912281,
        "f1_score": 0.5923076923076923,
        "balanced_accuracy": 0.5702774377804978,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "131",
        "agreement_percentage": 53.90946502057613,
        "mcc": 0.048277874693905445,
        "accuracy": 0.5390946502057613,
        "precision": 0.5333333333333333,
        "recall": 0.14035087719298245,
        "f1_score": 0.22222222222222224,
        "balanced_accuracy": 0.5159118727050184,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "129",
        "agreement_percentage": 53.086419753086425,
        "mcc": 0.07587602017424122,
        "accuracy": 0.5308641975308642,
        "precision": 0.5,
        "recall": 0.6403508771929824,
        "f1_score": 0.5615384615384615,
        "balanced_accuracy": 0.5372297021623826,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "134",
        "agreement_percentage": 55.144032921810705,
        "mcc": 0.08643142293504534,
        "accuracy": 0.551440329218107,
        "precision": 0.5324675324675324,
        "recall": 0.35964912280701755,
        "f1_score": 0.4293193717277487,
        "balanced_accuracy": 0.5402896776825785,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "128",
        "agreement_percentage": 52.674897119341566,
        "mcc": 0.03933445075601232,
        "accuracy": 0.5267489711934157,
        "precision": 0.4945054945054945,
        "recall": 0.39473684210526316,
        "f1_score": 0.43902439024390244,
        "balanced_accuracy": 0.5190738474092207,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "129",
        "agreement_percentage": 53.086419753086425,
        "mcc": 0.04743397516700449,
        "accuracy": 0.5308641975308642,
        "precision": 0.5,
        "recall": 0.39473684210526316,
        "f1_score": 0.4411764705882353,
        "balanced_accuracy": 0.5229498164014688,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "134",
        "agreement_percentage": 55.144032921810705,
        "mcc": 0.09179816290537114,
        "accuracy": 0.551440329218107,
        "precision": 0.5263157894736842,
        "recall": 0.43859649122807015,
        "f1_score": 0.4784688995215311,
        "balanced_accuracy": 0.5448796409628723,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "134",
        "agreement_percentage": 55.144032921810705,
        "mcc": 0.08918695545493606,
        "accuracy": 0.551440329218107,
        "precision": 0.5287356321839081,
        "recall": 0.40350877192982454,
        "f1_score": 0.4577114427860697,
        "balanced_accuracy": 0.5428396572827417,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "131",
        "agreement_percentage": 53.90946502057613,
        "mcc": 0.06931123050422339,
        "accuracy": 0.5390946502057613,
        "precision": 0.5098039215686274,
        "recall": 0.45614035087719296,
        "f1_score": 0.48148148148148145,
        "balanced_accuracy": 0.5342717258261933,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}