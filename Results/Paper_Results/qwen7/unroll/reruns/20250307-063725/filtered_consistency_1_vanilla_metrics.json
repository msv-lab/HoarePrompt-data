{
    "total_valid_rows": {
        "value": 41,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "19",
        "agreement_percentage": 46.34146341463415,
        "mcc": 0,
        "accuracy": 0.4634146341463415,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "19",
        "agreement_percentage": 46.34146341463415,
        "mcc": 0,
        "accuracy": 0.4634146341463415,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "23",
        "agreement_percentage": 56.09756097560976,
        "mcc": 0.09828450945679937,
        "accuracy": 0.5609756097560976,
        "precision": 0.5588235294117647,
        "recall": 0.8636363636363636,
        "f1_score": 0.6785714285714287,
        "balanced_accuracy": 0.5370813397129186,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "22",
        "agreement_percentage": 53.65853658536586,
        "mcc": 0.03612360973813756,
        "accuracy": 0.5365853658536586,
        "precision": 0.5454545454545454,
        "recall": 0.8181818181818182,
        "f1_score": 0.6545454545454545,
        "balanced_accuracy": 0.5143540669856459,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "21",
        "agreement_percentage": 51.21951219512195,
        "mcc": -0.020175005196093842,
        "accuracy": 0.5121951219512195,
        "precision": 0.53125,
        "recall": 0.7727272727272727,
        "f1_score": 0.6296296296296297,
        "balanced_accuracy": 0.4916267942583732,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "13",
        "agreement_percentage": 31.70731707317073,
        "mcc": -0.4455291691926621,
        "accuracy": 0.3170731707317073,
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.34210526315789475,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "19",
        "agreement_percentage": 46.34146341463415,
        "mcc": -0.12116227045072343,
        "accuracy": 0.4634146341463415,
        "precision": 0.5,
        "recall": 0.6818181818181818,
        "f1_score": 0.576923076923077,
        "balanced_accuracy": 0.4461722488038277,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "21",
        "agreement_percentage": 51.21951219512195,
        "mcc": 0.04157485898378407,
        "accuracy": 0.5121951219512195,
        "precision": 0.5625,
        "recall": 0.4090909090909091,
        "f1_score": 0.47368421052631576,
        "balanced_accuracy": 0.5203349282296651,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "17",
        "agreement_percentage": 41.46341463414634,
        "mcc": -0.16346342761154994,
        "accuracy": 0.4146341463414634,
        "precision": 0.4444444444444444,
        "recall": 0.36363636363636365,
        "f1_score": 0.39999999999999997,
        "balanced_accuracy": 0.41866028708133973,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "18",
        "agreement_percentage": 43.90243902439025,
        "mcc": -0.1064996084749822,
        "accuracy": 0.43902439024390244,
        "precision": 0.4666666666666667,
        "recall": 0.3181818181818182,
        "f1_score": 0.3783783783783784,
        "balanced_accuracy": 0.4485645933014354,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "13",
        "agreement_percentage": 31.70731707317073,
        "mcc": -0.36226673028138096,
        "accuracy": 0.3170731707317073,
        "precision": 0.2857142857142857,
        "recall": 0.18181818181818182,
        "f1_score": 0.2222222222222222,
        "balanced_accuracy": 0.3277511961722488,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "18",
        "agreement_percentage": 43.90243902439025,
        "mcc": -0.11138830857236433,
        "accuracy": 0.43902439024390244,
        "precision": 0.47058823529411764,
        "recall": 0.36363636363636365,
        "f1_score": 0.41025641025641024,
        "balanced_accuracy": 0.4449760765550239,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "16",
        "agreement_percentage": 39.02439024390244,
        "mcc": -0.21066919229990647,
        "accuracy": 0.3902439024390244,
        "precision": 0.4117647058823529,
        "recall": 0.3181818181818182,
        "f1_score": 0.358974358974359,
        "balanced_accuracy": 0.39593301435406697,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}