{
    "total_valid_rows": {
        "value": 102,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "49",
        "agreement_percentage": 48.03921568627451,
        "mcc": -0.04986897980417246,
        "accuracy": 0.4803921568627451,
        "precision": 0.4,
        "recall": 0.038461538461538464,
        "f1_score": 0.07017543859649124,
        "balanced_accuracy": 0.4892307692307692,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "50",
        "agreement_percentage": 49.01960784313725,
        "mcc": -0.004902903378454601,
        "accuracy": 0.49019607843137253,
        "precision": 0.5,
        "recall": 0.057692307692307696,
        "f1_score": 0.10344827586206896,
        "balanced_accuracy": 0.49884615384615383,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "52",
        "agreement_percentage": 50.98039215686274,
        "mcc": 0.014484136487558027,
        "accuracy": 0.5098039215686274,
        "precision": 0.5151515151515151,
        "recall": 0.6538461538461539,
        "f1_score": 0.576271186440678,
        "balanced_accuracy": 0.5069230769230769,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "58",
        "agreement_percentage": 56.86274509803921,
        "mcc": 0.13680122403979222,
        "accuracy": 0.5686274509803921,
        "precision": 0.5625,
        "recall": 0.6923076923076923,
        "f1_score": 0.6206896551724138,
        "balanced_accuracy": 0.5661538461538461,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "53",
        "agreement_percentage": 51.9607843137255,
        "mcc": 0.03922322702763681,
        "accuracy": 0.5196078431372549,
        "precision": 0.5294117647058824,
        "recall": 0.5192307692307693,
        "f1_score": 0.5242718446601942,
        "balanced_accuracy": 0.5196153846153846,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "49",
        "agreement_percentage": 48.03921568627451,
        "mcc": -0.034236839400873034,
        "accuracy": 0.4803921568627451,
        "precision": 0.47619047619047616,
        "recall": 0.19230769230769232,
        "f1_score": 0.273972602739726,
        "balanced_accuracy": 0.48615384615384616,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "50",
        "agreement_percentage": 49.01960784313725,
        "mcc": -0.020801257358446092,
        "accuracy": 0.49019607843137253,
        "precision": 0.5,
        "recall": 0.5192307692307693,
        "f1_score": 0.509433962264151,
        "balanced_accuracy": 0.4896153846153847,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "34",
        "agreement_percentage": 33.33333333333333,
        "mcc": -0.3328201177351375,
        "accuracy": 0.3333333333333333,
        "precision": 0.3333333333333333,
        "recall": 0.3076923076923077,
        "f1_score": 0.32,
        "balanced_accuracy": 0.33384615384615385,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "45",
        "agreement_percentage": 44.11764705882353,
        "mcc": -0.11699059097562219,
        "accuracy": 0.4411764705882353,
        "precision": 0.4489795918367347,
        "recall": 0.4230769230769231,
        "f1_score": 0.43564356435643564,
        "balanced_accuracy": 0.44153846153846155,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "46",
        "agreement_percentage": 45.09803921568628,
        "mcc": -0.09660072933362286,
        "accuracy": 0.45098039215686275,
        "precision": 0.45652173913043476,
        "recall": 0.40384615384615385,
        "f1_score": 0.4285714285714286,
        "balanced_accuracy": 0.4519230769230769,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "53",
        "agreement_percentage": 51.9607843137255,
        "mcc": 0.05285360104150326,
        "accuracy": 0.5196078431372549,
        "precision": 0.5517241379310345,
        "recall": 0.3076923076923077,
        "f1_score": 0.39506172839506176,
        "balanced_accuracy": 0.5238461538461539,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "50",
        "agreement_percentage": 49.01960784313725,
        "mcc": -0.013259870882635916,
        "accuracy": 0.49019607843137253,
        "precision": 0.5,
        "recall": 0.3076923076923077,
        "f1_score": 0.380952380952381,
        "balanced_accuracy": 0.4938461538461539,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "57",
        "agreement_percentage": 55.88235294117647,
        "mcc": 0.12581657766139803,
        "accuracy": 0.5588235294117647,
        "precision": 0.5897435897435898,
        "recall": 0.4423076923076923,
        "f1_score": 0.5054945054945056,
        "balanced_accuracy": 0.5611538461538461,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}