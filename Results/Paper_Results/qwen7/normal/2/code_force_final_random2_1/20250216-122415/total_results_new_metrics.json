{
    "total_valid_rows": {
        "value": 102,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "52",
        "agreement_percentage": 50.98039215686274,
        "mcc": 0.0970725343394151,
        "accuracy": 0.5098039215686274,
        "precision": 0.75,
        "recall": 0.057692307692307696,
        "f1_score": 0.10714285714285714,
        "balanced_accuracy": 0.5188461538461538,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "56",
        "agreement_percentage": 54.90196078431373,
        "mcc": 0.24514516892273003,
        "accuracy": 0.5490196078431373,
        "precision": 1.0,
        "recall": 0.11538461538461539,
        "f1_score": 0.20689655172413793,
        "balanced_accuracy": 0.5576923076923077,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "62",
        "agreement_percentage": 60.78431372549019,
        "mcc": 0.21659587187238546,
        "accuracy": 0.6078431372549019,
        "precision": 0.5967741935483871,
        "recall": 0.7115384615384616,
        "f1_score": 0.6491228070175439,
        "balanced_accuracy": 0.6057692307692308,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "65",
        "agreement_percentage": 63.725490196078425,
        "mcc": 0.27993282418232723,
        "accuracy": 0.6372549019607843,
        "precision": 0.6153846153846154,
        "recall": 0.7692307692307693,
        "f1_score": 0.6837606837606838,
        "balanced_accuracy": 0.6346153846153846,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "57",
        "agreement_percentage": 55.88235294117647,
        "mcc": 0.11649036210614801,
        "accuracy": 0.5588235294117647,
        "precision": 0.5636363636363636,
        "recall": 0.5961538461538461,
        "f1_score": 0.5794392523364486,
        "balanced_accuracy": 0.5580769230769231,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "57",
        "agreement_percentage": 55.88235294117647,
        "mcc": 0.1669222306095118,
        "accuracy": 0.5588235294117647,
        "precision": 0.6842105263157895,
        "recall": 0.25,
        "f1_score": 0.36619718309859156,
        "balanced_accuracy": 0.565,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "65",
        "agreement_percentage": 63.725490196078425,
        "mcc": 0.2738680698522023,
        "accuracy": 0.6372549019607843,
        "precision": 0.6363636363636364,
        "recall": 0.6730769230769231,
        "f1_score": 0.6542056074766355,
        "balanced_accuracy": 0.6365384615384615,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "55",
        "agreement_percentage": 53.92156862745098,
        "mcc": 0.08254465435755974,
        "accuracy": 0.5392156862745098,
        "precision": 0.5581395348837209,
        "recall": 0.46153846153846156,
        "f1_score": 0.5052631578947369,
        "balanced_accuracy": 0.5407692307692308,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "58",
        "agreement_percentage": 56.86274509803921,
        "mcc": 0.14714085143814862,
        "accuracy": 0.5686274509803921,
        "precision": 0.6052631578947368,
        "recall": 0.4423076923076923,
        "f1_score": 0.5111111111111111,
        "balanced_accuracy": 0.5711538461538461,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "67",
        "agreement_percentage": 65.68627450980392,
        "mcc": 0.3147970507172992,
        "accuracy": 0.6568627450980392,
        "precision": 0.673469387755102,
        "recall": 0.6346153846153846,
        "f1_score": 0.6534653465346534,
        "balanced_accuracy": 0.6573076923076924,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "61",
        "agreement_percentage": 59.80392156862745,
        "mcc": 0.22675899801677205,
        "accuracy": 0.5980392156862745,
        "precision": 0.6896551724137931,
        "recall": 0.38461538461538464,
        "f1_score": 0.4938271604938272,
        "balanced_accuracy": 0.6023076923076923,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "65",
        "agreement_percentage": 63.725490196078425,
        "mcc": 0.30683109125623664,
        "accuracy": 0.6372549019607843,
        "precision": 0.7419354838709677,
        "recall": 0.4423076923076923,
        "f1_score": 0.5542168674698795,
        "balanced_accuracy": 0.6411538461538462,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "68",
        "agreement_percentage": 66.66666666666666,
        "mcc": 0.37471356582095666,
        "accuracy": 0.6666666666666666,
        "precision": 0.8,
        "recall": 0.46153846153846156,
        "f1_score": 0.5853658536585367,
        "balanced_accuracy": 0.6707692307692308,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}