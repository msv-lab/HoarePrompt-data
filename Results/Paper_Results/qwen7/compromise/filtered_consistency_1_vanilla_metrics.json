{
    "total_valid_rows": {
        "value": 359,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "147",
        "agreement_percentage": 40.947075208913645,
        "mcc": 0.10485027696962272,
        "accuracy": 0.40947075208913647,
        "precision": 1.0,
        "recall": 0.027522935779816515,
        "f1_score": 0.05357142857142857,
        "balanced_accuracy": 0.5137614678899083,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "132",
        "agreement_percentage": 36.768802228412255,
        "mcc": -0.1641068898648283,
        "accuracy": 0.36768802228412256,
        "precision": 0.2857142857142857,
        "recall": 0.027522935779816515,
        "f1_score": 0.0502092050209205,
        "balanced_accuracy": 0.46056997852820614,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "214",
        "agreement_percentage": 59.610027855153206,
        "mcc": 0.09861602128770881,
        "accuracy": 0.596100278551532,
        "precision": 0.6346863468634686,
        "recall": 0.7889908256880734,
        "f1_score": 0.7034764826175869,
        "balanced_accuracy": 0.5434315830568026,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "205",
        "agreement_percentage": 57.10306406685237,
        "mcc": 0.03509482206828141,
        "accuracy": 0.5710306406685237,
        "precision": 0.6167883211678832,
        "recall": 0.7752293577981652,
        "f1_score": 0.6869918699186992,
        "balanced_accuracy": 0.5152742533671677,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "181",
        "agreement_percentage": 50.41782729805014,
        "mcc": -0.05546490009789744,
        "accuracy": 0.5041782729805014,
        "precision": 0.5869565217391305,
        "recall": 0.6192660550458715,
        "f1_score": 0.6026785714285715,
        "balanced_accuracy": 0.4727535948988223,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "138",
        "agreement_percentage": 38.440111420612816,
        "mcc": -0.13559148508823474,
        "accuracy": 0.38440111420612816,
        "precision": 0.4805194805194805,
        "recall": 0.16972477064220184,
        "f1_score": 0.25084745762711863,
        "balanced_accuracy": 0.44301841368989525,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "188",
        "agreement_percentage": 52.36768802228412,
        "mcc": -0.009984008249252647,
        "accuracy": 0.5236768802228412,
        "precision": 0.6035242290748899,
        "recall": 0.6284403669724771,
        "f1_score": 0.6157303370786517,
        "balanced_accuracy": 0.4950712473160258,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "175",
        "agreement_percentage": 48.74651810584958,
        "mcc": -0.03610614139618365,
        "accuracy": 0.48746518105849584,
        "precision": 0.5904255319148937,
        "recall": 0.5091743119266054,
        "f1_score": 0.5467980295566502,
        "balanced_accuracy": 0.4815375105732318,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "179",
        "agreement_percentage": 49.86072423398329,
        "mcc": -0.0010168640334975985,
        "accuracy": 0.4986072423398329,
        "precision": 0.6067415730337079,
        "recall": 0.4954128440366973,
        "f1_score": 0.5454545454545455,
        "balanced_accuracy": 0.4994794716637387,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "174",
        "agreement_percentage": 48.467966573816156,
        "mcc": -0.04058147653306542,
        "accuracy": 0.48467966573816157,
        "precision": 0.5882352941176471,
        "recall": 0.5045871559633027,
        "f1_score": 0.5432098765432098,
        "balanced_accuracy": 0.47924393259158043,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "170",
        "agreement_percentage": 47.353760445682454,
        "mcc": -0.0022567035745024305,
        "accuracy": 0.4735376044568245,
        "precision": 0.6058394160583942,
        "recall": 0.38073394495412843,
        "f1_score": 0.4676056338028169,
        "balanced_accuracy": 0.49887761077493653,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "171",
        "agreement_percentage": 47.63231197771588,
        "mcc": -0.0296304796078884,
        "accuracy": 0.4763231197771588,
        "precision": 0.5914634146341463,
        "recall": 0.44495412844036697,
        "f1_score": 0.5078534031413612,
        "balanced_accuracy": 0.48488841173791397,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "172",
        "agreement_percentage": 47.910863509749305,
        "mcc": -0.029984233197781197,
        "accuracy": 0.479108635097493,
        "precision": 0.591715976331361,
        "recall": 0.45871559633027525,
        "f1_score": 0.516795865633075,
        "balanced_accuracy": 0.4846769471013078,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}