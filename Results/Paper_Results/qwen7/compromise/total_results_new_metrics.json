{
    "total_valid_rows": {
        "value": 1719,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "885",
        "agreement_percentage": 51.48342059336824,
        "mcc": 0.0764018352465807,
        "accuracy": 0.5148342059336823,
        "precision": 0.7,
        "recall": 0.04895104895104895,
        "f1_score": 0.09150326797385622,
        "balanced_accuracy": 0.5140225628030506,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "889",
        "agreement_percentage": 51.716114019778935,
        "mcc": 0.07278706949736434,
        "accuracy": 0.5171611401977894,
        "precision": 0.6521739130434783,
        "recall": 0.06993006993006994,
        "f1_score": 0.12631578947368421,
        "balanced_accuracy": 0.5163819919917481,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "954",
        "agreement_percentage": 55.497382198952884,
        "mcc": 0.11417964470231642,
        "accuracy": 0.5549738219895288,
        "precision": 0.5430954587581094,
        "recall": 0.682983682983683,
        "f1_score": 0.6050593701600412,
        "balanced_accuracy": 0.5551968356846405,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "968",
        "agreement_percentage": 56.31180919139034,
        "mcc": 0.12959697241248408,
        "accuracy": 0.5631180919139034,
        "precision": 0.551294343240652,
        "recall": 0.6701631701631702,
        "f1_score": 0.6049447659126775,
        "balanced_accuracy": 0.5633045815972646,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "922",
        "agreement_percentage": 53.63583478766725,
        "mcc": 0.07285105523006179,
        "accuracy": 0.5363583478766725,
        "precision": 0.5340782122905028,
        "recall": 0.5571095571095571,
        "f1_score": 0.5453508271534513,
        "balanced_accuracy": 0.5363944998091339,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "864",
        "agreement_percentage": 50.26178010471204,
        "mcc": 0.005040721007786214,
        "accuracy": 0.5026178010471204,
        "precision": 0.5020297699594046,
        "recall": 0.4324009324009324,
        "f1_score": 0.46462116468378206,
        "balanced_accuracy": 0.5024954720076671,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "880",
        "agreement_percentage": 51.19255381035486,
        "mcc": 0.023815606260968757,
        "accuracy": 0.5119255381035486,
        "precision": 0.5125827814569537,
        "recall": 0.45104895104895104,
        "f1_score": 0.4798512089274644,
        "balanced_accuracy": 0.5118194813316764,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "869",
        "agreement_percentage": 50.552646887725416,
        "mcc": 0.010938422927734517,
        "accuracy": 0.5055264688772542,
        "precision": 0.5051282051282051,
        "recall": 0.4592074592074592,
        "f1_score": 0.48107448107448103,
        "balanced_accuracy": 0.5054457737384567,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "911",
        "agreement_percentage": 52.995927865037814,
        "mcc": 0.0624328744976651,
        "accuracy": 0.5299592786503782,
        "precision": 0.5420875420875421,
        "recall": 0.3752913752913753,
        "f1_score": 0.4435261707988981,
        "balanced_accuracy": 0.5296898223727492,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "900",
        "agreement_percentage": 52.35602094240838,
        "mcc": 0.04857241901018046,
        "accuracy": 0.5235602094240838,
        "precision": 0.531502423263328,
        "recall": 0.38344988344988346,
        "f1_score": 0.44549763033175355,
        "balanced_accuracy": 0.5233161147795294,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "914",
        "agreement_percentage": 53.170447934845846,
        "mcc": 0.06533428484612376,
        "accuracy": 0.5317044793484584,
        "precision": 0.5421303656597775,
        "recall": 0.3974358974358974,
        "f1_score": 0.45864156018829855,
        "balanced_accuracy": 0.5314705619583668,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}