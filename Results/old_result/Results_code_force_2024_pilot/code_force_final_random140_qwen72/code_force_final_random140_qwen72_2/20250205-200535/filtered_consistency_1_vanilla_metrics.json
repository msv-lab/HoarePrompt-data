{
    "total_valid_rows": {
        "value": 23,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "6",
        "agreement_percentage": 26.08695652173913,
        "mcc": 0,
        "accuracy": 0.2608695652173913,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "9",
        "agreement_percentage": 39.130434782608695,
        "mcc": 0.07305950062660077,
        "accuracy": 0.391304347826087,
        "precision": 0.8,
        "recall": 0.23529411764705882,
        "f1_score": 0.3636363636363636,
        "balanced_accuracy": 0.5343137254901961,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "16",
        "agreement_percentage": 69.56521739130434,
        "mcc": -0.12666009927622474,
        "accuracy": 0.6956521739130435,
        "precision": 0.7272727272727273,
        "recall": 0.9411764705882353,
        "f1_score": 0.8205128205128205,
        "balanced_accuracy": 0.47058823529411764,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "16",
        "agreement_percentage": 69.56521739130434,
        "mcc": 0.0639137490706142,
        "accuracy": 0.6956521739130435,
        "precision": 0.75,
        "recall": 0.8823529411764706,
        "f1_score": 0.8108108108108107,
        "balanced_accuracy": 0.5245098039215687,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "17",
        "agreement_percentage": 73.91304347826086,
        "mcc": 0.16806139112183874,
        "accuracy": 0.7391304347826086,
        "precision": 0.7619047619047619,
        "recall": 0.9411764705882353,
        "f1_score": 0.8421052631578947,
        "balanced_accuracy": 0.553921568627451,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "13",
        "agreement_percentage": 56.52173913043478,
        "mcc": -0.12745098039215685,
        "accuracy": 0.5652173913043478,
        "precision": 0.7058823529411765,
        "recall": 0.7058823529411765,
        "f1_score": 0.7058823529411765,
        "balanced_accuracy": 0.4362745098039216,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "13",
        "agreement_percentage": 56.52173913043478,
        "mcc": -0.27258651025455277,
        "accuracy": 0.5652173913043478,
        "precision": 0.6842105263157895,
        "recall": 0.7647058823529411,
        "f1_score": 0.7222222222222222,
        "balanced_accuracy": 0.38235294117647056,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "14",
        "agreement_percentage": 60.86956521739131,
        "mcc": -0.23008949665421113,
        "accuracy": 0.6086956521739131,
        "precision": 0.7,
        "recall": 0.8235294117647058,
        "f1_score": 0.7567567567567567,
        "balanced_accuracy": 0.4117647058823529,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "13",
        "agreement_percentage": 56.52173913043478,
        "mcc": -0.27258651025455277,
        "accuracy": 0.5652173913043478,
        "precision": 0.6842105263157895,
        "recall": 0.7647058823529411,
        "f1_score": 0.7222222222222222,
        "balanced_accuracy": 0.38235294117647056,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "16",
        "agreement_percentage": 69.56521739130434,
        "mcc": 0.16699314428937317,
        "accuracy": 0.6956521739130435,
        "precision": 0.7777777777777778,
        "recall": 0.8235294117647058,
        "f1_score": 0.7999999999999999,
        "balanced_accuracy": 0.5784313725490196,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "11",
        "agreement_percentage": 47.82608695652174,
        "mcc": 0.17776428228421592,
        "accuracy": 0.4782608695652174,
        "precision": 0.8571428571428571,
        "recall": 0.35294117647058826,
        "f1_score": 0.5,
        "balanced_accuracy": 0.5931372549019608,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "9",
        "agreement_percentage": 39.130434782608695,
        "mcc": -0.22407133233117496,
        "accuracy": 0.391304347826087,
        "precision": 0.6363636363636364,
        "recall": 0.4117647058823529,
        "f1_score": 0.5,
        "balanced_accuracy": 0.37254901960784315,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "14",
        "agreement_percentage": 60.86956521739131,
        "mcc": 0.3213142318599921,
        "accuracy": 0.6086956521739131,
        "precision": 0.9,
        "recall": 0.5294117647058824,
        "f1_score": 0.6666666666666667,
        "balanced_accuracy": 0.6813725490196079,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}