{
    "total_valid_rows": {
        "value": 1570,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "908",
        "agreement_percentage": 57.8343949044586,
        "mcc": 0.17648619898631251,
        "accuracy": 0.578343949044586,
        "precision": 0.6423841059602649,
        "recall": 0.36788874841972186,
        "f1_score": 0.467845659163987,
        "balanced_accuracy": 0.5799649133626209,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "834",
        "agreement_percentage": 53.12101910828025,
        "mcc": 0.09393122690078867,
        "accuracy": 0.5312101910828025,
        "precision": 0.6141078838174274,
        "recall": 0.18710493046776233,
        "f1_score": 0.2868217054263566,
        "balanced_accuracy": 0.5338605525252804,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "906",
        "agreement_percentage": 57.70700636942675,
        "mcc": 0.1544194983309808,
        "accuracy": 0.5770700636942675,
        "precision": 0.583224115334207,
        "recall": 0.5625790139064475,
        "f1_score": 0.5727155727155727,
        "balanced_accuracy": 0.5771816764012341,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "913",
        "agreement_percentage": 58.152866242038215,
        "mcc": 0.16342167994256274,
        "accuracy": 0.5815286624203821,
        "precision": 0.5883905013192612,
        "recall": 0.5638432364096081,
        "f1_score": 0.5758553905745641,
        "balanced_accuracy": 0.5816648787953047,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "932",
        "agreement_percentage": 59.36305732484076,
        "mcc": 0.18946811381002956,
        "accuracy": 0.5936305732484076,
        "precision": 0.6103896103896104,
        "recall": 0.5347661188369153,
        "f1_score": 0.5700808625336927,
        "balanced_accuracy": 0.5940839580063909,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "915",
        "agreement_percentage": 58.28025477707006,
        "mcc": 0.17907123786371862,
        "accuracy": 0.5828025477707006,
        "precision": 0.6317829457364341,
        "recall": 0.41213653603034134,
        "f1_score": 0.4988523335883704,
        "balanced_accuracy": 0.5841170485029755,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "928",
        "agreement_percentage": 59.10828025477707,
        "mcc": 0.1972443221023716,
        "accuracy": 0.5910828025477707,
        "precision": 0.6457925636007827,
        "recall": 0.41719342604298354,
        "f1_score": 0.5069124423963133,
        "balanced_accuracy": 0.5924221302230323,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "900",
        "agreement_percentage": 57.324840764331206,
        "mcc": 0.16296350087680808,
        "accuracy": 0.5732484076433121,
        "precision": 0.627906976744186,
        "recall": 0.3754740834386852,
        "f1_score": 0.46993670886075956,
        "balanced_accuracy": 0.574771701539625,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "876",
        "agreement_percentage": 55.796178343949045,
        "mcc": 0.13599537011410168,
        "accuracy": 0.5579617834394904,
        "precision": 0.6180048661800487,
        "recall": 0.3211125158027813,
        "f1_score": 0.42262895174708814,
        "balanced_accuracy": 0.5597860396728925,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "899",
        "agreement_percentage": 57.261146496815286,
        "mcc": 0.1703461007568742,
        "accuracy": 0.5726114649681529,
        "precision": 0.6485148514851485,
        "recall": 0.33122629582806573,
        "f1_score": 0.4384937238493724,
        "balanced_accuracy": 0.5744706575417607,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "871",
        "agreement_percentage": 55.47770700636943,
        "mcc": 0.13466043645128292,
        "accuracy": 0.5547770700636943,
        "precision": 0.6263736263736264,
        "recall": 0.28824273072060685,
        "f1_score": 0.3948051948051948,
        "balanced_accuracy": 0.5568299661305216,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}