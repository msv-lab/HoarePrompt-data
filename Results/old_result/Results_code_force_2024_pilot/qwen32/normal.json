{
    "total_valid_rows": {
        "value": 1665,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "970",
        "agreement_percentage": 58.25825825825825,
        "mcc": 0.1761497598725679,
        "accuracy": 0.5825825825825826,
        "precision": 0.6278625954198473,
        "recall": 0.3968636911942099,
        "f1_score": 0.4863266814486327,
        "balanced_accuracy": 0.5818050513387317,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "917",
        "agreement_percentage": 55.07507507507508,
        "mcc": 0.1290361319709393,
        "accuracy": 0.5507507507507508,
        "precision": 0.6363636363636364,
        "recall": 0.22798552472858866,
        "f1_score": 0.3357015985790408,
        "balanced_accuracy": 0.5493994609288876,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "992",
        "agreement_percentage": 59.57957957957958,
        "mcc": 0.1916425368651445,
        "accuracy": 0.5957957957957958,
        "precision": 0.5989847715736041,
        "recall": 0.5693606755126659,
        "f1_score": 0.5837971552257266,
        "balanced_accuracy": 0.5956851224453281,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "1030",
        "agreement_percentage": 61.86186186186187,
        "mcc": 0.23744682899677735,
        "accuracy": 0.6186186186186187,
        "precision": 0.6243589743589744,
        "recall": 0.5874547647768396,
        "f1_score": 0.6053449347420758,
        "balanced_accuracy": 0.618488147938659,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "929",
        "agreement_percentage": 55.7957957957958,
        "mcc": 0.11916288565899277,
        "accuracy": 0.557957957957958,
        "precision": 0.5763546798029556,
        "recall": 0.4234016887816647,
        "f1_score": 0.48817802503477054,
        "balanced_accuracy": 0.5573946242951385,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "922",
        "agreement_percentage": 55.37537537537538,
        "mcc": 0.13848761894228961,
        "accuracy": 0.5537537537537538,
        "precision": 0.6493055555555556,
        "recall": 0.2255729794933655,
        "f1_score": 0.3348254252461952,
        "balanced_accuracy": 0.5523797911820895,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "999",
        "agreement_percentage": 60.0,
        "mcc": 0.2011428886322546,
        "accuracy": 0.6,
        "precision": 0.6124137931034482,
        "recall": 0.5355850422195416,
        "f1_score": 0.5714285714285715,
        "balanced_accuracy": 0.599730320152833,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "948",
        "agreement_percentage": 56.93693693693693,
        "mcc": 0.1463520283046493,
        "accuracy": 0.5693693693693693,
        "precision": 0.6029411764705882,
        "recall": 0.3956574185765983,
        "f1_score": 0.47778587035688275,
        "balanced_accuracy": 0.5686421064174858,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "936",
        "agreement_percentage": 56.21621621621622,
        "mcc": 0.13192945114209242,
        "accuracy": 0.5621621621621622,
        "precision": 0.5946969696969697,
        "recall": 0.37876960193003617,
        "f1_score": 0.4627855563743552,
        "balanced_accuracy": 0.5613943703430085,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "953",
        "agreement_percentage": 57.23723723723724,
        "mcc": 0.15564143473474273,
        "accuracy": 0.5723723723723724,
        "precision": 0.6158415841584158,
        "recall": 0.3751507840772014,
        "f1_score": 0.4662668665667167,
        "balanced_accuracy": 0.5715466839046294,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "971",
        "agreement_percentage": 58.31831831831832,
        "mcc": 0.18380805976734355,
        "accuracy": 0.5831831831831832,
        "precision": 0.6464208242950108,
        "recall": 0.3594692400482509,
        "f1_score": 0.46201550387596896,
        "balanced_accuracy": 0.5822465817466135,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "972",
        "agreement_percentage": 58.37837837837838,
        "mcc": 0.18673760692400423,
        "accuracy": 0.5837837837837838,
        "precision": 0.6517857142857143,
        "recall": 0.35223160434258144,
        "f1_score": 0.45732184808144094,
        "balanced_accuracy": 0.5828143667645922,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "939",
        "agreement_percentage": 56.3963963963964,
        "mcc": 0.14752557620533974,
        "accuracy": 0.563963963963964,
        "precision": 0.6297229219143576,
        "recall": 0.30156815440289503,
        "f1_score": 0.40783034257748774,
        "balanced_accuracy": 0.5628654169143662,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}