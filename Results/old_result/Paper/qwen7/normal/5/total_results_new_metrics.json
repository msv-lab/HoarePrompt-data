{
    "total_valid_rows": {
        "value": 305,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "169",
        "agreement_percentage": 55.40983606557377,
        "mcc": 0.2005360948705262,
        "accuracy": 0.5540983606557377,
        "precision": 1.0,
        "recall": 0.07482993197278912,
        "f1_score": 0.13924050632911392,
        "balanced_accuracy": 0.5374149659863946,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "175",
        "agreement_percentage": 57.377049180327866,
        "mcc": 0.2518825567072754,
        "accuracy": 0.5737704918032787,
        "precision": 1.0,
        "recall": 0.11564625850340136,
        "f1_score": 0.20731707317073172,
        "balanced_accuracy": 0.5578231292517006,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "177",
        "agreement_percentage": 58.032786885245905,
        "mcc": 0.1679226941025926,
        "accuracy": 0.580327868852459,
        "precision": 0.5542857142857143,
        "recall": 0.6598639455782312,
        "f1_score": 0.6024844720496894,
        "balanced_accuracy": 0.583096529751141,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "170",
        "agreement_percentage": 55.73770491803278,
        "mcc": 0.12112658858204807,
        "accuracy": 0.5573770491803278,
        "precision": 0.5344827586206896,
        "recall": 0.6326530612244898,
        "f1_score": 0.5794392523364486,
        "balanced_accuracy": 0.5599974166881942,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "170",
        "agreement_percentage": 55.73770491803278,
        "mcc": 0.11471109484396907,
        "accuracy": 0.5573770491803278,
        "precision": 0.5394736842105263,
        "recall": 0.5578231292517006,
        "f1_score": 0.5484949832775919,
        "balanced_accuracy": 0.5573925772840782,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "159",
        "agreement_percentage": 52.131147540983605,
        "mcc": 0.02571789610866906,
        "accuracy": 0.521311475409836,
        "precision": 0.5087719298245614,
        "recall": 0.19727891156462585,
        "f1_score": 0.28431372549019607,
        "balanced_accuracy": 0.510031860845604,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "165",
        "agreement_percentage": 54.09836065573771,
        "mcc": 0.07952554315861626,
        "accuracy": 0.5409836065573771,
        "precision": 0.524822695035461,
        "recall": 0.5034013605442177,
        "f1_score": 0.5138888888888888,
        "balanced_accuracy": 0.5396753638164127,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "159",
        "agreement_percentage": 52.131147540983605,
        "mcc": 0.04004324690786538,
        "accuracy": 0.521311475409836,
        "precision": 0.5035460992907801,
        "recall": 0.48299319727891155,
        "f1_score": 0.4930555555555555,
        "balanced_accuracy": 0.5199776112976836,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "166",
        "agreement_percentage": 54.42622950819672,
        "mcc": 0.08449784011634737,
        "accuracy": 0.5442622950819672,
        "precision": 0.5303030303030303,
        "recall": 0.47619047619047616,
        "f1_score": 0.5017921146953404,
        "balanced_accuracy": 0.5418927064496685,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "152",
        "agreement_percentage": 49.8360655737705,
        "mcc": -0.005300583941717303,
        "accuracy": 0.49836065573770494,
        "precision": 0.4791666666666667,
        "recall": 0.46938775510204084,
        "f1_score": 0.4742268041237114,
        "balanced_accuracy": 0.49735210539912167,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "161",
        "agreement_percentage": 52.78688524590164,
        "mcc": 0.04603936269149044,
        "accuracy": 0.5278688524590164,
        "precision": 0.5151515151515151,
        "recall": 0.3469387755102041,
        "f1_score": 0.41463414634146345,
        "balanced_accuracy": 0.5215706535778869,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "162",
        "agreement_percentage": 53.11475409836065,
        "mcc": 0.05339758053006667,
        "accuracy": 0.5311475409836065,
        "precision": 0.5196078431372549,
        "recall": 0.36054421768707484,
        "f1_score": 0.4257028112449799,
        "balanced_accuracy": 0.525208817704297,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "161",
        "agreement_percentage": 52.78688524590164,
        "mcc": 0.04603936269149044,
        "accuracy": 0.5278688524590164,
        "precision": 0.5151515151515151,
        "recall": 0.3469387755102041,
        "f1_score": 0.41463414634146345,
        "balanced_accuracy": 0.5215706535778869,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}