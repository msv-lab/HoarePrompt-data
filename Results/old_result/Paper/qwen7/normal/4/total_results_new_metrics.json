{
    "total_valid_rows": {
        "value": 306,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "149",
        "agreement_percentage": 48.69281045751634,
        "mcc": -0.034145753477045813,
        "accuracy": 0.4869281045751634,
        "precision": 0.42857142857142855,
        "recall": 0.03870967741935484,
        "f1_score": 0.07100591715976332,
        "balanced_accuracy": 0.4928647724845118,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "150",
        "agreement_percentage": 49.01960784313725,
        "mcc": -0.017438691777083314,
        "accuracy": 0.49019607843137253,
        "precision": 0.47058823529411764,
        "recall": 0.05161290322580645,
        "f1_score": 0.09302325581395349,
        "balanced_accuracy": 0.496005127109592,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "162",
        "agreement_percentage": 52.94117647058824,
        "mcc": 0.057725797722948925,
        "accuracy": 0.5294117647058824,
        "precision": 0.5270935960591133,
        "recall": 0.6903225806451613,
        "f1_score": 0.5977653631284916,
        "balanced_accuracy": 0.5272804956205939,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "171",
        "agreement_percentage": 55.88235294117647,
        "mcc": 0.1184874231979934,
        "accuracy": 0.5588235294117647,
        "precision": 0.5515463917525774,
        "recall": 0.6903225806451613,
        "f1_score": 0.6131805157593123,
        "balanced_accuracy": 0.5570818201239052,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "158",
        "agreement_percentage": 51.633986928104584,
        "mcc": 0.032514419995727406,
        "accuracy": 0.5163398692810458,
        "precision": 0.5225806451612903,
        "recall": 0.5225806451612903,
        "f1_score": 0.5225806451612903,
        "balanced_accuracy": 0.5162572099978637,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "149",
        "agreement_percentage": 48.69281045751634,
        "mcc": -0.022747946550514313,
        "accuracy": 0.4869281045751634,
        "precision": 0.48484848484848486,
        "recall": 0.2064516129032258,
        "f1_score": 0.2895927601809955,
        "balanced_accuracy": 0.4906430249946592,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "149",
        "agreement_percentage": 48.69281045751634,
        "mcc": -0.026961712501077643,
        "accuracy": 0.4869281045751634,
        "precision": 0.49382716049382713,
        "recall": 0.5161290322580645,
        "f1_score": 0.5047318611987381,
        "balanced_accuracy": 0.48654133732108523,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "108",
        "agreement_percentage": 35.294117647058826,
        "mcc": -0.2939167913860383,
        "accuracy": 0.35294117647058826,
        "precision": 0.34965034965034963,
        "recall": 0.3225806451612903,
        "f1_score": 0.3355704697986577,
        "balanced_accuracy": 0.3533433027130955,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "133",
        "agreement_percentage": 43.4640522875817,
        "mcc": -0.13026842340248423,
        "accuracy": 0.434640522875817,
        "precision": 0.4383561643835616,
        "recall": 0.4129032258064516,
        "f1_score": 0.42524916943521596,
        "balanced_accuracy": 0.4349284340952788,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "145",
        "agreement_percentage": 47.385620915032675,
        "mcc": -0.05115625267322421,
        "accuracy": 0.4738562091503268,
        "precision": 0.47794117647058826,
        "recall": 0.41935483870967744,
        "f1_score": 0.44673539518900346,
        "balanced_accuracy": 0.4745780816064944,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "159",
        "agreement_percentage": 51.9607843137255,
        "mcc": 0.04894384064553924,
        "accuracy": 0.5196078431372549,
        "precision": 0.5444444444444444,
        "recall": 0.3161290322580645,
        "f1_score": 0.39999999999999997,
        "balanced_accuracy": 0.5223029267250587,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "143",
        "agreement_percentage": 46.73202614379085,
        "mcc": -0.06470811000258635,
        "accuracy": 0.4673202614379085,
        "precision": 0.46078431372549017,
        "recall": 0.3032258064516129,
        "f1_score": 0.36575875486381326,
        "balanced_accuracy": 0.4694936979277932,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "161",
        "agreement_percentage": 52.614379084967325,
        "mcc": 0.057149781544819235,
        "accuracy": 0.5261437908496732,
        "precision": 0.5431034482758621,
        "recall": 0.4064516129032258,
        "f1_score": 0.46494464944649444,
        "balanced_accuracy": 0.5277291177098911,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}