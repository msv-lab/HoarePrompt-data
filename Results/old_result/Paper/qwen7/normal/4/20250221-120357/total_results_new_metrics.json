{
    "total_valid_rows": {
        "value": 102,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "51",
        "agreement_percentage": 50.0,
        "mcc": 0.0,
        "accuracy": 0.5,
        "precision": 0.5,
        "recall": 0.0392156862745098,
        "f1_score": 0.07272727272727272,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "50",
        "agreement_percentage": 49.01960784313725,
        "mcc": -0.04540766091864998,
        "accuracy": 0.49019607843137253,
        "precision": 0.4,
        "recall": 0.0392156862745098,
        "f1_score": 0.07142857142857142,
        "balanced_accuracy": 0.49019607843137253,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "58",
        "agreement_percentage": 56.86274509803921,
        "mcc": 0.14920659471182063,
        "accuracy": 0.5686274509803921,
        "precision": 0.5492957746478874,
        "recall": 0.7647058823529411,
        "f1_score": 0.6393442622950819,
        "balanced_accuracy": 0.5686274509803921,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "55",
        "agreement_percentage": 53.92156862745098,
        "mcc": 0.08206099398622183,
        "accuracy": 0.5392156862745098,
        "precision": 0.5303030303030303,
        "recall": 0.6862745098039216,
        "f1_score": 0.5982905982905983,
        "balanced_accuracy": 0.5392156862745098,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "52",
        "agreement_percentage": 50.98039215686274,
        "mcc": 0.019622937706955574,
        "accuracy": 0.5098039215686274,
        "precision": 0.5094339622641509,
        "recall": 0.5294117647058824,
        "f1_score": 0.5192307692307693,
        "balanced_accuracy": 0.5098039215686274,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "51",
        "agreement_percentage": 50.0,
        "mcc": 0.0,
        "accuracy": 0.5,
        "precision": 0.5,
        "recall": 0.23529411764705882,
        "f1_score": 0.31999999999999995,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "49",
        "agreement_percentage": 48.03921568627451,
        "mcc": -0.039283710065919304,
        "accuracy": 0.4803921568627451,
        "precision": 0.48148148148148145,
        "recall": 0.5098039215686274,
        "f1_score": 0.49523809523809526,
        "balanced_accuracy": 0.48039215686274506,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "40",
        "agreement_percentage": 39.21568627450981,
        "mcc": -0.21635274585338146,
        "accuracy": 0.39215686274509803,
        "precision": 0.3829787234042553,
        "recall": 0.35294117647058826,
        "f1_score": 0.3673469387755102,
        "balanced_accuracy": 0.3921568627450981,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "43",
        "agreement_percentage": 42.15686274509804,
        "mcc": -0.15713484026367722,
        "accuracy": 0.4215686274509804,
        "precision": 0.4166666666666667,
        "recall": 0.39215686274509803,
        "f1_score": 0.40404040404040403,
        "balanced_accuracy": 0.4215686274509804,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "53",
        "agreement_percentage": 51.9607843137255,
        "mcc": 0.03959037912324479,
        "accuracy": 0.5196078431372549,
        "precision": 0.5227272727272727,
        "recall": 0.45098039215686275,
        "f1_score": 0.48421052631578954,
        "balanced_accuracy": 0.5196078431372549,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "53",
        "agreement_percentage": 51.9607843137255,
        "mcc": 0.042257712736425826,
        "accuracy": 0.5196078431372549,
        "precision": 0.53125,
        "recall": 0.3333333333333333,
        "f1_score": 0.40963855421686746,
        "balanced_accuracy": 0.5196078431372549,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "43",
        "agreement_percentage": 42.15686274509804,
        "mcc": -0.16222142113076254,
        "accuracy": 0.4215686274509804,
        "precision": 0.39473684210526316,
        "recall": 0.29411764705882354,
        "f1_score": 0.3370786516853933,
        "balanced_accuracy": 0.42156862745098045,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "47",
        "agreement_percentage": 46.07843137254902,
        "mcc": -0.08111071056538127,
        "accuracy": 0.46078431372549017,
        "precision": 0.4473684210526316,
        "recall": 0.3333333333333333,
        "f1_score": 0.38202247191011235,
        "balanced_accuracy": 0.4607843137254902,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}