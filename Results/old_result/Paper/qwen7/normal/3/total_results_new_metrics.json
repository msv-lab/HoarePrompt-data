{
    "total_valid_rows": {
        "value": 297,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "166",
        "agreement_percentage": 55.892255892255896,
        "mcc": 0.1423760894465495,
        "accuracy": 0.5589225589225589,
        "precision": 1.0,
        "recall": 0.03676470588235294,
        "f1_score": 0.07092198581560283,
        "balanced_accuracy": 0.5183823529411765,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "165",
        "agreement_percentage": 55.55555555555556,
        "mcc": 0.08597605037230371,
        "accuracy": 0.5555555555555556,
        "precision": 0.6666666666666666,
        "recall": 0.058823529411764705,
        "f1_score": 0.10810810810810811,
        "balanced_accuracy": 0.5169894044574351,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "166",
        "agreement_percentage": 55.892255892255896,
        "mcc": 0.15431655824191104,
        "accuracy": 0.5589225589225589,
        "precision": 0.5126903553299492,
        "recall": 0.7426470588235294,
        "f1_score": 0.6066066066066067,
        "balanced_accuracy": 0.5731868834490318,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "166",
        "agreement_percentage": 55.892255892255896,
        "mcc": 0.14687112871963826,
        "accuracy": 0.5589225589225589,
        "precision": 0.5132275132275133,
        "recall": 0.7132352941176471,
        "f1_score": 0.596923076923077,
        "balanced_accuracy": 0.5709033613445378,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "160",
        "agreement_percentage": 53.87205387205387,
        "mcc": 0.07686753609702436,
        "accuracy": 0.5387205387205387,
        "precision": 0.4965986394557823,
        "recall": 0.5367647058823529,
        "f1_score": 0.5159010600706714,
        "balanced_accuracy": 0.5385686883449032,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "169",
        "agreement_percentage": 56.9023569023569,
        "mcc": 0.11186139611454184,
        "accuracy": 0.569023569023569,
        "precision": 0.5952380952380952,
        "recall": 0.18382352941176472,
        "f1_score": 0.2808988764044944,
        "balanced_accuracy": 0.5391167336499818,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "168",
        "agreement_percentage": 56.56565656565656,
        "mcc": 0.1309342222327644,
        "accuracy": 0.5656565656565656,
        "precision": 0.5238095238095238,
        "recall": 0.5661764705882353,
        "f1_score": 0.5441696113074205,
        "balanced_accuracy": 0.5656969309462916,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "174",
        "agreement_percentage": 58.58585858585859,
        "mcc": 0.16628631305893446,
        "accuracy": 0.5858585858585859,
        "precision": 0.5474452554744526,
        "recall": 0.5514705882352942,
        "f1_score": 0.5494505494505494,
        "balanced_accuracy": 0.5831887102667155,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "161",
        "agreement_percentage": 54.20875420875421,
        "mcc": 0.07053237563957325,
        "accuracy": 0.5420875420875421,
        "precision": 0.5,
        "recall": 0.4485294117647059,
        "f1_score": 0.47286821705426363,
        "balanced_accuracy": 0.5348237120935331,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "164",
        "agreement_percentage": 55.218855218855225,
        "mcc": 0.10278642242272114,
        "accuracy": 0.5521885521885522,
        "precision": 0.5103448275862069,
        "recall": 0.5441176470588235,
        "f1_score": 0.5266903914590747,
        "balanced_accuracy": 0.5515619291194738,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "161",
        "agreement_percentage": 54.20875420875421,
        "mcc": 0.06478928096050013,
        "accuracy": 0.5420875420875421,
        "precision": 0.5,
        "recall": 0.40441176470588236,
        "f1_score": 0.44715447154471544,
        "balanced_accuracy": 0.5313984289367921,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "163",
        "agreement_percentage": 54.882154882154886,
        "mcc": 0.07878376564796816,
        "accuracy": 0.5488215488215489,
        "precision": 0.509090909090909,
        "recall": 0.4117647058823529,
        "f1_score": 0.45528455284552843,
        "balanced_accuracy": 0.5381804895871392,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "159",
        "agreement_percentage": 53.535353535353536,
        "mcc": 0.041975491952243094,
        "accuracy": 0.5353535353535354,
        "precision": 0.4891304347826087,
        "recall": 0.33088235294117646,
        "f1_score": 0.39473684210526316,
        "balanced_accuracy": 0.5194784435513335,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}