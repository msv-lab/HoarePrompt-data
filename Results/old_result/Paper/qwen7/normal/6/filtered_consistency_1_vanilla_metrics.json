{
    "total_valid_rows": {
        "value": 62,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "23",
        "agreement_percentage": 37.096774193548384,
        "mcc": 0,
        "accuracy": 0.3709677419354839,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "20",
        "agreement_percentage": 32.25806451612903,
        "mcc": -0.29363174566687283,
        "accuracy": 0.3225806451612903,
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.43478260869565216,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "37",
        "agreement_percentage": 59.67741935483871,
        "mcc": 0.046345446472873406,
        "accuracy": 0.5967741935483871,
        "precision": 0.64,
        "recall": 0.8205128205128205,
        "f1_score": 0.7191011235955057,
        "balanced_accuracy": 0.5189520624303233,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "35",
        "agreement_percentage": 56.451612903225815,
        "mcc": -0.0381668382717781,
        "accuracy": 0.5645161290322581,
        "precision": 0.62,
        "recall": 0.7948717948717948,
        "f1_score": 0.6966292134831461,
        "balanced_accuracy": 0.48439241917502784,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "33",
        "agreement_percentage": 53.2258064516129,
        "mcc": -0.011255439098214024,
        "accuracy": 0.532258064516129,
        "precision": 0.625,
        "recall": 0.6410256410256411,
        "f1_score": 0.6329113924050633,
        "balanced_accuracy": 0.4944258639910814,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "23",
        "agreement_percentage": 37.096774193548384,
        "mcc": -0.11713645963490477,
        "accuracy": 0.3709677419354839,
        "precision": 0.5,
        "recall": 0.1282051282051282,
        "f1_score": 0.2040816326530612,
        "balanced_accuracy": 0.45540691192865107,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "31",
        "agreement_percentage": 50.0,
        "mcc": -0.08103916150714098,
        "accuracy": 0.5,
        "precision": 0.6,
        "recall": 0.6153846153846154,
        "f1_score": 0.6075949367088608,
        "balanced_accuracy": 0.459866220735786,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "28",
        "agreement_percentage": 45.16129032258064,
        "mcc": -0.10016708449412667,
        "accuracy": 0.45161290322580644,
        "precision": 0.5806451612903226,
        "recall": 0.46153846153846156,
        "f1_score": 0.5142857142857143,
        "balanced_accuracy": 0.4481605351170569,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "28",
        "agreement_percentage": 45.16129032258064,
        "mcc": -0.10016708449412667,
        "accuracy": 0.45161290322580644,
        "precision": 0.5806451612903226,
        "recall": 0.46153846153846156,
        "f1_score": 0.5142857142857143,
        "balanced_accuracy": 0.4481605351170569,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "32",
        "agreement_percentage": 51.61290322580645,
        "mcc": -0.0010861451673873344,
        "accuracy": 0.5161290322580645,
        "precision": 0.6285714285714286,
        "recall": 0.5641025641025641,
        "f1_score": 0.5945945945945945,
        "balanced_accuracy": 0.4994425863991081,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "28",
        "agreement_percentage": 45.16129032258064,
        "mcc": -0.11764522577540269,
        "accuracy": 0.45161290322580644,
        "precision": 0.5757575757575758,
        "recall": 0.48717948717948717,
        "f1_score": 0.5277777777777778,
        "balanced_accuracy": 0.43924191750278707,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "25",
        "agreement_percentage": 40.32258064516129,
        "mcc": -0.19181747254148576,
        "accuracy": 0.4032258064516129,
        "precision": 0.5333333333333333,
        "recall": 0.41025641025641024,
        "f1_score": 0.463768115942029,
        "balanced_accuracy": 0.40078037904124864,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "31",
        "agreement_percentage": 50.0,
        "mcc": 0.02597147085858287,
        "accuracy": 0.5,
        "precision": 0.6428571428571429,
        "recall": 0.46153846153846156,
        "f1_score": 0.537313432835821,
        "balanced_accuracy": 0.5133779264214047,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}