{
    "total_valid_rows": {
        "value": 263,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "127",
        "agreement_percentage": 48.28897338403042,
        "mcc": -0.07371596159399887,
        "accuracy": 0.4828897338403042,
        "precision": 0.3333333333333333,
        "recall": 0.030303030303030304,
        "f1_score": 0.05555555555555555,
        "balanced_accuracy": 0.484617164006477,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "129",
        "agreement_percentage": 49.049429657794676,
        "mcc": -0.03278220860128344,
        "accuracy": 0.49049429657794674,
        "precision": 0.4375,
        "recall": 0.05303030303030303,
        "f1_score": 0.0945945945945946,
        "balanced_accuracy": 0.49216400647698355,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "137",
        "agreement_percentage": 52.09125475285171,
        "mcc": 0.04289877306497064,
        "accuracy": 0.5209125475285171,
        "precision": 0.5172413793103449,
        "recall": 0.6818181818181818,
        "f1_score": 0.5882352941176471,
        "balanced_accuracy": 0.5202984038861901,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "126",
        "agreement_percentage": 47.90874524714829,
        "mcc": -0.04425415945418808,
        "accuracy": 0.4790874524714829,
        "precision": 0.48484848484848486,
        "recall": 0.6060606060606061,
        "f1_score": 0.5387205387205387,
        "balanced_accuracy": 0.4786028221142725,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "129",
        "agreement_percentage": 49.049429657794676,
        "mcc": -0.019087281217424878,
        "accuracy": 0.49049429657794674,
        "precision": 0.4925373134328358,
        "recall": 0.5,
        "f1_score": 0.49624060150375937,
        "balanced_accuracy": 0.4904580152671756,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "127",
        "agreement_percentage": 48.28897338403042,
        "mcc": -0.03794361528349583,
        "accuracy": 0.4828897338403042,
        "precision": 0.46774193548387094,
        "recall": 0.2196969696969697,
        "f1_score": 0.29896907216494845,
        "balanced_accuracy": 0.48389428637520243,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "129",
        "agreement_percentage": 49.049429657794676,
        "mcc": -0.01929767760026563,
        "accuracy": 0.49049429657794674,
        "precision": 0.4928571428571429,
        "recall": 0.5227272727272727,
        "f1_score": 0.5073529411764707,
        "balanced_accuracy": 0.4903712699514226,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "120",
        "agreement_percentage": 45.627376425855516,
        "mcc": -0.0875678179127563,
        "accuracy": 0.45627376425855515,
        "precision": 0.452991452991453,
        "recall": 0.4015151515151515,
        "f1_score": 0.4257028112449799,
        "balanced_accuracy": 0.4564827665972704,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "124",
        "agreement_percentage": 47.14828897338403,
        "mcc": -0.05691626001122847,
        "accuracy": 0.4714828897338403,
        "precision": 0.472,
        "recall": 0.44696969696969696,
        "f1_score": 0.45914396887159525,
        "balanced_accuracy": 0.4715764515382836,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "126",
        "agreement_percentage": 47.90874524714829,
        "mcc": -0.0418714939107506,
        "accuracy": 0.4790874524714829,
        "precision": 0.48120300751879697,
        "recall": 0.48484848484848486,
        "f1_score": 0.4830188679245283,
        "balanced_accuracy": 0.47906546379828824,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "130",
        "agreement_percentage": 49.42965779467681,
        "mcc": -0.010755247947912867,
        "accuracy": 0.49429657794676807,
        "precision": 0.4943820224719101,
        "recall": 0.3333333333333333,
        "f1_score": 0.39819004524886875,
        "balanced_accuracy": 0.4949109414758269,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "122",
        "agreement_percentage": 46.38783269961977,
        "mcc": -0.07579636748915336,
        "accuracy": 0.46387832699619774,
        "precision": 0.4470588235294118,
        "recall": 0.2878787878787879,
        "f1_score": 0.3502304147465438,
        "balanced_accuracy": 0.46455008096229466,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "130",
        "agreement_percentage": 49.42965779467681,
        "mcc": -0.010820082705258438,
        "accuracy": 0.49429657794676807,
        "precision": 0.49504950495049505,
        "recall": 0.3787878787878788,
        "f1_score": 0.4291845493562232,
        "balanced_accuracy": 0.4947374508443211,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}