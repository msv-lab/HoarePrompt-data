{
    "total_valid_rows": {
        "value": 58,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "17",
        "agreement_percentage": 29.310344827586203,
        "mcc": 0,
        "accuracy": 0.29310344827586204,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "14",
        "agreement_percentage": 24.137931034482758,
        "mcc": -0.3626993274587609,
        "accuracy": 0.2413793103448276,
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.4117647058823529,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "40",
        "agreement_percentage": 68.96551724137932,
        "mcc": 0.11025852856619069,
        "accuracy": 0.6896551724137931,
        "precision": 0.7254901960784313,
        "recall": 0.9024390243902439,
        "f1_score": 0.8043478260869564,
        "balanced_accuracy": 0.539454806312769,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "41",
        "agreement_percentage": 70.6896551724138,
        "mcc": 0.25639085852655785,
        "accuracy": 0.7068965517241379,
        "precision": 0.7727272727272727,
        "recall": 0.8292682926829268,
        "f1_score": 0.7999999999999999,
        "balanced_accuracy": 0.6205164992826399,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "33",
        "agreement_percentage": 56.896551724137936,
        "mcc": -0.05844656146053494,
        "accuracy": 0.5689655172413793,
        "precision": 0.6904761904761905,
        "recall": 0.7073170731707317,
        "f1_score": 0.6987951807228916,
        "balanced_accuracy": 0.4713055954088953,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "19",
        "agreement_percentage": 32.758620689655174,
        "mcc": -0.03002163562743107,
        "accuracy": 0.3275862068965517,
        "precision": 0.6666666666666666,
        "recall": 0.0975609756097561,
        "f1_score": 0.1702127659574468,
        "balanced_accuracy": 0.4899569583931133,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "38",
        "agreement_percentage": 65.51724137931035,
        "mcc": 0.22421106716192896,
        "accuracy": 0.6551724137931034,
        "precision": 0.7837837837837838,
        "recall": 0.7073170731707317,
        "f1_score": 0.7435897435897435,
        "balanced_accuracy": 0.6183644189383071,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "28",
        "agreement_percentage": 48.275862068965516,
        "mcc": -0.03787770095392851,
        "accuracy": 0.4827586206896552,
        "precision": 0.6896551724137931,
        "recall": 0.4878048780487805,
        "f1_score": 0.5714285714285714,
        "balanced_accuracy": 0.47919655667144906,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "25",
        "agreement_percentage": 43.103448275862064,
        "mcc": -0.16728382013040066,
        "accuracy": 0.43103448275862066,
        "precision": 0.6333333333333333,
        "recall": 0.4634146341463415,
        "f1_score": 0.5352112676056339,
        "balanced_accuracy": 0.4081779053084649,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "29",
        "agreement_percentage": 50.0,
        "mcc": -0.015682858137225062,
        "accuracy": 0.5,
        "precision": 0.7,
        "recall": 0.5121951219512195,
        "f1_score": 0.5915492957746479,
        "balanced_accuracy": 0.4913916786226686,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "27",
        "agreement_percentage": 46.55172413793103,
        "mcc": 0.03499406290155164,
        "accuracy": 0.46551724137931033,
        "precision": 0.7272727272727273,
        "recall": 0.3902439024390244,
        "f1_score": 0.5079365079365079,
        "balanced_accuracy": 0.5186513629842181,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "29",
        "agreement_percentage": 50.0,
        "mcc": 0.015682858137225062,
        "accuracy": 0.5,
        "precision": 0.7142857142857143,
        "recall": 0.4878048780487805,
        "f1_score": 0.5797101449275363,
        "balanced_accuracy": 0.5086083213773314,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "31",
        "agreement_percentage": 53.44827586206896,
        "mcc": 0.09148333913381286,
        "accuracy": 0.5344827586206896,
        "precision": 0.75,
        "recall": 0.5121951219512195,
        "f1_score": 0.6086956521739131,
        "balanced_accuracy": 0.5502152080344334,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}