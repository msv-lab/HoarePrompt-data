{
    "total_valid_rows": {
        "value": 258,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "146",
        "agreement_percentage": 56.58914728682171,
        "mcc": 0.201047537592709,
        "accuracy": 0.5658914728682171,
        "precision": 0.7241379310344828,
        "recall": 0.41721854304635764,
        "f1_score": 0.5294117647058824,
        "balanced_accuracy": 0.5964597388128985,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "114",
        "agreement_percentage": 44.18604651162791,
        "mcc": 0.007743060369233925,
        "accuracy": 0.4418604651162791,
        "precision": 0.5945945945945946,
        "recall": 0.1456953642384106,
        "f1_score": 0.23404255319148937,
        "balanced_accuracy": 0.50275422417528,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "148",
        "agreement_percentage": 57.36434108527132,
        "mcc": 0.1468108724277049,
        "accuracy": 0.5736434108527132,
        "precision": 0.6564885496183206,
        "recall": 0.5695364238410596,
        "f1_score": 0.6099290780141844,
        "balanced_accuracy": 0.5744878380887541,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "145",
        "agreement_percentage": 56.201550387596896,
        "mcc": 0.11665507446496132,
        "accuracy": 0.562015503875969,
        "precision": 0.6397058823529411,
        "recall": 0.5761589403973509,
        "f1_score": 0.6062717770034842,
        "balanced_accuracy": 0.559107507581853,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "150",
        "agreement_percentage": 58.139534883720934,
        "mcc": 0.17344885261066345,
        "accuracy": 0.5813953488372093,
        "precision": 0.6747967479674797,
        "recall": 0.5496688741721855,
        "f1_score": 0.6058394160583942,
        "balanced_accuracy": 0.5879185492356254,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "134",
        "agreement_percentage": 51.93798449612403,
        "mcc": 0.09782528584126719,
        "accuracy": 0.5193798449612403,
        "precision": 0.651685393258427,
        "recall": 0.3841059602649007,
        "f1_score": 0.4833333333333334,
        "balanced_accuracy": 0.5471931670483382,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "140",
        "agreement_percentage": 54.263565891472865,
        "mcc": 0.1474756276387366,
        "accuracy": 0.5426356589147286,
        "precision": 0.6853932584269663,
        "recall": 0.40397350993377484,
        "f1_score": 0.5083333333333333,
        "balanced_accuracy": 0.5711456334715603,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "126",
        "agreement_percentage": 48.837209302325576,
        "mcc": 0.057204349607710384,
        "accuracy": 0.4883720930232558,
        "precision": 0.6301369863013698,
        "recall": 0.304635761589404,
        "f1_score": 0.4107142857142857,
        "balanced_accuracy": 0.5261496564956365,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "130",
        "agreement_percentage": 50.3875968992248,
        "mcc": 0.10795883072744199,
        "accuracy": 0.5038759689922481,
        "precision": 0.676923076923077,
        "recall": 0.2913907284768212,
        "f1_score": 0.40740740740740744,
        "balanced_accuracy": 0.5475645231169153,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "138",
        "agreement_percentage": 53.48837209302325,
        "mcc": 0.1709192405069163,
        "accuracy": 0.5348837209302325,
        "precision": 0.7246376811594203,
        "recall": 0.33112582781456956,
        "f1_score": 0.4545454545454546,
        "balanced_accuracy": 0.5767778671783128,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "140",
        "agreement_percentage": 54.263565891472865,
        "mcc": 0.20919927062168434,
        "accuracy": 0.5426356589147286,
        "precision": 0.7704918032786885,
        "recall": 0.31125827814569534,
        "f1_score": 0.44339622641509424,
        "balanced_accuracy": 0.5902085783251841,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}