{
    "total_valid_rows": {
        "value": 21,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "8",
        "agreement_percentage": 38.095238095238095,
        "mcc": 0.23529411764705882,
        "accuracy": 0.38095238095238093,
        "precision": 1.0,
        "recall": 0.23529411764705882,
        "f1_score": 0.38095238095238093,
        "balanced_accuracy": 0.6176470588235294,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "11",
        "agreement_percentage": 52.38095238095239,
        "mcc": 0.3429971702850177,
        "accuracy": 0.5238095238095238,
        "precision": 1.0,
        "recall": 0.4117647058823529,
        "f1_score": 0.5833333333333334,
        "balanced_accuracy": 0.7058823529411764,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "11",
        "agreement_percentage": 52.38095238095239,
        "mcc": -0.13080416089248587,
        "accuracy": 0.5238095238095238,
        "precision": 0.7692307692307693,
        "recall": 0.5882352941176471,
        "f1_score": 0.6666666666666667,
        "balanced_accuracy": 0.41911764705882354,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "11",
        "agreement_percentage": 52.38095238095239,
        "mcc": -0.13080416089248587,
        "accuracy": 0.5238095238095238,
        "precision": 0.7692307692307693,
        "recall": 0.5882352941176471,
        "f1_score": 0.6666666666666667,
        "balanced_accuracy": 0.41911764705882354,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "9",
        "agreement_percentage": 42.857142857142854,
        "mcc": -0.0700140042014005,
        "accuracy": 0.42857142857142855,
        "precision": 0.7777777777777778,
        "recall": 0.4117647058823529,
        "f1_score": 0.5384615384615384,
        "balanced_accuracy": 0.45588235294117646,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "7",
        "agreement_percentage": 33.33333333333333,
        "mcc": 0.19802950859533489,
        "accuracy": 0.3333333333333333,
        "precision": 1.0,
        "recall": 0.17647058823529413,
        "f1_score": 0.3,
        "balanced_accuracy": 0.5882352941176471,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "11",
        "agreement_percentage": 52.38095238095239,
        "mcc": 0.023124864503144014,
        "accuracy": 0.5238095238095238,
        "precision": 0.8181818181818182,
        "recall": 0.5294117647058824,
        "f1_score": 0.6428571428571428,
        "balanced_accuracy": 0.5147058823529411,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "7",
        "agreement_percentage": 33.33333333333333,
        "mcc": -0.17149858514250885,
        "accuracy": 0.3333333333333333,
        "precision": 0.7142857142857143,
        "recall": 0.29411764705882354,
        "f1_score": 0.4166666666666667,
        "balanced_accuracy": 0.3970588235294118,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "8",
        "agreement_percentage": 38.095238095238095,
        "mcc": 0.038348249442368525,
        "accuracy": 0.38095238095238093,
        "precision": 0.8333333333333334,
        "recall": 0.29411764705882354,
        "f1_score": 0.4347826086956522,
        "balanced_accuracy": 0.5220588235294118,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "7",
        "agreement_percentage": 33.33333333333333,
        "mcc": -0.17149858514250885,
        "accuracy": 0.3333333333333333,
        "precision": 0.7142857142857143,
        "recall": 0.29411764705882354,
        "f1_score": 0.4166666666666667,
        "balanced_accuracy": 0.3970588235294118,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "11",
        "agreement_percentage": 52.38095238095239,
        "mcc": 0.3429971702850177,
        "accuracy": 0.5238095238095238,
        "precision": 1.0,
        "recall": 0.4117647058823529,
        "f1_score": 0.5833333333333334,
        "balanced_accuracy": 0.7058823529411764,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "10",
        "agreement_percentage": 47.61904761904761,
        "mcc": 0.3067859955389482,
        "accuracy": 0.47619047619047616,
        "precision": 1.0,
        "recall": 0.35294117647058826,
        "f1_score": 0.5217391304347826,
        "balanced_accuracy": 0.6764705882352942,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "9",
        "agreement_percentage": 42.857142857142854,
        "mcc": 0.2711630722733202,
        "accuracy": 0.42857142857142855,
        "precision": 1.0,
        "recall": 0.29411764705882354,
        "f1_score": 0.45454545454545453,
        "balanced_accuracy": 0.6470588235294118,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}