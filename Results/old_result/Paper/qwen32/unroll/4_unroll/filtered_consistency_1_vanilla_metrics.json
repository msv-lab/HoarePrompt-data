{
    "total_valid_rows": {
        "value": 56,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "20",
        "agreement_percentage": 35.714285714285715,
        "mcc": -0.28978767892878315,
        "accuracy": 0.35714285714285715,
        "precision": 0.3157894736842105,
        "recall": 0.20689655172413793,
        "f1_score": 0.25,
        "balanced_accuracy": 0.3627075351213282,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "23",
        "agreement_percentage": 41.07142857142857,
        "mcc": -0.17580321054464088,
        "accuracy": 0.4107142857142857,
        "precision": 0.4,
        "recall": 0.27586206896551724,
        "f1_score": 0.32653061224489793,
        "balanced_accuracy": 0.4157088122605364,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "20",
        "agreement_percentage": 35.714285714285715,
        "mcc": -0.31404897297863477,
        "accuracy": 0.35714285714285715,
        "precision": 0.40540540540540543,
        "recall": 0.5172413793103449,
        "f1_score": 0.4545454545454546,
        "balanced_accuracy": 0.35121328224776505,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "22",
        "agreement_percentage": 39.285714285714285,
        "mcc": -0.23068188848261104,
        "accuracy": 0.39285714285714285,
        "precision": 0.42857142857142855,
        "recall": 0.5172413793103449,
        "f1_score": 0.46875000000000006,
        "balanced_accuracy": 0.388250319284802,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "22",
        "agreement_percentage": 39.285714285714285,
        "mcc": -0.21951508901390604,
        "accuracy": 0.39285714285714285,
        "precision": 0.41935483870967744,
        "recall": 0.4482758620689655,
        "f1_score": 0.4333333333333333,
        "balanced_accuracy": 0.3908045977011494,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "21",
        "agreement_percentage": 37.5,
        "mcc": -0.2799462554779272,
        "accuracy": 0.375,
        "precision": 0.25,
        "recall": 0.10344827586206896,
        "f1_score": 0.14634146341463414,
        "balanced_accuracy": 0.3850574712643678,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "22",
        "agreement_percentage": 39.285714285714285,
        "mcc": -0.23068188848261104,
        "accuracy": 0.39285714285714285,
        "precision": 0.42857142857142855,
        "recall": 0.5172413793103449,
        "f1_score": 0.46875000000000006,
        "balanced_accuracy": 0.388250319284802,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "20",
        "agreement_percentage": 35.714285714285715,
        "mcc": -0.2840811032184671,
        "accuracy": 0.35714285714285715,
        "precision": 0.34782608695652173,
        "recall": 0.27586206896551724,
        "f1_score": 0.3076923076923077,
        "balanced_accuracy": 0.36015325670498083,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "21",
        "agreement_percentage": 37.5,
        "mcc": -0.24826867189117374,
        "accuracy": 0.375,
        "precision": 0.36363636363636365,
        "recall": 0.27586206896551724,
        "f1_score": 0.3137254901960784,
        "balanced_accuracy": 0.3786717752234994,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "20",
        "agreement_percentage": 35.714285714285715,
        "mcc": -0.2840811032184671,
        "accuracy": 0.35714285714285715,
        "precision": 0.34782608695652173,
        "recall": 0.27586206896551724,
        "f1_score": 0.3076923076923077,
        "balanced_accuracy": 0.36015325670498083,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "21",
        "agreement_percentage": 37.5,
        "mcc": -0.24826867189117374,
        "accuracy": 0.375,
        "precision": 0.36363636363636365,
        "recall": 0.27586206896551724,
        "f1_score": 0.3137254901960784,
        "balanced_accuracy": 0.3786717752234994,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "20",
        "agreement_percentage": 35.714285714285715,
        "mcc": -0.28604554171843766,
        "accuracy": 0.35714285714285715,
        "precision": 0.3333333333333333,
        "recall": 0.2413793103448276,
        "f1_score": 0.28,
        "balanced_accuracy": 0.3614303959131545,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "19",
        "agreement_percentage": 33.92857142857143,
        "mcc": -0.3249695710067604,
        "accuracy": 0.3392857142857143,
        "precision": 0.3,
        "recall": 0.20689655172413793,
        "f1_score": 0.24489795918367346,
        "balanced_accuracy": 0.3441890166028097,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}