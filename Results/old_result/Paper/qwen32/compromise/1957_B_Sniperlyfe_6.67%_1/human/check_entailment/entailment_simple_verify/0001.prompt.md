
You are a program verifier. Your task is to evaluate the correctness of a Python program based on a given problem description, the program code, an initial assessment, and an annotated version of the code. The annotations describe the program's state at key points.

Task:
1. Analyze the problem description, the program code, and the original assessment. Assume valid inputs.
2. Use the annotated version to systematically evaluate the program’s behavior and reasoning. Use the annotations to validate or challenge the original assessment.
3. Decide whether to maintain or overturn the original assessment based on the evidence.

Reason about the code and explain if the  original assessment was accurate or inaccurate.
Then provide the final evaluation Final: **True** if the given program is correct  or Final: **False** if the given program is incorrect.

- Problem description: 
Given integers n and k , construct a sequence of n non-negative (i.e. \geq 0 )
integers a_1, a_2, \ldots, a_n such that

  1. \sum\limits_{i = 1}^n a_i = k 
  2. The number of 1 s in the binary representation of a_1 | a_2 | \ldots | a_n is maximized, where | denotes the [bitwise OR operation](https://en.wikipedia.org/wiki/Bitwise_operation#OR). 

Input

The first line contains a single integer t (1 \leq t \leq 10^4 ) — the number
of test cases.

The only line of each test case contains two integers n and k (1 \leq n \leq 2
\cdot 10^5 , 1 \leq k \leq 10^9 ) — the number of non-negative integers to be
printed and the sum respectively.

It is guaranteed that the sum of n over all test cases does not exceed 2 \cdot
10^5 .

Output

For each test case, output a sequence a_1, a_2, \ldots, a_n on a new line that
satisfies the conditions given above.

If there are multiple solutions, print any of them.

Example

Input

    4
    
    1 5
    
    2 3
    
    2 5
    
    6 51

Output

    5
    1 2
    5 0
    3 1 1 32 2 12

Note

In the first test case, we have to print exactly one integer, hence we can
only output 5 as the answer.

In the second test case, we output 1, 2 which sum up to 3 , and 1 | 2 = (11)_2 has two 1 s in its binary representation, which is the maximum we can achieve in these constraints.

In the fourth test case, we output 3, 1, 1, 32, 2, 12 which sum up to 51 , and 3 | 1 | 1 | 32 | 2 | 12 = (101\,111)_2 has five 1 s in its binary representation, which is the maximum we can achieve in these constraints.

- Program: 
t = int(input())
results = []
for _ in range(t):
    (n, k) = map(int, input().split())
    result = func_1(n, k)
    results.append(' '.join(map(str, result)))
print('\n'.join(results))

def func_1(n, k):
    nums = [0] * n
    for i in range(n):
        nums[i] = (1 << k.bit_length() - 1) - 1
        k -= nums[i]
    nums[-1] += k
    return nums



- Annotated Code: 
t = int(input())
results = []
for _ in range(t):
    (n, k) = map(int, input().split())
    result = func_1(n, k)
    results.append(' '.join(map(str, result)))
print('\n'.join(results))

#State of the program right berfore the function call: t is an integer such that 1 ≤ t ≤ 10^4, and for each test case, n and k are integers such that 1 ≤ n ≤ 2 · 10^5 and 1 ≤ k ≤ 10^9. The sum of n over all test cases does not exceed 2 · 10^5.
def func_1(n, k):
    nums = [0] * n
    for i in range(n):
        nums[i] = (1 << k.bit_length() - 1) - 1
        
        k -= nums[i]
        
    #State: `t` is an integer such that 1 ≤ t ≤ 10^4, `n` and `k` are integers such that 1 ≤ n ≤ 2 · 10^5 and 1 ≤ k ≤ 10^9 (reduced by the sum of the largest numbers representable with `k.bit_length() - 1` bits for each iteration), and `nums` is a list of `n` elements, each being the largest number representable with `k.bit_length() - 1` bits at the time of its assignment.
    nums[-1] += k
    return nums
    #The program returns a list `nums` containing `n` elements, where each element except the last one is the largest number representable with `k.bit_length() - 1` bits, and the last element is the largest number representable with `k.bit_length() - 1` bits plus `k`.



Beggining of Original Assessment: 
Let's analyze the provided program step by step to determine its correctness based on the problem description.

### Problem Analysis:
1. **Sum Constraint**: The sequence \( a_1, a_2, \ldots, a_n \) must satisfy \( \sum_{i=1}^n a_i = k \).
2. **Bitwise OR Constraint**: The number of 1s in the binary representation of \( a_1 | a_2 | \ldots | a_n \) should be maximized.

### Program Analysis:
The provided program constructs the sequence as follows:
1. It initializes a list `nums` of size `n` with all elements set to 0.
2. It then iterates over the list, setting each element to \( (1 << k.bit_length() - 1) - 1 \) and subtracting this value from `k`.
3. After the loop, it adds the remaining value of `k` to the last element of the list.
4. It returns the list `nums`.

### Issues in the Program:
1. **Incorrect Bitwise OR Maximization**: The program does not correctly maximize the number of 1s in the binary representation of the bitwise OR of the sequence.
2. **Incorrect Handling of Remaining Sum**: The program simply adds the remaining `k` to the last element, which does not necessarily maximize the number of 1s in the bitwise OR.

### Correct Approach:
To maximize the number of 1s in the bitwise OR:
1. Distribute the sum `k` such that as many bits as possible are set to 1 across the sequence.
2. Start by setting the least significant bits of the numbers in the sequence to 1 until `k` is exhausted.

### Correctness Evaluation:
Given the issues identified in the program, it does not correctly solve the problem as described. The provided program does not ensure that the number of 1s in the binary representation of the bitwise OR of the sequence is maximized.

### Conclusion:
Correctness: **False**

End of Original Assessment

Your Response: 
Reasoning: [Your explanation] 
Final: **True** or **False**

