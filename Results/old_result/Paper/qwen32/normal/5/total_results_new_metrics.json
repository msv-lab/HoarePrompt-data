{
    "total_valid_rows": {
        "value": 300,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "184",
        "agreement_percentage": 61.33333333333333,
        "mcc": 0.22612353138561853,
        "accuracy": 0.6133333333333333,
        "precision": 0.6451612903225806,
        "recall": 0.4195804195804196,
        "f1_score": 0.5084745762711865,
        "balanced_accuracy": 0.6046946683889359,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "177",
        "agreement_percentage": 59.0,
        "mcc": 0.2111889795507249,
        "accuracy": 0.59,
        "precision": 0.7380952380952381,
        "recall": 0.21678321678321677,
        "f1_score": 0.3351351351351351,
        "balanced_accuracy": 0.5733597612578505,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "178",
        "agreement_percentage": 59.333333333333336,
        "mcc": 0.18242204809029655,
        "accuracy": 0.5933333333333334,
        "precision": 0.5801526717557252,
        "recall": 0.5314685314685315,
        "f1_score": 0.5547445255474454,
        "balanced_accuracy": 0.590575030065476,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "188",
        "agreement_percentage": 62.66666666666667,
        "mcc": 0.25085912345056455,
        "accuracy": 0.6266666666666667,
        "precision": 0.6115107913669064,
        "recall": 0.5944055944055944,
        "f1_score": 0.6028368794326241,
        "balanced_accuracy": 0.6252282749098035,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "174",
        "agreement_percentage": 57.99999999999999,
        "mcc": 0.15324053457983558,
        "accuracy": 0.58,
        "precision": 0.5779816513761468,
        "recall": 0.4405594405594406,
        "f1_score": 0.5,
        "balanced_accuracy": 0.573782904993096,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "179",
        "agreement_percentage": 59.66666666666667,
        "mcc": 0.20689207193252537,
        "accuracy": 0.5966666666666667,
        "precision": 0.6833333333333333,
        "recall": 0.2867132867132867,
        "f1_score": 0.40394088669950745,
        "balanced_accuracy": 0.582847089216516,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "186",
        "agreement_percentage": 62.0,
        "mcc": 0.23604600009760213,
        "accuracy": 0.62,
        "precision": 0.6124031007751938,
        "recall": 0.5524475524475524,
        "f1_score": 0.5808823529411765,
        "balanced_accuracy": 0.6169881074339673,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "181",
        "agreement_percentage": 60.333333333333336,
        "mcc": 0.20163446375317648,
        "accuracy": 0.6033333333333334,
        "precision": 0.6071428571428571,
        "recall": 0.4755244755244755,
        "f1_score": 0.5333333333333333,
        "balanced_accuracy": 0.5976348492272059,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "169",
        "agreement_percentage": 56.333333333333336,
        "mcc": 0.11830521896165996,
        "accuracy": 0.5633333333333334,
        "precision": 0.5566037735849056,
        "recall": 0.4125874125874126,
        "f1_score": 0.4738955823293173,
        "balanced_accuracy": 0.5566121776312859,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "184",
        "agreement_percentage": 61.33333333333333,
        "mcc": 0.22548887454043373,
        "accuracy": 0.6133333333333333,
        "precision": 0.6421052631578947,
        "recall": 0.42657342657342656,
        "f1_score": 0.5126050420168068,
        "balanced_accuracy": 0.6050064585096433,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "192",
        "agreement_percentage": 64.0,
        "mcc": 0.2838449178273846,
        "accuracy": 0.64,
        "precision": 0.6881720430107527,
        "recall": 0.44755244755244755,
        "f1_score": 0.5423728813559322,
        "balanced_accuracy": 0.6314195358781346,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "185",
        "agreement_percentage": 61.66666666666667,
        "mcc": 0.23532028558342438,
        "accuracy": 0.6166666666666667,
        "precision": 0.6590909090909091,
        "recall": 0.40559440559440557,
        "f1_score": 0.5021645021645021,
        "balanced_accuracy": 0.6072558015233175,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "178",
        "agreement_percentage": 59.333333333333336,
        "mcc": 0.1933104698076319,
        "accuracy": 0.5933333333333334,
        "precision": 0.6567164179104478,
        "recall": 0.3076923076923077,
        "f1_score": 0.41904761904761906,
        "balanced_accuracy": 0.5805977462028418,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}