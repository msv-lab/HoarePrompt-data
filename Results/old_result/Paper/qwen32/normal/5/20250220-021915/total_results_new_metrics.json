{
    "total_valid_rows": {
        "value": 102,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "59",
        "agreement_percentage": 57.84313725490197,
        "mcc": 0.16219409183572184,
        "accuracy": 0.5784313725490197,
        "precision": 0.6129032258064516,
        "recall": 0.38,
        "f1_score": 0.46913580246913583,
        "balanced_accuracy": 0.5746153846153846,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "57",
        "agreement_percentage": 55.88235294117647,
        "mcc": 0.14657902694650268,
        "accuracy": 0.5588235294117647,
        "precision": 0.6666666666666666,
        "recall": 0.2,
        "f1_score": 0.30769230769230765,
        "balanced_accuracy": 0.551923076923077,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "58",
        "agreement_percentage": 56.86274509803921,
        "mcc": 0.136013826901741,
        "accuracy": 0.5686274509803921,
        "precision": 0.5652173913043478,
        "recall": 0.52,
        "f1_score": 0.5416666666666667,
        "balanced_accuracy": 0.5676923076923077,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "66",
        "agreement_percentage": 64.70588235294117,
        "mcc": 0.29584010465345556,
        "accuracy": 0.6470588235294118,
        "precision": 0.6296296296296297,
        "recall": 0.68,
        "f1_score": 0.6538461538461539,
        "balanced_accuracy": 0.6476923076923078,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "57",
        "agreement_percentage": 55.88235294117647,
        "mcc": 0.11677197808748507,
        "accuracy": 0.5588235294117647,
        "precision": 0.5675675675675675,
        "recall": 0.42,
        "f1_score": 0.4827586206896552,
        "balanced_accuracy": 0.5561538461538461,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "58",
        "agreement_percentage": 56.86274509803921,
        "mcc": 0.15787341451105966,
        "accuracy": 0.5686274509803921,
        "precision": 0.65,
        "recall": 0.26,
        "f1_score": 0.37142857142857144,
        "balanced_accuracy": 0.5626923076923077,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "63",
        "agreement_percentage": 61.76470588235294,
        "mcc": 0.2346617285702987,
        "accuracy": 0.6176470588235294,
        "precision": 0.6222222222222222,
        "recall": 0.56,
        "f1_score": 0.5894736842105264,
        "balanced_accuracy": 0.6165384615384616,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "57",
        "agreement_percentage": 55.88235294117647,
        "mcc": 0.11632098689450006,
        "accuracy": 0.5588235294117647,
        "precision": 0.5641025641025641,
        "recall": 0.44,
        "f1_score": 0.49438202247191015,
        "balanced_accuracy": 0.5565384615384615,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "55",
        "agreement_percentage": 53.92156862745098,
        "mcc": 0.07598176656377453,
        "accuracy": 0.5392156862745098,
        "precision": 0.5405405405405406,
        "recall": 0.4,
        "f1_score": 0.45977011494252873,
        "balanced_accuracy": 0.5365384615384616,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "56",
        "agreement_percentage": 54.90196078431373,
        "mcc": 0.0970725343394151,
        "accuracy": 0.5490196078431373,
        "precision": 0.5588235294117647,
        "recall": 0.38,
        "f1_score": 0.4523809523809524,
        "balanced_accuracy": 0.5457692307692308,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "63",
        "agreement_percentage": 61.76470588235294,
        "mcc": 0.2391426126586167,
        "accuracy": 0.6176470588235294,
        "precision": 0.6486486486486487,
        "recall": 0.48,
        "f1_score": 0.5517241379310345,
        "balanced_accuracy": 0.615,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "64",
        "agreement_percentage": 62.745098039215684,
        "mcc": 0.2634825932069838,
        "accuracy": 0.6274509803921569,
        "precision": 0.6764705882352942,
        "recall": 0.46,
        "f1_score": 0.5476190476190477,
        "balanced_accuracy": 0.6242307692307693,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "58",
        "agreement_percentage": 56.86274509803921,
        "mcc": 0.15333130636138698,
        "accuracy": 0.5686274509803921,
        "precision": 0.6363636363636364,
        "recall": 0.28,
        "f1_score": 0.3888888888888889,
        "balanced_accuracy": 0.563076923076923,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}