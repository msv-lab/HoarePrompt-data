{
    "total_valid_rows": {
        "value": 23,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "14",
        "agreement_percentage": 60.86956521739131,
        "mcc": 0.17565506213798923,
        "accuracy": 0.6086956521739131,
        "precision": 0.8461538461538461,
        "recall": 0.6111111111111112,
        "f1_score": 0.7096774193548387,
        "balanced_accuracy": 0.6055555555555556,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "5",
        "agreement_percentage": 21.73913043478261,
        "mcc": -0.3143730417143384,
        "accuracy": 0.21739130434782608,
        "precision": 0.5,
        "recall": 0.1111111111111111,
        "f1_score": 0.1818181818181818,
        "balanced_accuracy": 0.3555555555555555,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "14",
        "agreement_percentage": 60.86956521739131,
        "mcc": -0.07305950062660077,
        "accuracy": 0.6086956521739131,
        "precision": 0.7647058823529411,
        "recall": 0.7222222222222222,
        "f1_score": 0.7428571428571428,
        "balanced_accuracy": 0.46111111111111114,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "12",
        "agreement_percentage": 52.17391304347826,
        "mcc": -0.036980013081681945,
        "accuracy": 0.5217391304347826,
        "precision": 0.7692307692307693,
        "recall": 0.5555555555555556,
        "f1_score": 0.6451612903225806,
        "balanced_accuracy": 0.4777777777777778,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "8",
        "agreement_percentage": 34.78260869565217,
        "mcc": -0.10956262252231942,
        "accuracy": 0.34782608695652173,
        "precision": 0.7142857142857143,
        "recall": 0.2777777777777778,
        "f1_score": 0.4,
        "balanced_accuracy": 0.4388888888888889,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "2",
        "agreement_percentage": 8.695652173913043,
        "mcc": -0.7348469228349533,
        "accuracy": 0.08695652173913043,
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.2,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "17",
        "agreement_percentage": 73.91304347826086,
        "mcc": 0.44135833302489197,
        "accuracy": 0.7391304347826086,
        "precision": 0.9285714285714286,
        "recall": 0.7222222222222222,
        "f1_score": 0.8125000000000001,
        "balanced_accuracy": 0.7611111111111111,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "6",
        "agreement_percentage": 26.08695652173913,
        "mcc": -0.3386481059780782,
        "accuracy": 0.2608695652173913,
        "precision": 0.5714285714285714,
        "recall": 0.2222222222222222,
        "f1_score": 0.32,
        "balanced_accuracy": 0.3111111111111111,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "8",
        "agreement_percentage": 34.78260869565217,
        "mcc": -0.10956262252231942,
        "accuracy": 0.34782608695652173,
        "precision": 0.7142857142857143,
        "recall": 0.2777777777777778,
        "f1_score": 0.4,
        "balanced_accuracy": 0.4388888888888889,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "9",
        "agreement_percentage": 39.130434782608695,
        "mcc": -0.17565506213798923,
        "accuracy": 0.391304347826087,
        "precision": 0.7,
        "recall": 0.3888888888888889,
        "f1_score": 0.5,
        "balanced_accuracy": 0.3944444444444445,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "8",
        "agreement_percentage": 34.78260869565217,
        "mcc": 0.022222222222222223,
        "accuracy": 0.34782608695652173,
        "precision": 0.8,
        "recall": 0.2222222222222222,
        "f1_score": 0.3478260869565218,
        "balanced_accuracy": 0.5111111111111111,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "10",
        "agreement_percentage": 43.47826086956522,
        "mcc": 0.11952286093343938,
        "accuracy": 0.43478260869565216,
        "precision": 0.8571428571428571,
        "recall": 0.3333333333333333,
        "f1_score": 0.48,
        "balanced_accuracy": 0.5666666666666667,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "8",
        "agreement_percentage": 34.78260869565217,
        "mcc": -0.10956262252231942,
        "accuracy": 0.34782608695652173,
        "precision": 0.7142857142857143,
        "recall": 0.2777777777777778,
        "f1_score": 0.4,
        "balanced_accuracy": 0.4388888888888889,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}