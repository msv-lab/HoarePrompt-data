{
    "total_valid_rows": {
        "value": 101,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "57",
        "agreement_percentage": 56.43564356435643,
        "mcc": 0.11899573993292296,
        "accuracy": 0.5643564356435643,
        "precision": 0.5666666666666667,
        "recall": 0.3541666666666667,
        "f1_score": 0.4358974358974359,
        "balanced_accuracy": 0.5544418238993711,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "53",
        "agreement_percentage": 52.475247524752476,
        "mcc": 0.01988318011754622,
        "accuracy": 0.5247524752475248,
        "precision": 0.5,
        "recall": 0.14583333333333334,
        "f1_score": 0.22580645161290322,
        "balanced_accuracy": 0.50687893081761,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "62",
        "agreement_percentage": 61.386138613861384,
        "mcc": 0.22393616425306867,
        "accuracy": 0.6138613861386139,
        "precision": 0.6,
        "recall": 0.5625,
        "f1_score": 0.5806451612903225,
        "balanced_accuracy": 0.6114386792452831,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "59",
        "agreement_percentage": 58.415841584158414,
        "mcc": 0.16249909947493812,
        "accuracy": 0.5841584158415841,
        "precision": 0.5714285714285714,
        "recall": 0.5,
        "f1_score": 0.5333333333333333,
        "balanced_accuracy": 0.5801886792452831,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "49",
        "agreement_percentage": 48.51485148514851,
        "mcc": -0.057886185498039984,
        "accuracy": 0.48514851485148514,
        "precision": 0.42857142857142855,
        "recall": 0.25,
        "f1_score": 0.3157894736842105,
        "balanced_accuracy": 0.4740566037735849,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "57",
        "agreement_percentage": 56.43564356435643,
        "mcc": 0.1407485096960188,
        "accuracy": 0.5643564356435643,
        "precision": 0.6666666666666666,
        "recall": 0.16666666666666666,
        "f1_score": 0.26666666666666666,
        "balanced_accuracy": 0.5455974842767296,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "56",
        "agreement_percentage": 55.44554455445545,
        "mcc": 0.10039512975146071,
        "accuracy": 0.5544554455445545,
        "precision": 0.5384615384615384,
        "recall": 0.4375,
        "f1_score": 0.4827586206896552,
        "balanced_accuracy": 0.5489386792452831,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "57",
        "agreement_percentage": 56.43564356435643,
        "mcc": 0.12083472398628567,
        "accuracy": 0.5643564356435643,
        "precision": 0.5833333333333334,
        "recall": 0.2916666666666667,
        "f1_score": 0.38888888888888895,
        "balanced_accuracy": 0.551493710691824,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "56",
        "agreement_percentage": 55.44554455445545,
        "mcc": 0.0973371036710863,
        "accuracy": 0.5544554455445545,
        "precision": 0.56,
        "recall": 0.2916666666666667,
        "f1_score": 0.3835616438356164,
        "balanced_accuracy": 0.542059748427673,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "55",
        "agreement_percentage": 54.45544554455446,
        "mcc": 0.07425339909080914,
        "accuracy": 0.5445544554455446,
        "precision": 0.5416666666666666,
        "recall": 0.2708333333333333,
        "f1_score": 0.36111111111111105,
        "balanced_accuracy": 0.5316430817610063,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "56",
        "agreement_percentage": 55.44554455445545,
        "mcc": 0.09713770072795648,
        "accuracy": 0.5544554455445545,
        "precision": 0.5555555555555556,
        "recall": 0.3125,
        "f1_score": 0.39999999999999997,
        "balanced_accuracy": 0.5430424528301887,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "51",
        "agreement_percentage": 50.495049504950494,
        "mcc": -0.01616317375321096,
        "accuracy": 0.504950495049505,
        "precision": 0.46153846153846156,
        "recall": 0.25,
        "f1_score": 0.32432432432432434,
        "balanced_accuracy": 0.49292452830188677,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "56",
        "agreement_percentage": 55.44554455445545,
        "mcc": 0.09867723529517157,
        "accuracy": 0.5544554455445545,
        "precision": 0.5714285714285714,
        "recall": 0.25,
        "f1_score": 0.34782608695652173,
        "balanced_accuracy": 0.5400943396226415,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}