{
    "total_valid_rows": {
        "value": 24,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "10",
        "agreement_percentage": 41.66666666666667,
        "mcc": -0.1690308509457033,
        "accuracy": 0.4166666666666667,
        "precision": 0.42857142857142855,
        "recall": 0.5,
        "f1_score": 0.4615384615384615,
        "balanced_accuracy": 0.41666666666666663,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "10",
        "agreement_percentage": 41.66666666666667,
        "mcc": -0.1767766952966369,
        "accuracy": 0.4166666666666667,
        "precision": 0.375,
        "recall": 0.25,
        "f1_score": 0.3,
        "balanced_accuracy": 0.4166666666666667,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "11",
        "agreement_percentage": 45.83333333333333,
        "mcc": -0.10259783520851541,
        "accuracy": 0.4583333333333333,
        "precision": 0.47368421052631576,
        "recall": 0.75,
        "f1_score": 0.5806451612903226,
        "balanced_accuracy": 0.4583333333333333,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "14",
        "agreement_percentage": 58.333333333333336,
        "mcc": 0.22360679774997896,
        "accuracy": 0.5833333333333334,
        "precision": 0.55,
        "recall": 0.9166666666666666,
        "f1_score": 0.6874999999999999,
        "balanced_accuracy": 0.5833333333333333,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "12",
        "agreement_percentage": 50.0,
        "mcc": 0.0,
        "accuracy": 0.5,
        "precision": 0.5,
        "recall": 0.75,
        "f1_score": 0.6,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "8",
        "agreement_percentage": 33.33333333333333,
        "mcc": -0.3535533905932738,
        "accuracy": 0.3333333333333333,
        "precision": 0.25,
        "recall": 0.16666666666666666,
        "f1_score": 0.2,
        "balanced_accuracy": 0.3333333333333333,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "10",
        "agreement_percentage": 41.66666666666667,
        "mcc": -0.1767766952966369,
        "accuracy": 0.4166666666666667,
        "precision": 0.4375,
        "recall": 0.5833333333333334,
        "f1_score": 0.5,
        "balanced_accuracy": 0.4166666666666667,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "11",
        "agreement_percentage": 45.83333333333333,
        "mcc": -0.08606629658238706,
        "accuracy": 0.4583333333333333,
        "precision": 0.4666666666666667,
        "recall": 0.5833333333333334,
        "f1_score": 0.5185185185185186,
        "balanced_accuracy": 0.45833333333333337,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "14",
        "agreement_percentage": 58.333333333333336,
        "mcc": 0.1690308509457033,
        "accuracy": 0.5833333333333334,
        "precision": 0.5714285714285714,
        "recall": 0.6666666666666666,
        "f1_score": 0.6153846153846153,
        "balanced_accuracy": 0.5833333333333333,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "13",
        "agreement_percentage": 54.166666666666664,
        "mcc": 0.08362420100070908,
        "accuracy": 0.5416666666666666,
        "precision": 0.5384615384615384,
        "recall": 0.5833333333333334,
        "f1_score": 0.5599999999999999,
        "balanced_accuracy": 0.5416666666666667,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "14",
        "agreement_percentage": 58.333333333333336,
        "mcc": 0.16666666666666666,
        "accuracy": 0.5833333333333334,
        "precision": 0.5833333333333334,
        "recall": 0.5833333333333334,
        "f1_score": 0.5833333333333334,
        "balanced_accuracy": 0.5833333333333334,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "13",
        "agreement_percentage": 54.166666666666664,
        "mcc": 0.08362420100070908,
        "accuracy": 0.5416666666666666,
        "precision": 0.5454545454545454,
        "recall": 0.5,
        "f1_score": 0.5217391304347826,
        "balanced_accuracy": 0.5416666666666667,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "11",
        "agreement_percentage": 45.83333333333333,
        "mcc": -0.08362420100070908,
        "accuracy": 0.4583333333333333,
        "precision": 0.45454545454545453,
        "recall": 0.4166666666666667,
        "f1_score": 0.43478260869565216,
        "balanced_accuracy": 0.45833333333333337,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}