{
    "total_valid_rows": {
        "value": 21,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "11",
        "agreement_percentage": 52.38095238095239,
        "mcc": 0.08492077756084468,
        "accuracy": 0.5238095238095238,
        "precision": 0.46153846153846156,
        "recall": 0.6666666666666666,
        "f1_score": 0.5454545454545455,
        "balanced_accuracy": 0.5416666666666666,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "9",
        "agreement_percentage": 42.857142857142854,
        "mcc": -0.2041241452319315,
        "accuracy": 0.42857142857142855,
        "precision": 0.2857142857142857,
        "recall": 0.2222222222222222,
        "f1_score": 0.25,
        "balanced_accuracy": 0.4027777777777778,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "8",
        "agreement_percentage": 38.095238095238095,
        "mcc": -0.2041241452319315,
        "accuracy": 0.38095238095238093,
        "precision": 0.35714285714285715,
        "recall": 0.5555555555555556,
        "f1_score": 0.43478260869565216,
        "balanced_accuracy": 0.4027777777777778,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "9",
        "agreement_percentage": 42.857142857142854,
        "mcc": -0.046829290579084706,
        "accuracy": 0.42857142857142855,
        "precision": 0.42105263157894735,
        "recall": 0.8888888888888888,
        "f1_score": 0.5714285714285714,
        "balanced_accuracy": 0.4861111111111111,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "6",
        "agreement_percentage": 28.57142857142857,
        "mcc": -0.408248290463863,
        "accuracy": 0.2857142857142857,
        "precision": 0.2857142857142857,
        "recall": 0.4444444444444444,
        "f1_score": 0.34782608695652173,
        "balanced_accuracy": 0.3055555555555555,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "8",
        "agreement_percentage": 38.095238095238095,
        "mcc": -0.3347193406976015,
        "accuracy": 0.38095238095238093,
        "precision": 0.16666666666666666,
        "recall": 0.1111111111111111,
        "f1_score": 0.13333333333333333,
        "balanced_accuracy": 0.3472222222222222,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "7",
        "agreement_percentage": 33.33333333333333,
        "mcc": -0.31506301890630223,
        "accuracy": 0.3333333333333333,
        "precision": 0.35294117647058826,
        "recall": 0.6666666666666666,
        "f1_score": 0.46153846153846156,
        "balanced_accuracy": 0.375,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "11",
        "agreement_percentage": 52.38095238095239,
        "mcc": 0.027777777777777776,
        "accuracy": 0.5238095238095238,
        "precision": 0.4444444444444444,
        "recall": 0.4444444444444444,
        "f1_score": 0.4444444444444444,
        "balanced_accuracy": 0.5138888888888888,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "9",
        "agreement_percentage": 42.857142857142854,
        "mcc": -0.13762047064079508,
        "accuracy": 0.42857142857142855,
        "precision": 0.36363636363636365,
        "recall": 0.4444444444444444,
        "f1_score": 0.39999999999999997,
        "balanced_accuracy": 0.4305555555555556,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "8",
        "agreement_percentage": 38.095238095238095,
        "mcc": -0.2222222222222222,
        "accuracy": 0.38095238095238093,
        "precision": 0.3333333333333333,
        "recall": 0.4444444444444444,
        "f1_score": 0.380952380952381,
        "balanced_accuracy": 0.38888888888888884,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "12",
        "agreement_percentage": 57.14285714285714,
        "mcc": 0.16666666666666666,
        "accuracy": 0.5714285714285714,
        "precision": 0.5,
        "recall": 0.6666666666666666,
        "f1_score": 0.5714285714285715,
        "balanced_accuracy": 0.5833333333333333,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "11",
        "agreement_percentage": 52.38095238095239,
        "mcc": 0.05504818825631803,
        "accuracy": 0.5238095238095238,
        "precision": 0.45454545454545453,
        "recall": 0.5555555555555556,
        "f1_score": 0.5,
        "balanced_accuracy": 0.5277777777777778,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "9",
        "agreement_percentage": 42.857142857142854,
        "mcc": -0.13762047064079508,
        "accuracy": 0.42857142857142855,
        "precision": 0.36363636363636365,
        "recall": 0.4444444444444444,
        "f1_score": 0.39999999999999997,
        "balanced_accuracy": 0.4305555555555556,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}