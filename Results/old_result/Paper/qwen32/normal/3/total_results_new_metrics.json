{
    "total_valid_rows": {
        "value": 301,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "181",
        "agreement_percentage": 60.13289036544851,
        "mcc": 0.1997550939651915,
        "accuracy": 0.6013289036544851,
        "precision": 0.6375,
        "recall": 0.3591549295774648,
        "f1_score": 0.4594594594594595,
        "balanced_accuracy": 0.5883824962352733,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "170",
        "agreement_percentage": 56.47840531561462,
        "mcc": 0.12917437844278237,
        "accuracy": 0.5647840531561462,
        "precision": 0.6341463414634146,
        "recall": 0.18309859154929578,
        "f1_score": 0.2841530054644809,
        "balanced_accuracy": 0.5443794844538932,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "184",
        "agreement_percentage": 61.12956810631229,
        "mcc": 0.2170926330547865,
        "accuracy": 0.6112956810631229,
        "precision": 0.5968992248062015,
        "recall": 0.5422535211267606,
        "f1_score": 0.5682656826568265,
        "balanced_accuracy": 0.6076047479847639,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "193",
        "agreement_percentage": 64.11960132890366,
        "mcc": 0.2777266406880755,
        "accuracy": 0.6411960132890365,
        "precision": 0.6307692307692307,
        "recall": 0.5774647887323944,
        "f1_score": 0.6029411764705882,
        "balanced_accuracy": 0.6377889981397821,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "180",
        "agreement_percentage": 59.800664451827245,
        "mcc": 0.18816625170645893,
        "accuracy": 0.5980066445182725,
        "precision": 0.5929203539823009,
        "recall": 0.47183098591549294,
        "f1_score": 0.5254901960784313,
        "balanced_accuracy": 0.591261404907432,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "176",
        "agreement_percentage": 58.4717607973422,
        "mcc": 0.18738019866924568,
        "accuracy": 0.584717607973422,
        "precision": 0.7073170731707317,
        "recall": 0.20422535211267606,
        "f1_score": 0.31693989071038253,
        "balanced_accuracy": 0.5643768269997342,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "191",
        "agreement_percentage": 63.45514950166113,
        "mcc": 0.26359026027783644,
        "accuracy": 0.6345514950166113,
        "precision": 0.6311475409836066,
        "recall": 0.5422535211267606,
        "f1_score": 0.5833333333333334,
        "balanced_accuracy": 0.6296173266011161,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "174",
        "agreement_percentage": 57.80730897009967,
        "mcc": 0.14584299014745944,
        "accuracy": 0.5780730897009967,
        "precision": 0.5757575757575758,
        "recall": 0.4014084507042254,
        "f1_score": 0.47302904564315357,
        "balanced_accuracy": 0.5686287536539995,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "174",
        "agreement_percentage": 57.80730897009967,
        "mcc": 0.1458116859988864,
        "accuracy": 0.5780730897009967,
        "precision": 0.5789473684210527,
        "recall": 0.3873239436619718,
        "f1_score": 0.4641350210970464,
        "balanced_accuracy": 0.5678758083089733,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "175",
        "agreement_percentage": 58.139534883720934,
        "mcc": 0.1530055294593925,
        "accuracy": 0.5813953488372093,
        "precision": 0.5851063829787234,
        "recall": 0.3873239436619718,
        "f1_score": 0.4661016949152542,
        "balanced_accuracy": 0.5710204623970236,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "181",
        "agreement_percentage": 60.13289036544851,
        "mcc": 0.2083135346393997,
        "accuracy": 0.6013289036544851,
        "precision": 0.671875,
        "recall": 0.3028169014084507,
        "f1_score": 0.4174757281553398,
        "balanced_accuracy": 0.5853707148551688,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "178",
        "agreement_percentage": 59.136212624584715,
        "mcc": 0.18333847236041204,
        "accuracy": 0.5913621262458472,
        "precision": 0.6461538461538462,
        "recall": 0.29577464788732394,
        "f1_score": 0.4057971014492754,
        "balanced_accuracy": 0.5755602799185048,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "178",
        "agreement_percentage": 59.136212624584715,
        "mcc": 0.18870838305871013,
        "accuracy": 0.5913621262458472,
        "precision": 0.6666666666666666,
        "recall": 0.2676056338028169,
        "f1_score": 0.3819095477386934,
        "balanced_accuracy": 0.5740543892284524,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}