{
    "total_valid_rows": {
        "value": 14,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "8",
        "agreement_percentage": 57.14285714285714,
        "mcc": 0.14907119849998599,
        "accuracy": 0.5714285714285714,
        "precision": 0.7142857142857143,
        "recall": 0.5555555555555556,
        "f1_score": 0.6250000000000001,
        "balanced_accuracy": 0.5777777777777777,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "4",
        "agreement_percentage": 28.57142857142857,
        "mcc": -0.3721042037676254,
        "accuracy": 0.2857142857142857,
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.4,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "8",
        "agreement_percentage": 57.14285714285714,
        "mcc": -0.025949964805384102,
        "accuracy": 0.5714285714285714,
        "precision": 0.6363636363636364,
        "recall": 0.7777777777777778,
        "f1_score": 0.7000000000000001,
        "balanced_accuracy": 0.48888888888888893,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "10",
        "agreement_percentage": 71.42857142857143,
        "mcc": 0.37777777777777777,
        "accuracy": 0.7142857142857143,
        "precision": 0.7777777777777778,
        "recall": 0.7777777777777778,
        "f1_score": 0.7777777777777778,
        "balanced_accuracy": 0.6888888888888889,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "10",
        "agreement_percentage": 71.42857142857143,
        "mcc": 0.37777777777777777,
        "accuracy": 0.7142857142857143,
        "precision": 0.7777777777777778,
        "recall": 0.7777777777777778,
        "f1_score": 0.7777777777777778,
        "balanced_accuracy": 0.6888888888888889,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "10",
        "agreement_percentage": 71.42857142857143,
        "mcc": 0.5555555555555556,
        "accuracy": 0.7142857142857143,
        "precision": 1.0,
        "recall": 0.5555555555555556,
        "f1_score": 0.7142857142857143,
        "balanced_accuracy": 0.7777777777777778,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "12",
        "agreement_percentage": 85.71428571428571,
        "mcc": 0.7006490497453707,
        "accuracy": 0.8571428571428571,
        "precision": 0.8181818181818182,
        "recall": 1.0,
        "f1_score": 0.9,
        "balanced_accuracy": 0.8,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "9",
        "agreement_percentage": 64.28571428571429,
        "mcc": 0.25819888974716115,
        "accuracy": 0.6428571428571429,
        "precision": 0.75,
        "recall": 0.6666666666666666,
        "f1_score": 0.7058823529411765,
        "balanced_accuracy": 0.6333333333333333,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "8",
        "agreement_percentage": 57.14285714285714,
        "mcc": 0.14907119849998599,
        "accuracy": 0.5714285714285714,
        "precision": 0.7142857142857143,
        "recall": 0.5555555555555556,
        "f1_score": 0.6250000000000001,
        "balanced_accuracy": 0.5777777777777777,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "8",
        "agreement_percentage": 57.14285714285714,
        "mcc": 0.14907119849998599,
        "accuracy": 0.5714285714285714,
        "precision": 0.7142857142857143,
        "recall": 0.5555555555555556,
        "f1_score": 0.6250000000000001,
        "balanced_accuracy": 0.5777777777777777,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "7",
        "agreement_percentage": 50.0,
        "mcc": 0.04303314829119352,
        "accuracy": 0.5,
        "precision": 0.6666666666666666,
        "recall": 0.4444444444444444,
        "f1_score": 0.5333333333333333,
        "balanced_accuracy": 0.5222222222222221,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "7",
        "agreement_percentage": 50.0,
        "mcc": 0.04303314829119352,
        "accuracy": 0.5,
        "precision": 0.6666666666666666,
        "recall": 0.4444444444444444,
        "f1_score": 0.5333333333333333,
        "balanced_accuracy": 0.5222222222222221,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "7",
        "agreement_percentage": 50.0,
        "mcc": 0.04303314829119352,
        "accuracy": 0.5,
        "precision": 0.6666666666666666,
        "recall": 0.4444444444444444,
        "f1_score": 0.5333333333333333,
        "balanced_accuracy": 0.5222222222222221,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}