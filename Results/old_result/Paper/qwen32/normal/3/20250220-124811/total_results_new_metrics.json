{
    "total_valid_rows": {
        "value": 100,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "60",
        "agreement_percentage": 60.0,
        "mcc": 0.1945123112320916,
        "accuracy": 0.6,
        "precision": 0.6296296296296297,
        "recall": 0.3617021276595745,
        "f1_score": 0.4594594594594595,
        "balanced_accuracy": 0.5865114411882778,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "56",
        "agreement_percentage": 56.00000000000001,
        "mcc": 0.11260136051427588,
        "accuracy": 0.56,
        "precision": 0.6153846153846154,
        "recall": 0.1702127659574468,
        "f1_score": 0.26666666666666666,
        "balanced_accuracy": 0.5379365716579687,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "61",
        "agreement_percentage": 61.0,
        "mcc": 0.21353065802660115,
        "accuracy": 0.61,
        "precision": 0.5952380952380952,
        "recall": 0.5319148936170213,
        "f1_score": 0.5617977528089887,
        "balanced_accuracy": 0.6055800883179445,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "64",
        "agreement_percentage": 64.0,
        "mcc": 0.2741638980686992,
        "accuracy": 0.64,
        "precision": 0.6341463414634146,
        "recall": 0.5531914893617021,
        "f1_score": 0.5909090909090909,
        "balanced_accuracy": 0.6350863107185869,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "62",
        "agreement_percentage": 62.0,
        "mcc": 0.2331392627922652,
        "accuracy": 0.62,
        "precision": 0.6285714285714286,
        "recall": 0.46808510638297873,
        "f1_score": 0.5365853658536586,
        "balanced_accuracy": 0.6114010437575271,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "57",
        "agreement_percentage": 56.99999999999999,
        "mcc": 0.14551011371194295,
        "accuracy": 0.57,
        "precision": 0.6666666666666666,
        "recall": 0.1702127659574468,
        "f1_score": 0.2711864406779661,
        "balanced_accuracy": 0.5473705339221197,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "62",
        "agreement_percentage": 62.0,
        "mcc": 0.23291581282510734,
        "accuracy": 0.62,
        "precision": 0.6153846153846154,
        "recall": 0.5106382978723404,
        "f1_score": 0.558139534883721,
        "balanced_accuracy": 0.613809714973906,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "58",
        "agreement_percentage": 57.99999999999999,
        "mcc": 0.14859420199256476,
        "accuracy": 0.58,
        "precision": 0.5806451612903226,
        "recall": 0.3829787234042553,
        "f1_score": 0.46153846153846156,
        "balanced_accuracy": 0.5688478522681655,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "58",
        "agreement_percentage": 57.99999999999999,
        "mcc": 0.14859420199256476,
        "accuracy": 0.58,
        "precision": 0.5806451612903226,
        "recall": 0.3829787234042553,
        "f1_score": 0.46153846153846156,
        "balanced_accuracy": 0.5688478522681655,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "61",
        "agreement_percentage": 61.0,
        "mcc": 0.21597984939016518,
        "accuracy": 0.61,
        "precision": 0.6428571428571429,
        "recall": 0.3829787234042553,
        "f1_score": 0.48,
        "balanced_accuracy": 0.5971497390606182,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "62",
        "agreement_percentage": 62.0,
        "mcc": 0.24292477189715467,
        "accuracy": 0.62,
        "precision": 0.68,
        "recall": 0.3617021276595745,
        "f1_score": 0.4722222222222222,
        "balanced_accuracy": 0.6053793657165797,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "57",
        "agreement_percentage": 56.99999999999999,
        "mcc": 0.13023463370138993,
        "accuracy": 0.57,
        "precision": 0.6,
        "recall": 0.2553191489361702,
        "f1_score": 0.3582089552238805,
        "balanced_accuracy": 0.5521878763548775,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "58",
        "agreement_percentage": 57.99999999999999,
        "mcc": 0.1567949972350808,
        "accuracy": 0.58,
        "precision": 0.631578947368421,
        "recall": 0.2553191489361702,
        "f1_score": 0.3636363636363636,
        "balanced_accuracy": 0.5616218386190285,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}