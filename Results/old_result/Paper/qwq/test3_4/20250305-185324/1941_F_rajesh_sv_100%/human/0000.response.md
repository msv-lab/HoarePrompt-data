Alright, I have this problem to solve. Let's understand what's being asked here.

We have a set of n problems with unique complexities a1 < a2 < ... < an. Rudolf wants to add at most one new problem to this set to minimize the largest difference between any two consecutive complexities in the sorted list. This largest difference is what's being referred to as "imbalance."

He can create a new problem by combining one of m models with one of k functions, resulting in a problem with complexity d_i + f_j, where d_i is the complexity of the i-th model and f_j is the complexity of the j-th function.

My task is to determine the minimum possible imbalance that Rudolf can achieve by adding at most one such problem.

First, I need to understand the current state without adding any new problem. The imbalance is simply the maximum difference between consecutive a_i's.

By adding one problem with complexity x, where x is equal to d_i + f_j for some i and j, I can potentially reduce the maximum difference between consecutive complexities.

I need to find the best x to add to minimize this maximum difference.

Let's think about how adding a new problem affects the sequence.

Since the sequence is sorted, inserting x into the sequence will split one of the gaps between existing a_i's into two smaller gaps.

Specifically, if I insert x between a_p and a_{p+1}, the new gaps will be x - a_p and a_{p+1} - x.

The new maximum difference will be the maximum of the existing differences (excluding the one I split) and the two new differences.

My goal is to choose x such that the new maximum difference is as small as possible.

One way to approach this is to iterate through all possible positions to insert x and choose the x that minimizes the new maximum difference.

However, since m and k can be up to 2*10^5 each, iterating through all possible x (which could be up to 2*10^5 * 2*10^5 = 4*10^10) is not feasible due to time constraints.

Therefore, I need a smarter way to find the best x without checking every possible combination.

Let's consider the possible differences between consecutive a_i's.

Let's compute the differences: diff_i = a_{i+1} - a_i for i from 1 to n-1.

I need to reduce the maximum of these differences by adding one x.

Specifically, I need to find an x such that when I insert it into the sequence, the maximum of the new differences is minimized.

This sounds like a classic optimization problem where I can use binary search to find the smallest possible maximum difference.

But in this case, since I'm adding only one element, I need to find an x that minimally increases the smallest possible maximum difference.

Wait, perhaps I can think of it differently.

Let's consider that by adding x, I can split one of the differences into two smaller ones.

I need to choose which difference to split and what x to use to minimize the new maximum difference.

An optimal strategy would be to choose to split the largest difference, as that would have the most impact in reducing the maximum difference.

However, even then, choosing the best x to split that difference is crucial.

Let's formalize this.

Let me denote the differences as diff_1, diff_2, ..., diff_{n-1}, where diff_i = a_{i+1} - a_i.

Let current_max_diff be the maximum of these differences.

I want to reduce this current_max_diff by adding one x.

I need to find the smallest possible new_max_diff, where new_max_diff is the maximum of all the new differences after inserting x.

To minimize new_max_diff, I need to choose x such that the largest of the two new differences created by inserting x is as small as possible.

In other words, for each possible position to insert x, I need to compute the maximum of (x - a_p) and (a_{p+1} - x), and choose the x that minimizes this maximum.

This sounds like finding the x that balances the two differences as much as possible.

In fact, for a given position p, the optimal x is x = a_p + (a_{p+1} - a_p)/2.

But since x must be equal to d_i + f_j for some i and j, I need to find the x among the possible d_i + f_j values that is closest to this ideal x.

Wait, but m and k are large, and iterating through all possible d_i + f_j is not efficient.

I need a better way.

Let me consider that x is d_i + f_j.

Given that d_i and f_j can be combined in any way, the possible x values are all sums of one d and one f.

But since m and k are large, I need a way to handle this efficiently.

Perhaps I can fix the difference I want to split and find the best x among the possible d + f values.

But I need to consider all possible differences.

Wait, maybe I can iterate through all possible x = d + f and keep track of the new maximum difference for each x.

But again, with m and k up to 2*10^5, this would be too slow.

I need a smarter approach.

Let me consider that the best x to add is the one that minimizes the maximum difference after insertion.

To minimize the maximum difference, I should look for x that reduces the largest difference in the current sequence.

So, I should identify the largest difference in the current sequence and see if I can split it into two smaller differences by inserting x.

The idea is to choose x such that the larger of the two new differences is as small as possible.

In other words, for the largest difference between a_i and a_{i+1}, I want to choose x such that max(x - a_i, a_{i+1} - x) is minimized.

This is equivalent to choosing x as close as possible to the midpoint of a_i and a_{i+1}.

Given that, for each large difference, I can compute the ideal x as a_i + (a_{i+1} - a_i)/2, and then find the d + f value closest to this ideal x.

But again, with large m and k, iterating through all d + f is inefficient.

I need a way to find, for each such large difference, the d + f value that minimizes the maximum of (x - a_i) and (a_{i+1} - x).

Wait, perhaps I can iterate through all possible d + f values and, for each d + f, find the position where it can be inserted to reduce the maximum difference.

But that still seems too slow.

Let me think differently.

Suppose I fix a target maximum difference, say t.

I want to find if there exists an x = d + f such that, after inserting x into the sequence, the maximum difference between any two consecutive elements is at most t.

If I can find such an x, then t is achievable.

Otherwise, it's not.

If I can binary search on t to find the smallest t for which such an x exists, that would be efficient.

But I need to check, for a given t, whether there exists an x = d + f that, when inserted into the sequence, all differences between consecutive elements are at most t.

This sounds promising.

Let's see how to implement this check.

Given t, I need to ensure that after inserting x, all differences between consecutive elements are <= t.

This means that for each existing difference diff_i = a_{i+1} - a_i, either diff_i <= t, or there exists an x such that x is in [a_i + t - t, a_{i+1} - t], because inserting x in that range would split diff_i into two parts, both <= t.

Wait, more precisely, to have x - a_i <= t and a_{i+1} - x <= t, x must satisfy x >= a_i + t - t and x <= a_{i+1} - t.

But that seems off.

Wait, if I have x inserted between a_i and a_{i+1}, then x - a_i <= t and a_{i+1} - x <= t.

So x must be >= a_i + t and <= a_{i+1} - t.

Wait, no.

Wait, if x is inserted between a_i and a_{i+1}, then the differences are x - a_i and a_{i+1} - x.

For both of these to be <= t, we need x - a_i <= t and a_{i+1} - x <= t.

From x - a_i <= t, we get x <= a_i + t.

From a_{i+1} - x <= t, we get x >= a_{i+1} - t.

So x must satisfy a_{i+1} - t <= x <= a_i + t.

But since a_i < a_{i+1}, for this interval to be non-empty, we need a_{i+1} - t <= a_i + t, which implies t >= (a_{i+1} - a_i)/2.

So, for a given t, if for every difference greater than t, there exists an x = d + f in [a_{i+1} - t, a_i + t], then it's possible to achieve a maximum difference of t by inserting one x.

Wait, but I can have multiple differences greater than t, and I'm only allowed to insert one x.

So, actually, I need to ensure that there is at least one x = d + f that covers the largest difference in a way that splits it into two parts, each <= t.

But I'm getting confused.

Let me try to formalize this.

Define the current maximum difference as max_diff.

I want to find the smallest possible new_max_diff after inserting at most one x.

I can consider that new_max_diff is the maximum of:

- The differences that are already <= max_diff, but possibly reduced by inserting x.

- The two new differences created by inserting x into one of the gaps.

But this seems too vague.

Let me consider that the best strategy is to insert x into the largest difference, to split it into two smaller differences.

So, find the largest difference, say diff_max.

Then, choose x to minimize the larger of (x - a_p) and (a_{p+1} - x), where a_p and a_{p+1} are the complexities between which x is inserted.

This is equivalent to choosing x as close as possible to the midpoint of a_p and a_{p+1}.

Given that x must be equal to d_i + f_j for some i and j, I need to find the x among all possible d_i + f_j that minimizes the maximum of (x - a_p) and (a_{p+1} - x).

This is equivalent to finding the x that is closest to (a_p + a_{p+1}) / 2.

So, for the largest difference, find the x among d + f that is closest to the midpoint of that difference.

Then, compute the new maximum difference, which would be the maximum of the smaller of the two new differences.

Wait, actually, no.

Wait, if I insert x into the largest difference, the new differences are x - a_p and a_{p+1} - x.

The new maximum difference would be the maximum of:

- The new differences x - a_p and a_{p+1} - x.

- The other existing differences.

To minimize the new maximum difference, I need to minimize the maximum of x - a_p and a_{p+1} - x.

This is minimized when x is chosen such that x - a_p = a_{p+1} - x, i.e., x = (a_p + a_{p+1}) / 2.

But x must be equal to d_i + f_j, so I need to find the d_i + f_j that is closest to (a_p + a_{p+1}) / 2.

Then, the new maximum difference would be the maximum of:

- The larger of x - a_p and a_{p+1} - x.

- The next largest difference in the original sequence.

Wait, but there might be multiple differences that are large, so I need to consider all of them.

Wait, perhaps I should consider the second largest difference in the original sequence, and ensure that the new maximum difference is at least as small as that.

Wait, I'm getting tangled here.

Let me try to outline a plan.

1. Compute all the differences between consecutive a_i's.

2. Identify the largest difference, say max_diff.

3. Find the second largest difference, say next_max_diff.

4. The minimum possible new_max_diff is the minimum between next_max_diff and the minimal maximum difference achievable by splitting max_diff with an appropriate x.

5. To find the minimal maximum difference achievable by splitting max_diff with x, find the x among d + f that minimizes the maximum of (x - a_p) and (a_{p+1} - x), where a_p and a_{p+1} are the complexities between which max_diff occurs.

6. The minimal maximum difference achievable by splitting max_diff is the minimal value of max(x - a_p, a_{p+1} - x) over all possible x = d_i + f_j.

7. This is equivalent to finding the x = d_i + f_j that is closest to (a_p + a_{p+1}) / 2, and then taking the maximum difference as max(x - a_p, a_{p+1} - x).

8. Compare this value with next_max_diff, and the minimum of these two is the desired new_max_diff.

This seems like a feasible plan.

Now, to implement this efficiently, considering that n can be up to 1e5 and m and k up to 2e5, I need to handle the computations efficiently.

Let's proceed step by step.

Step 1: Read the input values: t (number of test cases), for each test case, read n, m, k, the array a of size n, the array d of size m, and the array f of size k.

Step 2: For each test case:

a. Compute the differences between consecutive a_i's.

b. Find the largest difference (max_diff) and its position.

c. Find the second largest difference (next_max_diff).

d. For the position with max_diff, find the x = d_i + f_j that is closest to (a_p + a_{p+1}) / 2.

e. Compute the maximum of (x - a_p) and (a_{p+1} - x).

f. The new_max_diff is the minimum between this value and next_max_diff.

g. Output new_max_diff.

Now, the critical part is step 2d: finding the x = d_i + f_j closest to the target value (a_p + a_{p+1}) / 2.

Given that m and k can be up to 2e5 each, computing all possible d_i + f_j would be too slow (4e10 operations).

Therefore, I need a smarter way to find the closest x to the target.

One way to optimize this is to iterate through one of the arrays (say d) and, for each d_i, find the f_j that makes d_i + f_j as close as possible to the target.

Since f can be large, to find the closest f_j efficiently, I can sort f and use binary search to find the f_j closest to (target - d_i).

This would reduce the time complexity to O(m log k), which should be acceptable since m and k are up to 2e5.

Similarly, I can sort f in advance, and for each d_i, perform a binary search to find the f_j that minimizes |d_i + f_j - target|.

Then, among all these minimal differences, I can choose the x = d_i + f_j that gives the smallest |x - target|.

Once I have the best x, I can compute max(x - a_p, a_{p+1} - x), and compare it with next_max_diff to get the final new_max_diff.

Let's formalize this.

Given:

- a_p and a_{p+1}, the complexities between which the largest difference occurs.

- target = (a_p + a_{p+1}) / 2.

- Arrays d (sorted or unsorted?) and f (sorted or unsorted?).

Plan:

1. Sort array f.

2. Initialize variables to track the minimal difference and the corresponding x.

3. For each d_i in d:

a. Compute the required f_j as target - d_i.

b. Use binary search on f to find the f_j closest to (target - d_i).

c. Compute x = d_i + f_j.

d. If |x - target| is smaller than the current minimal difference, update the minimal difference and record this x.

4. After processing all d_i's, choose the x that gives the smallest |x - target|.

5. Compute max(x - a_p, a_{p+1} - x).

6. Set new_max_diff to be the minimum between this max(x - a_p, a_{p+1} - x) and next_max_diff.

7. Output new_max_diff.

Wait, but m and k are both up to 2e5, and t is up to 1e4, so I need to make sure that the total time is acceptable.

Wait, t is up to 1e4, but n, m, k are up to 1e5 and 2e5 respectively per test case.

Wait, the constraints say:

- Sum of n over all test cases <= 1e5.

- Sum of m over all test cases <= 2e5.

- Sum of k over all test cases <= 2e5.

So, overall time complexity should be O((n + m + k) log k), which should be acceptable.

Now, considering that f is used across multiple test cases, I need to make sure that I handle it efficiently.

Also, since a is sorted for each test case, I can compute the differences directly.

Edge Cases:

- When n = 2: only one difference to consider.

- When m = 1 and k = 1: only one possible x to add.

- When the largest difference is already less than or equal to the second largest difference: adding x doesn't help.

- When no x can sufficiently reduce the largest difference.

Implementing the plan:

- For each test case:

a. Read n, m, k, a, d, f.

b. Compute differences: diff_i = a[i] - a[i-1] for i from 1 to n-1.

c. Find max_diff and its index.

d. Find next_max_diff: the second largest difference.

e. If max_diff <= next_max_diff, then no need to add x, as the maximum difference is already minimized.

f. Else, proceed to find the best x to add.

g. Sort f.

h. For each d_i in d:

i. Compute target = (a_p + a_{p+1}) / 2 - d_i.

j. Find f_j in f closest to target using binary search.

k. Compute x = d_i + f_j.

l. Compute max(x - a_p, a_{p+1} - x).

m. Track the minimal such value.

n. Set new_max_diff to be the minimum between this minimal value and next_max_diff.

o. Output new_max_diff.

Wait, in step h, I need to find f_j closest to (target - d_i), but target is (a_p + a_{p+1}) / 2.

Wait, let's correct that.

Target is (a_p + a_{p+1}) / 2.

For each d_i, I want f_j such that d_i + f_j is as close as possible to target.

So, f_j should be as close as possible to target - d_i.

Hence, for each d_i, find f_j closest to (target - d_i).

Then, x = d_i + f_j.

Then, compute max(x - a_p, a_{p+1} - x).

Track the minimal such max(x - a_p, a_{p+1} - x) over all d_i and corresponding best f_j.

Finally, set new_max_diff to be the minimum between this tracked minimal value and next_max_diff.

Implementing this efficiently requires sorting f and using binary search to find the closest f_j for each d_i.

Also, since a_p and a_{p+1} are fixed for the position with max_diff, I can precompute target once.

Let's outline the code structure.

- Read t.

- For each test case:

a. Read n, m, k.

b. Read a as sorted list of n elements.

c. Read d as list of m elements.

d. Read f as list of k elements.

e. Compute differences: diff[i] = a[i] - a[i-1] for i from 1 to n-1.

f. Find max_diff and its index: max_diff = max(diff), index = diff.index(max_diff).

g. Remove max_diff from diff to find next_max_diff: if len(diff) > 0, next_max_diff = max(diff), else next_max_diff = 0.

h. If max_diff <= next_max_diff:

i. new_max_diff = max_diff

j. Else:

k. target = (a[index] + a[index + 1]) / 2

l. Sort f.

m. Initialize min_max_diff = infinity

n. For each d_i in d:

i. required_f = target - d_i

ii. j = bisect_left(f, required_f)

iii. candidates = [f[j-1], f[j]] if 0 <= j-1 < len(f) and j < len(f), else [f[j-1]] or [f[j]].

iv. for cand in candidates:

a. x = d_i + cand

b. current_max = max(x - a[index], a[index + 1] - x)

c. if current_max < min_max_diff:

aa. min_max_diff = current_max

o. new_max_diff = min(min_max_diff, next_max_diff)

p. print(new_max_diff)

Wait, but in step g, removing max_diff from diff might not be efficient, especially if diff is large.

A better way is to keep track of the maximum and the second maximum difference.

In Python, I can use the built-in functions to find the maximum and then remove it to find the second maximum.

But for large n, this might not be efficient.

Alternatively, I can iterate through diff once to find the maximum and second maximum.

Let's do that.

So, in code:

- Initialize max_diff = -1, next_max_diff = -1

- For each diff in differences:

a. if diff > max_diff:

i. next_max_diff = max_diff

ii. max_diff = diff

b. elif diff > next_max_diff:

i. next_max_diff = diff

- Then, proceed as above.

Also, need to handle the case when n=2, where there is only one difference, so next_max_diff would be 0 or not applicable.

Wait, in the problem statement, n >= 2, and m and k >=1.

So, for n=2, there is only one difference, so max_diff is that difference, and next_max_diff would be 0.

In this case, adding x won't help, as there are no other differences to consider.

Wait, no, adding x can split that single difference into two smaller ones.

So, in that case, new_max_diff would be the minimum between the minimal maximum of the two new differences and 0.

But 0 is not applicable, so I need to handle it carefully.

Wait, no, next_max_diff should be considered as 0 if there is only one difference.

Hence, new_max_diff would be the minimum between the minimal maximum of the two new differences and 0.

But since differences are positive, the minimal maximum of the two new differences can't be less than 0.

Hence, in such cases, new_max_diff would be the minimal maximum of the two new differences.

Wait, I need to think carefully.

Let's consider n=2.

a1 and a2.

diff = a2 - a1.

We add x, and insert it between a1 and a2.

New differences are x - a1 and a2 - x.

Then, new_max_diff = max(x - a1, a2 - x).

We need to choose x = d_i + f_j to minimize this max(x - a1, a2 - x).

This is similar to choosing x as close as possible to (a1 + a2)/2.

Then, new_max_diff = max(x - a1, a2 - x).

Since x is chosen to minimize this, the minimal new_max_diff would be (a2 - a1)/2, but x must be equal to d_i + f_j.

Hence, the minimal new_max_diff would be the minimal max(x - a1, a2 - x) over all possible x = d_i + f_j.

Then, compare this with next_max_diff, which in this case is 0, but since the original max_diff is the only difference, and we are adding one x, the new_max_diff should be the minimal max(x - a1, a2 - x).

Hence, in this case, new_max_diff = minimal max(x - a1, a2 - x) over all x = d_i + f_j.

Wait, perhaps I need to adjust my approach for the case when there is only one difference.

But in general, new_max_diff should be the minimum between the minimal max(x - a_p, a_{p+1} - x) and next_max_diff.

In the case when there is only one difference, next_max_diff doesn't exist, so new_max_diff should be the minimal max(x - a_p, a_{p+1} - x).

Hence, in code, if there is only one difference, set next_max_diff to a very large value, say infinity, so that new_max_diff is forced to be the minimal max(x - a_p, a_{p+1} - x).

Wait, no.

Wait, in the case when there is only one difference, max_diff is that difference, and next_max_diff should be 0, but in reality, next_max_diff doesn't exist because there are no other differences.

Hence, in that case, new_max_diff should be the minimal max(x - a_p, a_{p+1} - x).

Wait, but in the earlier plan, if max_diff <= next_max_diff, then new_max_diff = max_diff.

But in the case when there is only one difference, next_max_diff doesn't exist, so I should set next_max_diff to max_diff, meaning that new_max_diff = max_diff.

But that doesn't make sense, because adding x can potentially reduce max_diff.

Hence, I need to adjust the logic.

Let me rephrase.

- If there is only one difference, then new_max_diff is the minimal max(x - a_p, a_{p+1} - x).

- If there are multiple differences, then new_max_diff is the minimum between the minimal max(x - a_p, a_{p+1} - x) and the second largest difference.

Hence, in code, if there is only one difference, set next_max_diff to max_diff, meaning that new_max_diff = minimal max(x - a_p, a_{p+1} - x).

Else, set new_max_diff to the minimum between the minimal max(x - a_p, a_{p+1} - x) and next_max_diff.

Wait, but in the earlier plan, if max_diff <= next_max_diff, then new_max_diff = max_diff.

But in reality, if there is only one difference, max_diff is the only difference, and next_max_diff doesn't exist, so new_max_diff should be the minimal max(x - a_p, a_{p+1} - x).

Hence, perhaps I need to set next_max_diff to max_diff in the case when there is only one difference.

Wait, let's think differently.

Let me compute the list of differences.

If there is only one difference, set next_max_diff to max_diff.

Else, find the second largest difference as next_max_diff.

Then, proceed as before.

This way, when there is only one difference, new_max_diff is the minimum between the minimal max(x - a_p, a_{p+1} - x) and max_diff.

Which makes sense, because adding x can potentially reduce the single difference, but cannot make new_max_diff less than the existing difference.

Wait, but in reality, adding x can split the difference into two smaller ones, so new_max_diff could be smaller than the original max_diff.

Hence, I need to allow new_max_diff to be smaller than max_diff, but not smaller than the minimal max(x - a_p, a_{p+1} - x).

Hence, setting next_max_diff to max_diff when there is only one difference seems appropriate.

Wait, perhaps I'm overcomplicating this.

Let me try with an example.

Example 1:

n=2, a=[10, 20]

diff=[10]

max_diff=10, next_max_diff=0 (but set to 10)

Then, find x to split 10 into two parts, say x=15.

Then, new differences are 5 and 5.

So, new_max_diff=5.

Which is less than max_diff=10.

Hence, new_max_diff should be 5.

But according to the earlier plan, new_max_diff = min(minimal max(x - a_p, a_{p+1} - x), next_max_diff)

If next_max_diff is set to max_diff=10, then new_max_diff = min(5,10)=5.

Which is correct.

Hence, this seems to work.

Another example:

n=3, a=[10,15,20]

diff=[5,5]

max_diff=5, next_max_diff=5

Since max_diff <= next_max_diff, new_max_diff=5.

Which is correct, since adding x cannot reduce the maximum difference below 5.

Hence, the plan seems sound.

Implementing this in code.

I need to handle the input efficiently.

Given that t can be up to 1e4, but sum of n, m, k are limited, I need to read all inputs first and process them accordingly.

Also, since a is sorted for each test case, I can proceed as planned.

Implementing the function to find the best x:

- Sort f.

- For each d_i, compute required_f = target - d_i.

- Find the f_j in f closest to required_f using bisect_left.

- Consider f[j-1] and f[j] if within bounds.

- Compute x = d_i + f_j and x = d_i + f_{j-1}, and choose the one that gives the smallest |x - target|.

- Then, compute max(x - a_p, a_{p+1} - x) for that x.

- Track the minimal such value.

Finally, set new_max_diff to be the minimum between this minimal value and next_max_diff.

Edge Cases to consider:

1. n=2, m=1, k=1.

- Only one difference, and only one possible x.

- new_max_diff should be max(x - a1, a2 - x).

2. All differences are equal.

- If adding x can make one difference smaller, then new_max_diff is the smaller value.

- Else, new_max_diff remains the same.

3. Adding x cannot reduce the maximum difference.

- In this case, new_max_diff remains max_diff.

4. Adding x can make all differences equal.

- In this case, new_max_diff is the value of the equal differences.

Now, to optimize the code further, I can consider that f is sorted only once per test case.

Also, to handle multiple test cases efficiently, I need to read all inputs first and process them one by one.

Implementing this in Python, I need to be careful with input reading, as sys.stdin.readline is faster for large inputs.

Hence, I should use sys.stdin.readline for reading inputs.

Also, to handle floating point precision issues, I need to ensure that target is computed accurately.

But since a_p and a_{p+1} are integers, (a_p + a_{p+1}) / 2 might not be integer, so I need to handle floating points.

But since d_i and f_j are integers, x is integer, so x - a_p and a_{p+1} - x will be integers.

Hence, I can compute target as (a_p + a_{p+1}) / 2.0 to handle floating points.

Then, for each d_i, required_f = target - d_i, which could be a float.

When searching in f, which is sorted integers, I need to find the f_j closest to required_f.

I can use bisect_left to find the insertion point for required_f in f, and then consider f[j-1] and f[j] to find the closest f_j.

Then, x = d_i + f_j, and compute max(x - a_p, a_{p+1} - x).

Track the minimal such max(x - a_p, a_{p+1} - x) over all d_i and corresponding best f_j.

Finally, set new_max_diff to be the minimum between this minimal value and next_max_diff.

Implementing this should solve the problem efficiently.

Hence, the given program seems to be implementing this logic correctly.

Therefore, the program is correct.

**Final Answer**

\[ \boxed{\text{True}} \]

