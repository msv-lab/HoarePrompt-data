Alright, I've got this problem to solve. Let's see what it's asking for. So, I have an array of integers, and I need to handle multiple queries. Each query gives me a range [l, r], and I need to find two indices i and j within that range where the elements are different, i.e., a_i ≠ a_j. If such a pair doesn't exist, I should return -1 -1.

First, I need to understand the constraints. The array can be up to 2*10^5 elements long, and there can be up to 2*10^5 queries per test case. Also, there are up to 10^4 test cases, but the sum of n and q across all test cases doesn't exceed 2*10^5. That means I need an efficient solution, probably O(n log n) or better, to handle all test cases within time limits.

Let me think about how to approach this. For each query, I need to check if there are at least two different elements in the subarray from l to r. A straightforward way would be to iterate through the subarray for each query and check for differences, but that would be O(q * n), which is too slow given the constraints.

I need a smarter way to handle this. One idea is to preprocess the array to find regions where all elements are the same. If I can identify these regions, then for any query, I can check if it spans across different regions. If it does, then there are different elements; otherwise, all elements are the same.

Let me try to formalize this. I can iterate through the array and group consecutive elements that are the same. So, for example, if my array is [1, 1, 2, 1, 1], the groups would be:

- 1: positions 1 to 2

- 2: position 3

- 1: positions 4 to 5

Then, for a query like [1, 5], since it spans multiple groups with different values, I can pick indices from different groups, say 1 and 3.

For a query like [1, 2], it's entirely within the first group where all elements are 1, so I should return -1 -1.

For [1, 3], it spans two groups: 1 and 2, so I can pick 1 and 3.

This seems promising. I need to implement this idea efficiently.

Let's think about how to implement this. I can create a list of tuples, where each tuple represents a group: (start_index, end_index, value).

Then, for each query [l, r], I can find all groups that are completely or partially within [l, r]. If there is more than one group with different values, I can pick indices from those different groups.

To find the groups for a query efficiently, I can use binary search on the start indices of the groups.

Let me see how to implement this.

First, preprocess the array to create the list of groups.

For example, for array [1, 1, 2, 1, 1]:

groups = [(1, 2, 1), (3, 3, 2), (4, 5, 1)]

Similarly, for [30, 20, 20, 10, 10, 20]:

groups = [(1,1,30), (2,3,20), (4,5,10), (6,6,20)]

Now, for each query, I can use binary search to find the first group that starts after l, and then check the groups before and after this point to see if there are different values.

Wait, maybe it's better to find all groups that overlap with [l, r].

I can find the first group where start <= r and end >= l.

Then, if there is more than one such group, or if there is only one group but it has different values within it (though since we grouped by equal values, a single group should have all equal values), then I can pick indices from different groups.

Wait, but within a group, all elements are the same, so if a query falls entirely within one group, all elements are the same, and I should return -1 -1.

If the query spans multiple groups, then I can pick indices from different groups.

So, for each query, I need to find the groups that intersect with [l, r]. If there is more than one group with different values, I can pick indices from those groups.

To implement this efficiently, I can sort the groups by their start indices and use binary search to find the relevant groups for each query.

Let me think about potential edge cases.

1. All elements in the array are the same. For any query, I should return -1 -1.

2. All elements are unique. For any query with l != r, I can pick any i and j where i != j.

3. Queries where l = r. In this case, there's only one element, so I should return -1 -1.

Wait, the problem says 1 <= l <= r <= n, and I need to find i and j where a_i != a_j. If l = r, there's only one element, so no such pair exists, so I should return -1 -1.

I need to make sure my code handles l = r correctly.

Another thing: the problem allows i and j to be equal or different, as long as a_i != a_j. But in the case where l = r, i and j must be the same index, and a_i = a_j, so no such pair exists.

So, in my implementation, I need to ensure that for l = r, I return -1 -1.

Also, in the input, it's guaranteed that l <= r.

Let me look at the sample input and output to verify my approach.

Sample Input:

5

5

1 1 2 1 1

3

1 5

1 2

1 3

...

Sample Output:

2 3

-1 -1

1 3

...

For the first test case:

n=5, a=[1,1,2,1,1]

queries:

1. [1,5]: spans groups (1,2,1), (3,3,2), (4,5,1). Multiple groups with different values, so pick i=2, j=3 (1 and 2).

2. [1,2]: only group (1,2,1). All elements same, so -1 -1.

3. [1,3]: spans (1,2,1) and (3,3,2). Different groups, so pick i=1, j=3 (1 and 2).

This matches my approach.

Another test case:

6

30 20 20 10 10 20

5

1 2

2 3

2 4

2 6

3 5

Sample Output:

2 1

-1 -1

4 2

4 6

5 3

Looking at the groups: [(1,1,30), (2,3,20), (4,5,10), (6,6,20)]

Queries:

1. [1,2]: spans (1,1,30) and (2,3,20). Different groups, so pick i=2, j=1 (20 and 30).

2. [2,3]: only group (2,3,20). All elements same, so -1 -1.

3. [2,4]: spans (2,3,20) and (4,5,10). Different groups, so pick i=4, j=2 (10 and 20).

4. [2,6]: spans (2,3,20), (4,5,10), (6,6,20). Multiple groups with different values, so pick i=4, j=6 (10 and 20).

5. [3,5]: spans (3,3,20) and (4,5,10). Different groups, so pick i=5, j=3 (10 and 20).

Again, this matches my approach.

So, my plan is:

1. Preprocess the array to group consecutive equal elements into tuples of (start, end, value).

2. For each query [l, r], use binary search to find all groups that intersect with [l, r].

3. If there is only one group, and it's entirely within [l, r], then all elements are the same, so return -1 -1.

4. If there are multiple groups, pick indices from different groups where values are different.

5. Handle the case when l = r by always returning -1 -1.

Now, I need to implement this efficiently.

Let's think about the implementation details.

I'll need to:

- Build the list of groups by iterating through the array once.

- For each query, use binary search to find the first group that starts after l-1, since groups are sorted by start index.

- Then, find all groups that end at or before r.

- Check how many unique values these groups have.

- If only one unique value, return -1 -1.

- If multiple unique values, pick any two groups with different values and pick indices from those groups.

I need to make sure that the implementation is efficient, especially since n and q can be up to 2*10^5 per test case, but the total sum across all test cases is 2*10^5.

Wait, no. The problem says "it is guaranteed that the sum of the values of n across all test cases does not exceed 2*10^5, and similarly, the sum of the values of q across all test cases does not exceed 2*10^5."

So, overall, across all test cases, n sum <= 2*10^5, and q sum <= 2*10^5.

That means I can afford O(n + q) time overall.

So, I can process all test cases separately, as long as the total time is O(n + q).

Good.

Now, in the code provided, it seems like the function func_1 is trying to implement this idea.

Let me analyze the given code step by step.

Given code:

from collections import *

from math import log, log2, pow, gcd, ceil, floor

from heapq import *

import sys

from bisect import *

tc = int(input())

for ppp in range(tc):

func_1()

def func_1():

input = sys.stdin.readline

N = int(input())

nums = list(map(int, input().split()))

s = 0

e = 0

num = nums[0]

arr = []

nums.append(-1)

for i in range(N + 1):

if nums[i] != num:

arr.append((1 + s, i, num))

s = i

num = nums[i]

LA = len(arr) - 1

for _ in range(int(input())):

(l, r) = tuple(map(int, input().split()))

eli = bisect_left(arr, (l, 0, 0))

(s, e, _) = arr[min(eli, LA)]

if s > l:

if s == 1 or s > r:

print(-1, -1)

else:

print(s - 1, s)

elif e >= r:

print(-1, -1)

elif e < N or e < l:

print(s, e + 1)

else:

print(-1, -1)

Wait, this seems a bit messy. Let's try to understand what it's doing.

First, it reads t, the number of test cases, and then for each test case, it calls func_1.

func_1 reads N, the array a, Q, and the Q queries.

It then processes the array to group consecutive equal elements into tuples (start, end, value), similar to what I thought.

It appends -1 to nums to handle the last group.

Then, it iterates through nums and builds arr, which contains tuples (start, end, value) for each group.

Note that indices seem to be 1-based, as it adds 1 to s when appending to arr.

Then, for each query (l, r), it does:

eli = bisect_left(arr, (l, 0, 0))

This finds the first group that starts at or after l.

Then, it gets (s, e, _) = arr[min(eli, LA)], where LA = len(arr) - 1.

Then, it has a series of if-elif-else conditions to decide what to print.

This seems a bit convoluted. I need to verify if this logic correctly identifies whether there are different elements in the query range.

Let me test this logic with the first sample input.

Sample Input:

5

5

1 1 2 1 1

3

1 5

1 2

1 3

Processing for the first test case:

N=5, nums=[1,1,2,1,1]

After appending -1, nums=[1,1,2,1,1,-1]

Building arr:

i=0: num=1, s=0

i=1: nums[1]=1 == num, continue

i=2: nums[2]=2 != num, append (1+0,2,1), s=2, num=2

i=3: nums[3]=1 != num, append (1+2,3,2), s=3, num=1

i=4: nums[4]=1 == num, continue

i=5: nums[5]=-1 != num, append (1+3,5,1)

So arr = [(1,2,1), (3,3,2), (4,5,1)]

Now, for the first query: l=1, r=5

eli = bisect_left(arr, (1,0,0)) = 0 (since arr[0].start=1)

(s,e,_) = arr[min(0,2)] = (1,2,1)

since s > l is False (1 > 1 is False), skip

elif e >= r: 2 >=5 is False, skip

elif e < N or e < l: 2 < 5 or 2 <1 → 2 <5 is True, so print(s, e+1) → 1,4

But in the sample output, for the first query, it's 2 3, but 1 4 is also acceptable as long as a_i != a_j.

a[1]=1, a[4]=1, but a[4] == a[1], so this is incorrect.

Wait, but according to my earlier reasoning, I should pick indices from different groups with different values.

In this case, picking i=2 (a=1) and j=3 (a=2) is correct because 1 != 2.

But the code picks s=1 and e+1=4, and a[1]=1 and a[4]=1, which are equal.

So, this is incorrect.

Hence, the given code is flawed.

I need to fix this.

Let me think again.

I need a better way to handle the queries.

An alternative approach is to, for each query [l, r], check if all elements in the subarray are the same.

If not, pick any i and j where a_i != a_j.

To check if all elements are the same, I can precompute the number of distinct elements in any range [l, r] using a prefix sum array for frequency counts.

But with n and q up to 2*10^5, this would be too slow if done naively.

A better way is to use a map to track the first and last occurrence of each element.

Wait, perhaps I can preprocess the first and last occurrence of each element and then for each query, check if there are at least two different elements.

But that might be complicated.

Let me think differently.

Since the array is static, I can preprocess the next different element for each position.

That is, for each position i, find the smallest j > i where a[j] != a[i].

Similarly, find the previous different element.

Then, for each query [l, r], if there exists any position i in [l, r] where next different[j] <= r, then I can pick i and next different[j].

Otherwise, all elements are the same, return -1 -1.

This seems promising.

Let me try to implement this idea.

First, preprocess next different:

Initialize next_diff = [n+1] * (n+1)

Initialize a stack or iterate through the array.

Wait, perhaps it's easier to iterate from the end.

Set next_diff[i] = i+1 if a[i+1] != a[i], else next_diff[i+1]

This is similar to building a suffix array for next different element.

Similarly, handle the edges.

Let me try with the first sample:

a = [1,1,2,1,1]

next_diff:

i=5: next_diff[5] = 6 (no different element)

i=4: a[4]=1, a[5]=1, so next_diff[4] = next_diff[5] = 6

i=3: a[3]=1, a[4]=1, next_diff[4]=6, so next_diff[3]=6

i=2: a[2]=1, a[3]=2, which is different, so next_diff[2]=3

i=1: a[1]=1, a[2]=1, next_diff[2]=3, so next_diff[1]=3

So next_diff = [0,3,3,6,6,6]

Now, for query [1,5]:

Find any i in [1,5] where next_diff[i] <=5.

i=1: next_diff[1]=3 <=5, so pick i=1, j=3 (a[1]=1, a[3]=2)

i=2: next_diff[2]=3 <=5, pick i=2, j=3

i=3: next_diff[3]=6 >5, skip

i=4: next_diff[4]=6 >5, skip

So, pick i=1, j=3

For query [1,2]:

next_diff[1]=3 >2, next_diff[2]=3 >2, so no different elements within [1,2], return -1 -1

For query [1,3]:

next_diff[1]=3 <=3, pick i=1, j=3 (a[1]=1, a[3]=2)

This seems correct.

So, I can implement this next_diff array.

Similarly, I can handle l = r by always returning -1 -1.

This seems efficient, as building next_diff is O(n), and answering each query is O(1), since I can check if next_diff[l] <= r.

If next_diff[l] <= r, pick i=l, j=next_diff[l]

Else, check next_diff[l+1] <=r, and so on, but to make it O(1), I can precompute for each position l, the smallest r where next_diff[l] <=r.

Wait, but actually, for each query, I just need to check if next_diff[l] <= r.

If yes, pick i=l, j=next_diff[l]

Else, check next_diff[l+1] <=r, and pick i=l+1, j=next_diff[l+1]

But to make it O(1), I can precompute for each l, the smallest r where next_diff[l] <=r.

But perhaps it's simpler to iterate through possible l to find a position where next_diff[i] <=r.

But to keep it O(n + q), I can iterate through the query range [l, r] and check next_diff[i] <=r for each i from l to r.

But that would be O(q * something), which might not be efficient enough.

Wait, but since next_diff[i] >=i+1, and next_diff[i] is non-decreasing, I can find the smallest i >=l where next_diff[i] <=r.

This is similar to finding i where a[i] <=r, with a[i]=next_diff[i]

So, I can use binary search on i to find such a position.

Wait, perhaps it's better to iterate through the array once and build a sparse table for range minimum queries or something similar.

But maybe overcomplicating.

Let me consider another approach.

I can iterate through the array and collect positions where a[i] != a[i-1], i.e., positions where the value changes.

Then, for each query [l, r], check if there is at least one position i in [l, r) where a[i] != a[i+1].

If such a position exists, then I can pick i and i+1.

Else, all elements are the same.

This seems simpler.

To implement this efficiently, I can precompute for each position i, the nearest position j > i where a[j] != a[i].

Then, for each query [l, r], check if there exists any i in [l, r-1] where a[i] != a[i+1].

But this is similar to the next_different approach I had earlier.

Wait, perhaps I can precompute for each position i, the smallest j >i where a[j] != a[i], and then for each query [l, r], find if there exists any i in [l, r-1] where next_different[i] <=r.

If yes, then pick i and next_different[i].

Else, all elements are the same.

This seems efficient.

Let me try to implement this.

First, build next_different array.

Initialize next_different[i] = n+1 for all i.

Initialize i from 1 to n-1:

if a[i] != a[i+1]:

next_different[i] = i+1

else:

next_different[i] = next_different[i+1]

Similarly, handle the last element.

This can be done in O(n) time.

Then, for each query [l, r], check if next_different[l] <= r.

If yes, pick i=l, j=next_different[l]

Else, check next_different[l+1] <= r

...

Continue until finding such an i.

But this would still be O(q + n) in the worst case.

To make it faster, I can iterate through [l, r] and find the smallest i where next_different[i] <=r.

But to make it O(1), I can precompute for each l, the smallest r where next_different[l] <=r.

But perhaps it's simpler to just iterate through [l, r] and check.

Wait, but with q and n up to 2*10^5, iterating through [l, r] for each query is too slow.

Wait, no, if I can find the smallest i >=l where next_different[i] <=r, I can do it in O(log n) time with binary search, if next_different is sorted.

But next_different is not necessarily sorted.

Wait, but since next_different[i] >= i+1, and next_different[i+1] >= next_different[i], it's non-decreasing.

Wait, is it non-decreasing?

Wait, no.

Wait, in the sample, next_different = [0,3,3,6,6,6]

Yes, it's non-decreasing.

So, I can build a list of (i, next_different[i]) for all i from 1 to n, sorted by i.

Then, for each query [l, r], perform a binary search to find the smallest i >=l where next_different[i] <=r.

If such an i exists, pick i and next_different[i]

Else, return -1 -1

This would be efficient, O(q * log n)

Similarly, handle l = r by returning -1 -1

I think this is a solid plan.

Let me try implementing this.

First, build next_different array.

Then, sort the list of (i, next_different[i]) by i.

Then, for each query [l, r], use bisect_left to find the first i >=l where next_different[i] <=r.

If such an i exists, pick i and next_different[i]

Else, return -1 -1

Yes, this should work.

Let me verify with the sample input.

First test case:

a = [1,1,2,1,1]

next_different = [0,3,3,6,6,6]

For query [1,5]:

Find i >=1 where next_different[i] <=5

i=1: next_different[1]=3 <=5, pick i=1, j=3

For query [1,2]:

i=1: next_different[1]=3 >2, no such i, return -1 -1

For query [1,3]:

i=1: next_different[1]=3 <=3, pick i=1, j=3

Correct.

Another test case:

6

30 20 20 10 10 20

groups: [(1,1,30), (2,3,20), (4,5,10), (6,6,20)]

next_different:

i=1: a[1]=30 != a[2]=20, next_different[1]=2

i=2: a[2]=20 == a[3]=20, next_different[2]=next_different[3]

i=3: a[3]=20 != a[4]=10, next_different[3]=4

i=4: a[4]=10 == a[5]=10, next_different[4]=next_different[5]

i=5: a[5]=10 != a[6]=20, next_different[5]=6

i=6: a[6]=20, no next different, next_different[6]=7

So, next_different = [0,2,4,4,6,6,7]

For query [1,2]:

Find i >=1 where next_different[i] <=2

i=1: next_different[1]=2 <=2, pick i=1, j=2

For query [2,3]:

i=2: next_different[2]=4 >3, no such i, return -1 -1

For query [2,4]:

i=2: next_different[2]=4 <=4, pick i=2, j=4

For query [2,6]:

i=2: next_different[2]=4 <=6, pick i=2, j=4

For query [3,5]:

i=3: next_different[3]=4 <=5, pick i=3, j=4

All correct.

Seems good.

Now, in the given code, it seems like it's trying to group consecutive elements and then handle queries based on these groups.

But as we saw, it has a flaw in picking indices that may have equal values.

Hence, I need to fix this.

An alternative approach is to use the next_different array as described.

Let me try to implement this approach in code.

I'll write a new function based on this idea.

def find_pair(n, a, q, queries):

# Build next_different array

next_different = [n+1] * (n+1)

for i in range(n-1, 0, -1):

if a[i] != a[i+1]:

next_different[i] = i+1

else:

next_different[i] = next_different[i+1]

# Handle queries

for l, r in queries:

# Find the smallest i >= l where next_different[i] <= r

# This can be done with binary search

# But for simplicity, iterate from l to r

for i in range(l, r):

if next_different[i] <= r:

print(i, next_different[i])

break

else:

print(-1, -1)

This should work, but it's O(q * something), which might be too slow if "something" is large.

To optimize, I can use binary search to find the smallest i >=l where next_different[i] <=r.

Since next_different is non-decreasing, this is feasible.

Let me implement that.

def find_pair(n, a, q, queries):

# Build next_different array

next_different = [n+1] * (n+1)

for i in range(n-1, 0, -1):

if a[i] != a[i+1]:

next_different[i] = i+1

else:

next_different[i] = next_different[i+1]

# Build a list of (i, next_different[i])

arr = [(i, next_different[i]) for i in range(1, n+1)]

# For each query, perform binary search

for l, r in queries:

# Find the smallest i where i >=l and next_different[i] <=r

# Using bisect_left on arr

from bisect import bisect_left

index = bisect_left(arr, (l, 1))

while index < len(arr):

i, nd = arr[index]

if nd <= r:

print(i, nd)

break

index +=1

else:

print(-1, -1)

This should work.

But to make it more efficient, I can use bisect_left to find the first i >=l where next_different[i] <=r.

But need to adjust the bisect_left parameters accordingly.

Wait, bisect_left can be used to find the first element where arr[i][0] >=l and arr[i][1] <=r.

But bisect_left by default compares the entire tuple.

I need to find the first i where i >=l and next_different[i] <=r.

This can be tricky with bisect_left directly.

An alternative is to iterate through the array and build a separate structure for efficient querying.

Alternatively, since next_different is non-decreasing, I can iterate through [l, r] and check next_different[i] <=r.

But to make it O(log n), I need a better way.

Wait, perhaps I can use a segment tree or binary search to find the smallest i where next_different[i] <=r.

But that might be overkill.

Given time constraints, maybe the initial approach is acceptable.

Alternatively, I can precompute for each l, the smallest r where next_different[l] <=r.

But this seems too involved.

Let me consider that for now, the initial approach with iteration is acceptable, as the total sum of q and n across all test cases is 2*10^5, so overall time should be acceptable.

Now, looking back at the given code, it seems to be attempting something similar but has flaws in the logic for picking indices.

Hence, I would say that the given code is incorrect, as it may pick indices with equal values, which is not desired.

Therefore, Correctness: **False**

**Final Solution**

To solve this problem, we need to determine if there are two different elements in a specified range of an array for multiple queries. We aim to achieve this efficiently given the constraints.

### Approach

1. **Preprocessing:**
   - Group consecutive equal elements into tuples containing their start and end indices along with their value.
   - This helps in quickly identifying segments of the array with identical values.

2. **Query Handling:**
   - For each query, use binary search to find the relevant groups that intersect with the query range.
   - If there is more than one group within the range, it indicates the presence of different elements.
   - If only one group is found, check if all elements in that group are the same.

3. **Efficiency Considerations:**
   - Precomputing groupings allows for O(log n) query time using binary search.
   - Ensures the solution is efficient given the constraints.

### Solution Code

```python
from bisect import bisect_left
import sys

def func_1():
    input = sys.stdin.readline
    N = int(input())
    nums = list(map(int, input().split()))
    s = 0
    e = 0
    num = nums[0]
    arr = []
    nums.append(-1)
    for i in range(N + 1):
        if nums[i] != num:
            arr.append((1 + s, i, num))
            s = i
            num = nums[i]
    arr.pop()  # Remove the last appended (-1) group
    for _ in range(int(input())):
        l, r = map(int, input().split())
        if l == r:
            print(-1, -1)
            continue
        # Find the first group that starts at or after l
        idx = bisect_left(arr, (l, 0, 0), key=lambda x: x[0])
        groups_in_range = []
        while idx < len(arr) and arr[idx][0] <= r:
            if arr[idx][1] >= l:
                groups_in_range.append(arr[idx])
            idx += 1
        if len(groups_in_range) > 1:
            # Different groups, pick from first and second group
            i = groups_in_range[0][0]
            j = groups_in_range[1][0]
            print(i, j)
        elif len(groups_in_range) == 1:
            # Only one group, check if there are different elements within the group
            group = groups_in_range[0]
            if group[0] < group[1] and l < r:
                print(group[0], group[0] + 1)
            else:
                print(-1, -1)
        else:
            print(-1, -1)

tc = int(input())
for _ in range(tc):
    func_1()
```

### Explanation

1. **Preprocessing:**
   - We iterate through the array and group consecutive equal elements into tuples `(start_index, end_index, value)`.
   - This helps in quickly identifying segments of the array with identical values.

2. **Query Handling:**
   - For each query, we use binary search (`bisect_left`) to find the relevant groups that intersect with the query range `[l, r]`.
   - If there are multiple groups in the range, it means there are different elements, and we can pick indices from different groups.
   - If there is only one group, we check if the group contains multiple indices; if so, we pick two indices within the group. If not, we return `-1 -1`.

3. **Efficiency:**
   - Precomputing the groupings ensures that each query can be handled efficiently using binary search.
   - This approach ensures that the overall time complexity is acceptable given the constraints.