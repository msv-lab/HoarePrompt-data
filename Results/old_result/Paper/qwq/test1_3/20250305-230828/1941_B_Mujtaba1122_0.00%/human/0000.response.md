Alright, I've got this problem to solve. Let's see what it's asking for. So, Rudolf has an array of integers, and he can perform a specific operation on it any number of times. The operation involves choosing an index i (which has to be between 2 and n-1, so not the first or last element), and then decrementing a_{i-1}, a_i, and a_{i+1} by 1, 2, and 1 respectively. The goal is to make all elements of the array zero using these operations.

First, I need to understand what this operation does. It seems like it's a way to reduce the values in the array, particularly targeting the middle elements more heavily since a_i is decremented by 2. The operation can be applied any number of times, and any index i (within the valid range) can be chosen for each operation.

I need to figure out if it's possible to apply these operations in such a way that all elements become zero.

Let me think about the constraints and what they imply.

Given that n is at least 3 and can be up to 2*10^5, and each a_j can be up to 10^9, I need an efficient algorithm, probably O(n) time per test case, considering the constraints.

First, I need to find a way to determine whether it's possible to make all elements zero with the given operations.

One approach is to model this as a system of equations. Each operation corresponds to subtracting certain values from specific positions in the array. I need to see if I can subtract multiples of these operations to reach an array of all zeros.

Let's consider the operations as vectors that can be subtracted from the array. For each i from 2 to n-1, there's a vector that has:

- -1 at position i-1

- -2 at position i

- -1 at position i+1

And zeros elsewhere.

The problem then becomes whether, by adding multiples of these vectors to the original array, we can reach the zero vector.

This is essentially solving a system of linear equations where the variables are the number of times each operation is applied.

However, with n up to 2*10^5, solving a system of equations directly is not feasible due to time and space constraints.

I need a smarter way to approach this.

Let me consider the effect of the operations step by step.

Suppose I start from the left end of the array. If I have a non-zero value at position 1, I need to reduce it. However, the only operation that affects position 1 is when i=2, which affects positions 1, 2, and 3.

Similarly, for position n, only i=n-1 affects it.

Maybe I can process the array from left to right, keeping track of how much each operation affects the subsequent elements.

Let me try to simulate the operations.

Suppose I have the array [a1, a2, a3, a4, a5].

If I apply the operation at i=2, it becomes [a1-1, a2-2, a3-1, a4, a5].

Then, if I apply it at i=3, it becomes [a1-1, a2-2, a3-3, a4-2, a5-1].

And so on.

But this seems too vague. I need a more systematic way.

Perhaps I can think in terms of differences or cumulative sums.

Let me consider the differences between consecutive elements.

Define d1 = a1, d2 = a2 - a1, d3 = a3 - a2, ..., dn = an - a_{n-1}.

Wait, that seems familiar. It's similar to the first differences in sequences.

But I need to see how the operations affect these differences.

When I apply an operation at index i, it changes a_{i-1}, a_i, and a_{i+1}.

Let's see how it affects the differences.

For example, applying the operation at i=2:

- a1 becomes a1 -1

- a2 becomes a2 -2

- a3 becomes a3 -1

So, d1 = (a1 -1) - (a1 -1) = a1 -1 - (a1 -1) = 0?

Wait, maybe I need to be more careful.

Original differences:

d1 = a1

d2 = a2 - a1

d3 = a3 - a2

d4 = a4 - a3

d5 = a5 - a4

After applying operation at i=2:

New a1 = a1 -1

New a2 = a2 -2

New a3 = a3 -1

New differences:

d1' = a1 -1

d2' = (a2 -2) - (a1 -1) = a2 - a1 -1

d3' = (a3 -1) - (a2 -2) = a3 - a2 +1

d4' = a4 - (a3 -1) = a4 - a3 +1

d5' = a5 - a4

Wait, this seems complicated. Maybe differences aren't the way to go.

Let me try another approach.

Suppose I want to make all a_i = 0.

I need to find a sequence of operations that sum up to the original array.

Each operation corresponds to a vector: [-1, -2, -1] at positions i-1, i, i+1.

I need to see if I can express the original array as a linear combination of these operations.

But with large n, this is not practical.

Maybe I can think in terms of invariants.

Is there some invariant that must hold for the array to be reducible to all zeros?

For example, maybe the sum of the array must be a multiple of a certain number.

Let's check the sum of the array.

Each operation decreases the sum by 4: -1 -2 -1 = -4.

So, the total sum must be divisible by 4, right?

Wait, no. Because you can apply operations multiple times, but it's possible that overlapping operations affect the total sum differently.

Wait, actually, each operation reduces the sum by 4, so the total sum must be divisible by 4 if we can apply a certain number of operations to reach zero.

But in the first example:

1 + 3 + 5 + 5 + 2 = 16, which is divisible by 4, and the answer is YES.

In the second example:

2 + 4 + 4 + 5 + 1 = 16, again divisible by 4, but the answer is NO.

So, sum being divisible by 4 is not sufficient.

Hmm.

Maybe I need a different approach.

Let me consider the operations in reverse.

Suppose I have an array of zeros, and I apply the operations in reverse to build up to the given array.

Each reverse operation would add 1 to a_{i-1}, 2 to a_i, and 1 to a_{i+1}.

So, I need to see if the given array can be built by adding such operations.

This seems similar to solving a system where each operation is a vector added to the array.

But again, with large n, this isn't practical.

Maybe I can consider the array as a whole and look for patterns or properties that must hold.

Let me consider the borders.

The first and last elements can only be affected by operations involving i=2 and i=n-1, respectively.

So, perhaps I can process the array from left to right and ensure that the values can be balanced appropriately.

Let me try to process the array step by step.

Start from the left:

- For position 1: it can only be affected by operations at i=2.

- So, the value at position 1 must be reduced by the number of operations applied at i=2.

- Similarly, position 2 is affected by operations at i=2 and i=3.

- And so on.

This seems a bit tangled.

Maybe I can use a greedy approach.

Start from the left, and for each position, decide how many operations to apply to make it zero, considering the impact on the next positions.

Let me try this with the first example:

[1, 3, 5, 5, 2]

Start with position 1: 1

To make it zero, I need to apply some operations that reduce it by 1.

The only operation that affects position 1 is i=2, which reduces a1 by 1, a2 by 2, and a3 by 1.

So, applying one operation at i=2:

a1 = 1 -1 = 0

a2 = 3 -2 = 1

a3 = 5 -1 = 4

Array becomes: [0, 1, 4, 5, 2]

Next, position 2: 1

To make it zero, apply an operation at i=3:

a2 = 1 -2 = -1

a3 = 4 -2 = 2

a4 = 5 -1 = 4

But a2 becomes -1, which is not allowed since the problem likely assumes non-negative integers.

Wait, but in the problem statement, it says "0 ≤ a_j ≤ 10^9", so presumably, after operations, elements can become zero, but during the process, negative values might be allowed, or perhaps not.

The problem says "Rudolf can apply this operation any number of times. Any index i can be used zero or more times."

It doesn't specify that the array elements must remain non-negative during the operations, so perhaps negative values are allowed.

But in the context of the problem, it's about making all elements zero, and the operations can be applied any number of times, so maybe it's acceptable for intermediate steps to have negative values.

However, if negative values are allowed, then the problem becomes more complex.

In the first step, applying one operation at i=2 to the first array:

[1,3,5,5,2] -> [0,1,4,5,2]

Then, applying one operation at i=3:

[0,1,4,5,2] -> [0,1-2,4-2,5-1,2] = [0,-1,2,4,2]

Then, applying one operation at i=4:

[0,-1,2,4,2] -> [0,-1,2-1,4-2,2-1] = [0,-1,1,2,1]

This seems messy, and it's not clear how to proceed.

Maybe the greedy approach isn't the best way.

Let me think differently.

Suppose I model the operations as variables.

Let o2, o3, ..., o_{n-1} be the number of operations applied at each index i.

Then, the effect on each a_j is:

a1: -o2

a2: -2*o2 - o3

a3: -o2 -2*o3 - o4

...

a_{n-1}: -o_{n-2} -2*o_{n-1}

a_n: -o_{n-1}

I need to solve for o2, o3, ..., o_{n-1} such that:

- o2 >= 0

- o3 >= 0

...

- o_{n-1} >= 0

And:

- -o2 = -a1

- -2*o2 - o3 = -a2

- -o2 -2*o3 - o4 = -a3

...

- -o_{n-2} -2*o_{n-1} = -a_{n-1}

- -o_{n-1} = -a_n

Or, equivalently:

o2 = a1

2*o2 + o3 = a2

o2 + 2*o3 + o4 = a3

...

o_{n-2} + 2*o_{n-1} = a_{n-1}

o_{n-1} = a_n

This is a system of linear equations with variables o2 to o_{n-1}.

I need to check if this system has a solution where all o_i >= 0.

This seems promising.

Let me try to solve this system step by step.

Starting from the last equation:

o_{n-1} = a_n

Then, from the second last equation:

o_{n-2} + 2*o_{n-1} = a_{n-1}

Substituting o_{n-1}:

o_{n-2} + 2*a_n = a_{n-1}

So, o_{n-2} = a_{n-1} - 2*a_n

Similarly, from the previous equation:

o_{n-3} + 2*o_{n-2} + o_{n-1} = a_{n-2}

Substituting o_{n-2} and o_{n-1}:

o_{n-3} + 2*(a_{n-1} - 2*a_n) + a_n = a_{n-2}

Simplify:

o_{n-3} + 2*a_{n-1} - 4*a_n + a_n = a_{n-2}

o_{n-3} + 2*a_{n-1} - 3*a_n = a_{n-2}

So, o_{n-3} = a_{n-2} - 2*a_{n-1} + 3*a_n

This pattern seems to be emerging, but it's getting complicated.

Maybe there's a general formula for o_i in terms of a_j.

Alternatively, perhaps there's a better way to approach this.

Wait a minute, perhaps I can use the fact that the operations are similar to convolution or some kind of smoothing.

Alternatively, maybe there's a way to express the operations in terms of prefix sums or differences.

Let me consider prefix sums.

Define s_i = o2 + o3 + ... + oi

Then, looking at the equations:

o2 = a1

2*o2 + o3 = a2

o2 + 2*o3 + o4 = a3

...

o_{n-2} + 2*o_{n-1} = a_{n-1}

o_{n-1} = a_n

This seems like a system that can be solved using prefix sums or inclusion-exclusion.

But it's getting too involved for my current understanding.

Maybe I need to look for a different approach.

Let me consider the fact that the operation affects three consecutive elements.

Perhaps I can iterate through the array and greedily apply operations to make each element zero, starting from one end.

For example, start from the left and make each element zero by applying operations that affect it.

But I need to be careful with how operations affect subsequent elements.

Wait, maybe I can use a sliding window approach.

Let me try to process the array from left to right.

Initialize o2, o3, ..., o_{n-1} to zero.

Start with the first element a1.

To make a1 zero, I need to set o2 = a1.

Then, move to a2: 2*o2 + o3 = a2

Since o2 is already set to a1, o3 = a2 - 2*a1

Then, move to a3: o2 + 2*o3 + o4 = a3

Substitute o2 and o3:

a1 + 2*(a2 - 2*a1) + o4 = a3

Simplify:

a1 + 2*a2 - 4*a1 + o4 = a3

o4 = a3 - 2*a2 + 3*a1

Continue this pattern.

This seems like a recursive way to compute o_i in terms of a_j.

However, I need to ensure that all o_i are non-negative.

If any o_i comes out to be negative, then it's impossible.

Let me try this with the first example:

a = [1,3,5,5,2]

n=5

Compute o2 to o4.

Set o2 = a1 = 1

Then o3 = a2 - 2*a1 = 3 - 2*1 = 1

Then o4 = a3 - 2*a2 + 3*a1 = 5 - 2*3 + 3*1 = 5 - 6 + 3 = 2

Then check o4 = a4 - 2*a3 + 3*a2 - 4*a1 = 5 - 2*5 + 3*3 - 4*1 = 5 - 10 + 9 - 4 = 0

Wait, that seems inconsistent.

I need a general formula.

Wait, perhaps I can generalize o_i as follows:

o_i = a_i - a_{i+1} + o_{i+1}

But I'm not sure.

This is getting too complicated.

Maybe there's a different way to look at it.

Let me consider that each operation at i reduces a_{i-1}, a_i, and a_{i+1} by 1,2,1 respectively.

So, the net effect is a kind of smoothing operation.

Maybe I can think in terms of the differences between consecutive elements.

Let me consider the first differences d_i = a_i - a_{i-1}

Then, applying an operation at i affects d_i and d_{i+1}.

Specifically:

- d_i = a_i - a_{i-1} -> (a_i - 2) - (a_{i-1} - 1) = a_i - a_{i-1} -1 = d_i -1

- d_{i+1} = a_{i+1} - a_i -> (a_{i+1} -1) - (a_i -2) = a_{i+1} - a_i +1 = d_{i+1} +1

So, applying an operation at i decreases d_i by 1 and increases d_{i+1} by 1.

This is interesting because it shows that the operations are shifting "deficits" or "surpluses" between differences.

So, if I look at the sequence of differences, I can see how operations affect these differences.

Starting from the left, I can try to balance the differences by applying operations to shift the excess to the right.

Let me try this with the first example:

a = [1,3,5,5,2]

differences:

d1 = 1 - 0 = 1 (assuming a_0 = 0)

d2 = 3 - 1 = 2

d3 = 5 - 3 = 2

d4 = 5 - 5 = 0

d5 = 2 - 5 = -3

So, d = [1,2,2,0,-3]

Now, applying an operation at i=2:

- d2 decreases by 1: 2 -1 =1

- d3 increases by 1: 2 +1 =3

So, d becomes [1,1,3,0,-3]

Then, apply operation at i=3:

- d3 decreases by 1: 3 -1 =2

- d4 increases by 1: 0 +1 =1

d = [1,1,2,1,-3]

Apply operation at i=4:

- d4 decreases by 1:1 -1=0

- d5 increases by 1: -3 +1=-2

d = [1,1,2,0,-2]

Apply operation at i=3 again:

- d3 decreases by 1:2 -1=1

- d4 increases by 1:0 +1=1

d = [1,1,1,1,-2]

Apply operation at i=4 again:

- d4 decreases by 1:1 -1=0

- d5 increases by 1:-2 +1=-1

d = [1,1,1,0,-1]

It seems like no matter how I apply operations, I can't get all differences to zero because of the negative values.

Wait, but in the first example, it's possible to make the array zero. So maybe this approach isn't correct.

Wait, perhaps I need to consider that the sum of the differences should be zero for the array to be reducible to zero.

Sum of d_i should be equal to a_n - a_0, which is a_n, since a_0=0.

In the first example, a_n=2, and sum of d_i is 1+2+2+0-3=2, which matches.

In the second example, let's see.

a = [2,4,4,5,1]

d = [2,2,0,1,-4]

Sum is 2+2+0+1-4=1, but a_n=1, which matches.

But in the first example, even though the differences don't sum to zero, the array can be made zero.

Wait, no, in the first example, sum of d_i is 2, and a_n=2, which matches.

Wait, actually, sum of d_i should be equal to a_n, which it is.

But in the first example, it's possible to make the array zero, while in the second example, it's not.

So, sum of d_i equal to a_n is necessary but not sufficient.

I need to find another condition.

Perhaps I need to ensure that at no point do the cumulative sums become negative.

Let me think about cumulative sums.

Define c_i = d1 + d2 + ... + d_i

Then, c_n = a_n, as expected.

In the first example:

c = [1,3,5,5,2]

Wait, no.

Wait, c1 = d1 =1

c2 = d1 + d2 =1+2=3

c3 =1+2+2=5

c4=5+0=5

c5=5-3=2

So, c = [1,3,5,5,2]

Now, applying operations affects the differences as follows:

Each operation at i decreases d_i by 1 and increases d_{i+1} by 1.

So, it shifts one unit from d_i to d_{i+1}.

This is similar to shifting water from one bucket to another.

So, if I have a deficit in d_i, I can try to fill it from the previous differences.

But in the first example, starting from c1=1, c2=3, c3=5, c4=5, c5=2.

To make all c_i zero, I need to balance the cumulative sums.

Wait, perhaps I need to ensure that the cumulative sums are non-negative.

In the first example, all c_i are non-negative, and c_n = a_n =2.

But the target is to make c_n =0, so perhaps I need to adjust accordingly.

Wait, maybe I need to ensure that the cumulative sums, after applying operations, can be reduced to zero.

This is getting too convoluted.

Let me look for a different approach.

Perhaps I can consider the array as a system where each operation reduces the array in a specific pattern, and I need to see if the target vector (all zeros) is reachable from the initial array.

In linear algebra terms, it's about whether the initial array is in the span of the operation vectors.

Given the constraints, I need an efficient way to check this.

Let me consider the matrix formed by the operations.

Each operation corresponds to a vector:

For i=2: [-1, -2, -1, 0, ..., 0]

For i=3: [0, -1, -2, -1, 0, ..., 0]

And so on.

This is similar to a tridiagonal matrix.

Given that, I can represent the operations as the columns of a matrix and see if the initial array is in the column space.

But again, with large n, this isn't practical.

Maybe I can look for invariants or properties that the array must satisfy for it to be reducible to zero.

Let me consider the sum of the array elements.

Each operation reduces the sum by 4.

So, the total sum must be divisible by 4.

But in the second example, the sum is 16, which is divisible by 4, but it's still "NO".

So, that's not sufficient.

Perhaps there's another condition.

Let me consider the parity of the elements.

But in the first example, all elements are odd or even, but in other examples, they're mixed.

Wait, in the first example, [1,3,5,5,2], which is mixed.

In the second, [2,4,4,5,1], also mixed.

Not sure.

Maybe I need to look at the differences between elements.

Wait, perhaps I need to ensure that certain subarrays sum to specific values.

Alternatively, maybe I need to ensure that the array can be expressed as a combination of certain patterns.

This is getting too vague.

Let me consider the dual approach: instead of applying operations to reduce the array, build the array from operations.

Each operation at i adds [-1, -2, -1] to positions i-1, i, i+1.

So, building the array would mean finding operations that, when added, give the original array.

But since operations subtract, it's equivalent to finding operations whose combined effect equals the negative of the original array.

But again, this seems too abstract for my current level.

Maybe I need to look for a different strategy.

Let me consider the fact that operations can be applied any number of times, and any index i can be used zero or more times.

So, perhaps I can model this as a system where each operation is a vector, and I need to find non-negative integer combinations of these vectors that sum to the negative of the original array.

This is similar to solving a system of linear equations with non-negative integer constraints, which is generally difficult, especially for large n.

Given the time constraints, I need a more efficient way.

Let me consider the following approach:

- Start from the left, and for each position, determine how many operations to apply to make it zero, considering the impact on the next positions.

- Propagate the effects to the right.

This sounds like a greedy approach.

Let me try implementing this.

Define o_i as the number of operations applied at position i (where i ranges from 2 to n-1).

Then, the effect on the array is:

a1: -o2 = -a1 => o2 = a1

a2: -2*o2 - o3 = -a2 => o3 = a2 - 2*o2 = a2 - 2*a1

a3: -o2 -2*o3 - o4 = -a3 => o4 = a3 - o2 -2*o3 = a3 - a1 -2*(a2 - 2*a1) = a3 - a1 -2*a2 + 4*a1 = a3 -2*a2 +3*a1

And so on.

This seems recursive, and I need to ensure that all o_i are non-negative.

In the first example:

a1=1, a2=3, a3=5, a4=5, a5=2

Compute o2 =1

o3 =3 -2*1=1

o4=2 -1 -2*1= -1

Wait, o4 comes out to be negative, which is invalid.

But in the first example, it's possible to make the array zero.

Wait, maybe I made a mistake in the computation.

Wait, according to the earlier simulation, it's possible, but according to this, o4 is -1, which is invalid.

So, perhaps this approach isn't correct.

Wait, maybe I need to adjust the order of computation.

Let me try computing o_i from left to right, ensuring that o_i >=0 at each step.

Starting with o2 = a1 =1

Then o3 = a2 -2*o2 =3-2*1=1

Then o4 = a3 - o2 -2*o3 =5 -1 -2*1=2

Then o5 = a4 - o3 -2*o4 =5 -1 -4=0

Then o6 = a5 - o4 -2*o5=2 -2 -0=0

Wait, in this case, o4=2, o5=0, o6=0

But in the earlier simulation, o4 came out to be -1, which was incorrect.

Perhaps I made a mistake in the earlier computation.

Let me recast the equations.

Given:

o2 = a1

o3 = a2 - 2*o2

o4 = a3 - o2 - 2*o3

o5 = a4 - o3 - 2*o4

o6 = a5 - o4 - 2*o5

Wait, but in the first example, n=5, so o2 to o4.

So:

o2 =1

o3=3-2*1=1

o4=5-1-2*1=2

Then, check a4: 5 - o3 -2*o4 =5 -1 -4=0

And a5:2 - o4 -2*o5=2-2-0=0

This seems consistent.

So, in this case, o4=2, which is non-negative.

Wait, earlier I thought o4 was -1, but that was a mistake.

So, in this case, o3=1, o4=2, which are both non-negative, so it's possible.

In the second example:

a=[2,4,4,5,1]

n=5

o2=2

o3=4-2*2=0

o4=5-2-2*0=3

Then check a5=1 - o4 -2*o5=1-3-0=-2, which is negative, invalid.

Hence, "NO"

In the third example:

a=[0,1,3,3,1]

o2=0

o3=1-2*0=1

o4=3-0-2*1=1

o5=3-1-2*1=0

o6=1-1-2*0=0

All o_i >=0, so "YES"

In the fourth example:

a=[5,6,0,2,3,0]

n=6

o2=5

o3=6-2*5= -4, which is invalid, so "NO"

In the fifth example:

a=[1,2,7,2]

n=4

o2=1

o3=2-2*1=0

o4=7-1-2*0=6

o5=2-0-2*6= -10, invalid, "NO"

In the sixth example:

a=[7,1,0]

n=3

o2=7

o3=1-2*7= -13, invalid, "NO"

In the seventh example:

a=[1,1,1,1]

n=4

o2=1

o3=1-2*1= -1, invalid, "NO"

So, according to this approach, it correctly classifies the examples.

Therefore, this seems to be a valid approach.

Hence, the program should implement this:

- For each test case:

- Read n and the array a.

- Initialize o2 = a1

- Then o3 = a2 - 2*o2

- o4 = a3 - o2 - 2*o3

- ...

- Continue up to o_{n-1} = a_{n-1} - o_{n-2} - 2*o_{n-1}

- And o_n = a_n - o_{n-1} - 2*o_n

- Check if all o_i >=0

- If yes, "YES"; else, "NO"

Wait, but in the last step, o_n is defined in terms of o_{n-1} and o_n itself, which seems recursive.

Wait, perhaps I need to adjust the indexing.

Let me define o_i for i from 2 to n-1.

Then, the equations are:

o2 = a1

o3 = a2 - 2*o2

o4 = a3 - o2 -2*o3

...

o_{k} = a_{k-1} - o_{k-2} -2*o_{k-1}

...

o_{n-1} = a_{n-2} - o_{n-3} -2*o_{n-2}

o_n = a_{n-1} - o_{n-2} -2*o_{n-1}

o_{n+1} = a_n - o_{n-1} -2*o_n

But this seems off.

Wait, perhaps I need to stop at o_{n-1}, and the last equation is o_n = a_n - o_{n-1}

But I need to verify this.

In the first example, n=5:

o2=1

o3=3-2*1=1

o4=5-1-2*1=2

o5=5-1-2*2=0

o6=2-2-2*0=0

But o6 is not used, as n=5.

Wait, perhaps I need to adjust the indices.

Let me try to generalize.

For i from 2 to n-1:

o_i = a_{i-1} - o_{i-1} -2*o_i

Wait, that doesn't make sense.

I think I need to revisit the equations.

Given:

a1: -o2 = -a1 => o2 = a1

a2: -2*o2 - o3 = -a2 => o3 = a2 - 2*o2

a3: -o2 -2*o3 - o4 = -a3 => o4 = a3 - o2 -2*o3

...

a_{n-1}: -o_{n-2} -2*o_{n-1} = -a_{n-1} => o_{n-1} = (a_{n-1} - o_{n-2}) / 2

a_n: -o_{n-1} = -a_n => o_{n-1} = a_n

So, from the last equation, o_{n-1} = a_n

Then, from the previous equation: o_{n-1} = (a_{n-1} - o_{n-2}) / 2

But from o_{n-1} = a_n, we have a_n = (a_{n-1} - o_{n-2}) / 2

So, o_{n-2} = a_{n-1} - 2*a_n

And so on, recursively.

This seems like a way to compute o_i from right to left.

Let me try this with the first example:

n=5

a=[1,3,5,5,2]

Compute o4 = a5 =2

Then o3 = a4 - 2*o4 =5 -4=1

Then o2 = a3 - o3 -2*o4 =5 -1 -4=0

Then check o2 = a1=1, but o2=0, which doesn't match.

Wait, that's inconsistent.

I must have made a mistake.

Wait, perhaps I need to adjust the equations.

From a1: -o2 = -a1 => o2 = a1

From a2: -2*o2 - o3 = -a2 => o3 = a2 - 2*o2

From a3: -o2 -2*o3 - o4 = -a3 => o4 = a3 - o2 -2*o3

From a4: -o3 -2*o4 - o5 = -a4 => o5 = a4 - o3 -2*o4

From a5: -o4 -2*o5 = -a5 => o5 = (a5 - o4)/2

But from the previous equation, o5 = a4 - o3 -2*o4

So, set (a5 - o4)/2 = a4 - o3 -2*o4

Solve for o3: o3 = a4 -2*o4 - (a5 - o4)/2

But this seems too complicated.

Perhaps I need to compute o_i from left to right.

Set o2 = a1

Then o3 = a2 - 2*o2

Then o4 = a3 - o2 -2*o3

And so on, until o_{n-1} = a_{n-2} - o_{n-3} -2*o_{n-2}

Then, o_n = a_{n-1} - o_{n-2} -2*o_{n-1}

But I need to ensure that o_n = a_n

So, in the first example:

o2=1

o3=3-2*1=1

o4=5-1-2*1=2

o5=5-1-2*2=0

o5 should also equal a5=2, but here o5=0, which doesn't match a5=2.

Wait, but according to the earlier simulation, it's possible to make the array zero.

So, perhaps this approach is incorrect.

I must have misunderstood something.

Let me try to think differently.

Suppose I define o_i for i from 2 to n-1.

Then, express a_i in terms of o_j.

a1 = o2

a2 = 2*o2 + o3

a3 = o2 + 2*o3 + o4

...

a_{n-1} = o_{n-2} + 2*o_{n-1}

a_n = o_{n-1}

This is similar to a system of equations where each a_i is expressed in terms of o_j.

This is a lower triangular system, which can be solved sequentially.

Starting from a1, we can find o2, then o3, and so on.

Let me try this with the first example:

a1=1 => o2=1

a2=3=2*1 + o3 => o3=1

a3=5=1 + 2*1 + o4 => o4=2

a4=5=o3 + 2*o4 =1 +4=5 => o5=0

a5=2=o4=2, but o4=2, which matches a5=2.

Wait, but earlier I had o5=0, which should be equal to a5=2, which doesn't match.

Wait, perhaps I need to adjust the equations.

Wait, according to the definitions:

a_n = -o_{n-1} = -a_n

Wait, no, earlier I had o_n = a_n - o_{n-1} -2*o_n

This is getting too tangled.

I need to find a better way.

Let me look for a pattern or a mathematical invariant that must hold for the array to be reducible to zero.

Perhaps I can consider the array as a quadratic form or something similar, but that's beyond my current capabilities.

Alternatively, maybe I can look for a specific property that must be satisfied.

Let me consider that each operation reduces the sum of the array by 4.

So, the total sum must be divisible by 4.

But in the second example, the sum is 16, which is divisible by 4, but it's still "NO".

So, that's not sufficient.

Maybe there's another condition related to the differences or cumulative sums.

Let me consider the differences again.

From earlier, applying an operation at i decreases d_i by 1 and increases d_{i+1} by 1.

So, operations can shift "deficits" from d_i to d_{i+1}.

Therefore, to make all d_i zero, I need to ensure that the cumulative sum of the differences can be balanced appropriately.

In other words, starting from d1, I need to ensure that for each d_i, the cumulative sum up to d_i is non-negative, and the final cumulative sum is zero.

This is similar to the concept of "loan balancing" or "bucket filling".

So, in terms of the differences, I need to ensure that:

- The cumulative sum of d_i from i=1 to k is >=0 for all k from 1 to n-1

- The total sum of d_i is equal to a_n

But in the first example, the cumulative sums are:

c1=1

c2=3

c3=5

c4=5

c5=2

The cumulative sums are all non-negative, and c5=a_n=2.

But to make the array zero, I need to reduce c5 to zero.

So, perhaps I need to ensure that the cumulative sums can be reduced to zero by applying operations that shift deficits.

Wait, perhaps I need to ensure that the cumulative sums are monotonically non-decreasing up to the end.

But in this case, c5=2 is less than c4=5, which might be a problem.

Wait, in the first example, it's possible to make the array zero, so maybe this condition isn't correct.

Let me think differently.

Suppose I define b_i = a_i - a_{i-1}, with a_0=0.

Then, b_i is the difference between a_i and a_{i-1}.

Applying an operation at i decreases b_i by 1 and increases b_{i+1} by 1.

So, operations can shift values from b_i to b_{i+1}.

Therefore, to make all a_i zero, I need to make all b_i zero by shifting values through operations.

This is similar to moving "deficits" or "surpluses" along the array.

So, starting from b1, I can shift its value to b2, then to b3, and so on.

But I need to ensure that at each step, I don't create negative values that can't be balanced.

Therefore, a necessary condition is that the cumulative sum of b_i up to any point k should be non-negative.

In other words, for all k, sum_{i=1}^k b_i >=0

Additionally, the total sum of b_i should be zero, since I need to reduce the array to zero.

Wait, but in the first example, sum of b_i is 2, which is equal to a_n=2.

So, perhaps the cumulative sums should be >=0, and the final cumulative sum should be zero.

Wait, but in the first example, the final cumulative sum is 2, not zero.

So, perhaps I need to adjust the approach.

Let me consider that to make a_i zero, the cumulative sum up to i should be <= the cumulative sum up to i-1.

Wait, I'm getting confused.

Let me look for a different perspective.

Suppose I consider the array as a sequence of "blocks" that need to be reduced.

Each operation reduces a block and its neighbors.

This seems similar to the concept of smoothing or averaging.

But I need a more concrete approach.

Let me consider the dual problem: building up the array from zero using reverse operations.

Each reverse operation adds 1 to a_{i-1}, 2 to a_i, and 1 to a_{i+1}.

So, the array can be built by adding such patterns.

This seems similar to signal processing or convolution.

But again, this is too vague.

Let me consider the problem in terms of linear algebra.

Define the operation matrix O, where each row corresponds to an operation at a particular i.

Each operation affects a_{i-1}, a_i, a_{i+1}.

I need to solve O * x = a, where x are the number of operations applied at each i.

This is a system of linear equations.

But with n up to 2*10^5, solving this directly is impossible.

I need a smarter way.

Let me consider that the operations form a basis for the space of arrays.

But I doubt that's the case.

Alternatively, perhaps I can find a rank of the operation matrix and see if it spans the space containing a.

But again, too time-consuming.

Given time constraints, perhaps I should look for a pattern or a mathematical formula that can quickly determine if the array can be reduced to zero.

Looking back at the earlier approach, where I compute o_i sequentially and check if they are non-negative, it seems to work for the examples.

In the first example, o2=1, o3=1, o4=2, which are all >=0, so "YES"

In the second example, o2=2, o3=0, o4=3, but then o5 would be negative, so "NO"

In the