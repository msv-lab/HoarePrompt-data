Alright, I've got this problem to solve. Let's see what it's about. So, Rudolf has an array of integers, and he can perform a specific operation on it any number of times. The operation involves choosing an index i (which has to be between 2 and n-1, inclusive), and then decrementing a[i-1], a[i], and a[i+1] by 1, 2, and 1, respectively. The goal is to make all elements of the array zero using these operations.

First, I need to understand the operation clearly. So, for any chosen i (where 2 ≤ i ≤ n-1), the operation affects three consecutive elements: a[i-1], a[i], and a[i+1]. It decreases a[i-1] by 1, a[i] by 2, and a[i+1] by 1. This operation can be applied any number of times, and any index i can be chosen zero or more times.

My task is to determine whether it's possible to make all elements of the array zero after performing these operations some number of times.

Let me think about this. Since the operations can be applied multiple times, and the changes are additive, I need to find a way to accumulate the operations in such a way that all elements become zero.

I recall that in similar problems involving operations on arrays where elements are incremented or decremented in a specific pattern, sometimes the problem can be modeled using differences or cumulative sums.

Let me consider the array as a sequence and see if there's a pattern or a mathematical property that can help me determine the possibility of making all elements zero.

Let's denote the array as a1, a2, a3, ..., an.

Each operation on index i changes a[i-1], a[i], and a[i+1] by -1, -2, and -1, respectively.

I need to find a series of such operations that result in all ai being zero.

This seems like a system of linear equations, where each operation corresponds to subtracting a certain vector from the array.

But with n up to 2*10^5 and t up to 10^4, solving it as a system of equations is not feasible due to time constraints.

I need a smarter approach.

Let me think differently. Suppose I try to reverse-engineer the process. Instead of starting with the initial array and applying operations to reach all zeros, maybe I can start from all zeros and build up to the given array using the reverse operations.

But that might not help directly.

Another approach: since each operation affects three consecutive elements, perhaps I can look at the array in a sliding window of three elements and see how operations affect them.

Wait, but operations can be applied multiple times, and the effects are additive, so maybe I can think in terms of the total operations applied to each position.

Let me define oi as the number of times operation is applied with index i.

Then, for each i from 2 to n-1, the operation decrements:

- a[i-1] by oi

- a[i] by 2*oi

- a[i+1] by oi

So, for each position j from 1 to n, the total decrement is:

- For j=1: decremented by o2

- For j=2: decremented by o2 + 2*o3

- For j=3: decremented by o3 + 2*o4 + o2

- ...

- For j=k: decremented by ok + 2*ok+1 + ok+2 (for k in appropriate range)

- For j=n-1: decremented by on-2 + 2*on-1

- For j=n: decremented by on-1

Wait, maybe I need to set up equations for each position.

Let me try to write equations for the decrements.

Let me define oi as the number of times operation is applied with index i.

Then, for each position j:

- If j=1: a[j] -= o2

- If j=2: a[j] -= 2*o2 + o3

- If j=3: a[j] -= o2 + 2*o3 + o4

- ...

- If j=k (2 <= k <= n-1): a[j] -= o_{k-1} + 2*ok + o_{k+1}

- If j=n-1: a[j] -= o_{n-2} + 2*o_{n-1}

- If j=n: a[j] -= o_{n-1}

We want a[j] -= (certain expression in terms of oi) = 0 for all j.

This seems complicated to solve directly.

Maybe there's a better way.

Let me look for invariants or properties that must hold for the array to be reducible to zero.

One thing I notice is that the operation always decreases the sum of the array by 4 (since -1 -2 -1 = -4). So, the total sum of the array must be divisible by 4 for it to be possible to reach zero.

Wait, but that's not necessarily true because operations can be applied multiple times, and the sum decreases by 4 each time, but the initial sum doesn't have to be divisible by 4; it just needs to be possible to reach zero through a series of such operations.

Wait, actually, if each operation decreases the sum by 4, then for the array to reach zero, the initial sum must be divisible by 4.

Yes, that makes sense.

So, a necessary condition is that the sum of the array is divisible by 4.

But is it sufficient?

Probably not, because there might be other constraints on how the operations affect the array.

Let me check the examples.

In the first example:

n=5, array=[1,3,5,5,2]

Sum is 1+3+5+5+2=16, which is divisible by 4.

And it's possible to make all elements zero.

In the second example:

n=5, array=[2,4,4,5,1]

Sum is 2+4+4+5+1=16, which is divisible by 4.

But it's not possible to make all elements zero.

So, the sum being divisible by 4 is necessary but not sufficient.

I need more conditions.

Let me think differently.

Maybe I can model this as a system where each operation affects a certain range, and see if I can cover the entire array with these operations to zero out everything.

Alternatively, perhaps there's a way to represent the operations in terms of differences.

Let me consider the differences between consecutive elements.

Define d1 = a1, d2 = a2 - a1, d3 = a3 - a2, ..., dn = an - a{n-1}.

But I'm not sure if that helps directly.

Wait, perhaps cumulative sums could be useful here.

Let me define s0 = 0, s1 = a1, s2 = a1 + a2, s3 = a1 + a2 + a3, ..., sn = a1 + a2 + ... + an.

But I'm not sure.

Wait, maybe I can look at the array in terms of its second differences.

In some problems involving operations that affect consecutive elements, second differences can be useful.

Let me recall that in discrete calculus, the second difference can relate to operations that affect three consecutive elements.

Define the second difference as delta2[j] = a[j] - 2*a[j-1] + a[j-2], for j from 2 to n-1.

Wait, perhaps.

In the operation, when I apply it to index i, it changes a[i-1], a[i], a[i+1] by -1, -2, -1.

So, the second difference at position i would be:

delta2[i] = a[i] - 2*a[i-1] + a[i-2]

After the operation, it would be:

delta2[i]' = (a[i] - 2) - 2*(a[i-1] - 1) + (a[i-2] - 1) = a[i] - 2 - 2*a[i-1] + 2 + a[i-2] - 1 = a[i] - 2*a[i-1] + a[i-2] -1 = delta2[i] -1

Wait, that seems interesting.

So, applying an operation affects the second differences.

But I need to think more carefully.

Wait, perhaps I need to consider that the operations can be seen as applying a certain "filter" or "kernel" to the array, and see if I can invert that to reach zero.

This seems complicated.

Let me try to think of it in terms of linear algebra.

Each operation corresponds to subtracting a specific vector from the array.

For example, operation on index i subtracts [-1, -2, -1] from positions i-1, i, i+1.

So, if I represent the array as a vector, and each operation as subtracting a specific vector, then the problem reduces to whether the vector corresponding to the initial array is in the span of the operation vectors.

But with large n and t, this isn't practical to compute directly.

I need a better approach.

Let me look for patterns or properties that the array must satisfy for it to be possible to zero it out.

Looking back at the examples:

First test case:

n=5, a=[1,3,5,5,2]

Sum is 16, which is divisible by 4, and it's possible.

Second test case:

n=5, a=[2,4,4,5,1]

Sum is 16, which is divisible by 4, but it's not possible.

So, there must be another condition beyond the sum being divisible by 4.

Let me see what's different between these two arrays.

In the first array: [1,3,5,5,2]

After some operations, it can be zeroed out.

In the second array: [2,4,4,5,1]

It cannot be zeroed out, despite the sum being the same.

Is there a pattern in the differences or something else?

Let me look at the differences between consecutive elements.

For the first array:

Differences: 3-1=2, 5-3=2, 5-5=0, 2-5=-3

For the second array:

Differences: 4-2=2, 4-4=0, 5-4=1, 1-5=-4

Not sure if that helps.

Wait, perhaps I need to consider the second differences.

For the first array:

Second differences:

a2 - 2*a1 + a0 = 3 - 2*1 + 0 = 1

a3 - 2*a2 + a1 = 5 - 2*3 + 1 = 0

a4 - 2*a3 + a2 = 5 - 2*5 + 3 = -2

a5 - 2*a4 + a3 = 2 - 2*5 + 5 = -3

For the second array:

Second differences:

a2 - 2*a1 + a0 = 4 - 2*2 + 0 = 0

a3 - 2*a2 + a1 = 4 - 2*4 + 2 = -2

a4 - 2*a3 + a2 = 5 - 2*4 + 4 = 1

a5 - 2*a4 + a3 = 1 - 2*5 + 4 = -5

Not sure if that's useful.

Wait, perhaps I need to consider that the operations affect the second differences in a specific way.

Earlier, I thought that each operation decreases the second difference at position i by 1, but I need to verify that.

Wait, perhaps I need to think differently.

Let me consider that the operations can be applied multiple times, and they affect specific positions.

Maybe I can model this as a system of equations where I need to solve for the number of times each operation is applied.

So, for each position, I can write an equation based on how the operations affect it.

For example, for position 1:

a1 - o2 = 0 => o2 = a1

For position 2:

a2 - 2*o2 - o3 = 0

For position 3:

a3 - o2 - 2*o3 - o4 = 0

...

For position n-1:

a_{n-1} - o_{n-2} - 2*o_{n-1} - o_n = 0

For position n:

a_n - o_{n-1} = 0

This seems like a system of linear equations that I need to solve for o2 to o_{n-1}.

But with n up to 2*10^5, solving this system directly is not feasible.

I need a smarter way to determine if the system has a solution.

Let me try to see if I can solve this system step by step.

Starting from position 1:

o2 = a1

From position n:

o_{n-1} = a_n

Then, from position n-1:

o_{n-2} + 2*o_{n-1} + o_n = a_{n-1}

But o_{n-1} is already known from position n.

Similarly, from position n-2:

o_{n-3} + 2*o_{n-2} + o_{n-1} = a_{n-2}

And so on.

This seems like a recurrence relation that I can solve backward.

Wait, perhaps I can iterate from the end to the beginning, calculating the required operations based on the known values.

Let me try this approach.

Start with o2 = a1

Then, from position 2:

a2 - 2*o2 - o3 = 0 => o3 = a2 - 2*o2

But o2 is already set to a1, so o3 = a2 - 2*a1

Then, from position 3:

a3 - o2 - 2*o3 - o4 = 0 => o4 = a3 - o2 - 2*o3

Substituting o2 and o3:

o4 = a3 - a1 - 2*(a2 - 2*a1) = a3 - a1 - 2*a2 + 4*a1 = a3 - 2*a2 + 3*a1

Continuing this way, I can express each oi in terms of a1, a2, ..., a_n.

But I need to check if all oi are non-negative integers, since the number of operations can't be negative.

Wait, but in the problem, there are no constraints on the number of operations, only that they are integers. But in the context, it makes sense that operations are non-negative.

So, perhaps the condition is that all oi are integers and non-negative.

But this seems too involved to compute for large n.

Is there a better way?

Let me consider the necessary conditions for the array to be reducible to zero.

I already have that the sum must be divisible by 4.

Additionally, looking at the operations, perhaps there are constraints on the differences between consecutive elements.

Wait, perhaps I can look at the array in terms of its "peaks" and "valleys", and see how operations can flatten them.

But that seems vague.

Let me consider a smaller array and see if I can find a pattern.

Take n=3, array [a,b,c]

Operations can only be applied on i=2.

So, operation on i=2: a1 -=1, a2 -=2, a3 -=1

So, [a-1, b-2, c-1]

To make all zero: a-1=0, b-2=0, c-1=0 => a=1, b=2, c=1

So, only [1,2,1] can be reduced to [0,0,0] with one operation.

If a=1, b=2, c=1, sum is 4, which is divisible by 4.

If a=2, b=4, c=2, sum is 8, which is divisible by 4.

But [2,4,2] can be reduced by applying the operation twice: first [1,2,1], then [0,0,0].

So, in this case, it works.

But what about [2,3,2]? Sum is 7, not divisible by 4.

Cannot be reduced to zero.

So, in this small case, the sum being divisible by 4 seems sufficient.

But in the larger examples, it's not sufficient.

So, perhaps for n=3 it's sufficient, but for larger n, there are additional constraints.

Let me try n=4.

Array [a,b,c,d]

Operations can be on i=2 or i=3.

Operation on i=2: a -=1, b-=2, c-=1

Operation on i=3: b -=1, c-=2, d-=1

So, total decrements:

a: -o2

b: -2*o2 - o3

c: -o2 -2*o3 - o4

d: -o3 - o4

We want:

a - o2 = 0 => o2 = a

b - 2*o2 - o3 = 0 => o3 = b - 2*o2

But o2 = a, so o3 = b - 2*a

Similarly, c - o2 - 2*o3 - o4 = 0 => o4 = c - o2 - 2*o3

Substituting o2 and o3:

o4 = c - a - 2*(b - 2*a) = c - a - 2*b + 4*a = c - 2*b + 3*a

Finally, d - o3 - o4 = 0 => o3 + o4 = d

Substituting o3 and o4:

(b - 2*a) + (c - 2*b + 3*a) = d

Simplify:

b - 2*a + c - 2*b + 3*a = d => ( -2*a + 3*a ) + ( b - 2*b ) + c = d => a - b + c = d

So, for n=4, in addition to the sum being divisible by 4, we must have a - b + c = d.

Interesting.

Let me check this condition with some examples.

Take [1,2,1,0]

Check a - b + c = 1 - 2 + 1 = 0, which equals d=0.

Sum is 1+2+1+0=4, divisible by 4.

So, it should be possible.

Let's see:

Apply operation on i=2: [1-1, 2-2, 1-1, 0] = [0,0,0,0]

Yes, it works.

Another example: [2,4,2,0]

Sum is 8, divisible by 4.

Check a - b + c = 2 - 4 + 2 = 0 = d.

Apply operation twice on i=2: first time [1,2,1,0], second time [0,0,0,0].

Works.

Another example: [2,3,2,0]

Sum is 7, not divisible by 4.

Cannot be reduced to zero.

Another example: [2,3,2,1]

Sum is 8, divisible by 4.

Check a - b + c = 2 - 3 + 2 = 1 = d.

So, it should be possible.

Let's try:

Apply operation on i=2: [1,1,1,0]

Then, apply operation on i=3: [1,0,0,0]

But a1=1 !=0.

So, it's not possible.

Wait, but according to the condition, a - b + c = d (1=1), and sum is 8, divisible by 4, but it's not possible.

So, my condition is insufficient.

I must have made a mistake.

Wait, in the earlier step, I had o4 = c - o2 - 2*o3

With o2 = a, o3 = b - 2*a

So, o4 = c - a - 2*(b - 2*a) = c - a - 2*b + 4*a = c - 2*b + 3*a

And then o3 + o4 = d

So, (b - 2*a) + (c - 2*b + 3*a) = d => a - b + c = d

But in this example, a=2, b=3, c=2, d=1

So, 2 - 3 + 2 = 1, which equals d=1.

But when I apply the operations, I don't reach [0,0,0,0].

Wait, maybe I need to apply operations in a different sequence.

First apply operation on i=3: [2,3,1,0]

Then apply operation on i=2: [1,1,0,0]

Then apply operation on i=3: [1,0,0,0]

Still a1=1 !=0.

So, even though the conditions are satisfied, it's not possible.

So, my condition is insufficient.

I need to think differently.

Perhaps I need to look for a general pattern or find a way to express the operations in terms of the array elements.

Wait, perhaps I can model this as a system where the operations correspond to certain basis vectors.

Alternatively, maybe I can use the concept of invariant or some mathematical property that must hold for the array to be reducible to zero.

Let me consider that each operation decreases the sum by 4.

Moreover, in the operation, the central element is decreased by 2, and the neighbors by 1 each.

So, perhaps there's a way to represent this in terms of differences or some other mathematical construct.

Alternatively, perhaps I can consider the array as a system of equations where each equation corresponds to the condition that the element becomes zero after applying the operations.

But with large n, solving this directly is not feasible.

I need a more efficient way.

Let me consider the differences between consecutive elements.

Define b[i] = a[i] - a[i-1] for i from 2 to n.

Then, the operation on i decreases b[i] by 1 and b[i+1] by 1.

Wait, b[i] = a[i] - a[i-1]

After operation on j:

a[j-1] -=1, a[j] -=2, a[j+1] -=1

So, b[j] = a[j] - a[j-1] becomes (a[j] - 2) - (a[j-1] -1) = a[j] - a[j-1] -1 = b[j] -1

Similarly, b[j+1] = a[j+1] - a[j] becomes (a[j+1] -1) - (a[j] -2) = a[j+1] - a[j] +1 = b[j+1] +1

Wait, that's interesting.

So, operation on j decreases b[j] by 1 and increases b[j+1] by 1.

So, operations can shift the difference between b[j] and b[j+1].

This seems like water pouring between containers, where you can transfer water from one to the next.

In this case, operations can adjust b[j] and b[j+1] by transferring between them.

So, perhaps if I look at the sequence of b[i], I can see if it's possible to make all b[i] equal to something by these operations.

But ultimately, I need to make all a[i] zero.

Wait, perhaps I can consider the cumulative sum.

Let me think differently.

Suppose I have the array a[1..n], and I want to make all a[i] = 0.

Let me consider defining a new array s where s[i] = a[i] - a[i-1], with s[1] = a[1].

Then, the operations affect s as follows:

Operation on i: s[i] -=1, s[i+1] +=1

Because a[i-1] -=1, a[i] -=2, a[i+1] -=1

So, s[i] = a[i] - a[i-1] becomes (a[i] -2) - (a[i-1] -1) = a[i] - a[i-1] -1 = s[i] -1

And s[i+1] = a[i+1] - a[i] becomes (a[i+1] -1) - (a[i] -2) = a[i+1] - a[i] +1 = s[i+1] +1

So, each operation decreases s[i] by 1 and increases s[i+1] by 1.

This is similar to moving a "deficit" from s[i] to s[i+1].

My goal is to make all a[i] = 0, which would mean making s[i] = 0 for all i.

Wait, no.

If a[i] = 0 for all i, then s[i] = 0 for all i.

But in reality, s[i] represents the difference between a[i] and a[i-1].

So, if I can adjust s[i] by operations that transfer value from s[i] to s[i+1], I need to see if I can make all s[i] = 0.

This seems similar to shifting values along the array.

But I need to think about what the initial s[i] are and whether I can balance them to zero using these operations.

Wait, perhaps I can consider that the sum of s[i] from 1 to k for any k should be adjustible to zero using the operations.

Wait, maybe I need to look at the prefix sums.

Define p[i] = a[1] + a[2] + ... + a[i]

Then, the operation on i affects p[i-1], p[i], and p[i+1]:

p[i-1] -=1, p[i] -=3, p[i+1] -=4, p[i+2] -=1 (assuming i+2 <=n)

Wait, perhaps that's not helpful.

Let me think differently.

Suppose I fix the operations o2, o3, ..., o_{n-1}, and express a[i] in terms of these operations.

From earlier:

a1 - o2 = 0 => o2 = a1

a2 - 2*o2 - o3 = 0 => o3 = a2 - 2*o2 = a2 - 2*a1

a3 - o2 - 2*o3 - o4 = 0 => o4 = a3 - o2 - 2*o3 = a3 - a1 - 2*(a2 - 2*a1) = a3 - a1 - 2*a2 + 4*a1 = a3 - 2*a2 + 3*a1

...

And so on, until an - o_{n-1} = 0 => o_{n-1} = an

But earlier, I had o_{n-1} = a_n

Wait, but in the n=4 case, I had o3 = b - 2*a and o4 = c - o2 - 2*o3

With o2 = a, o3 = b - 2*a, o4 = c - a - 2*(b - 2*a) = c - a - 2*b + 4*a = c - 2*b + 3*a

And o3 + o4 = d

So, (b - 2*a) + (c - 2*b + 3*a) = d => a - b + c = d

Which is the condition I derived earlier.

But in the example where a=2, b=3, c=2, d=1, a - b + c =1 =d, sum=8 divisible by 4, but it's not possible to reduce to zero.

Wait, but in that case, o2 = a =2

o3 = b - 2*a =3 -4=-1

o4 = c - o2 - 2*o3 =2 -2 -2*(-1)=2-2+2=2

But o3 = -1, which is negative, which is invalid.

Wait, in my earlier assumption, o3 = b - 2*a =3 -4=-1, which is negative.

But in reality, operations can't be negative, so this is invalid.

So, perhaps all oi must be non-negative.

In this case, o3 is negative, so it's invalid, meaning it's not possible to reduce to zero.

But in the example, even though a - b + c = d and sum is divisible by 4, it's not possible because o3 is negative.

So, perhaps in addition to a - b + c = d and sum divisible by 4, I need to ensure that all oi are non-negative.

But in this case, o3 is negative, so it's invalid.

Wait, but in the problem statement, it's allowed to apply operations zero or more times, but operations can't be applied fractionally or negatively.

So, perhaps ensuring that all oi are non-negative integers is sufficient.

But in the above example, o3 is negative, so it's invalid.

Hence, in addition to the sum being divisible by 4 and a - b + c = d, I need to ensure that all oi are non-negative.

In this case, o3 = b - 2*a >=0 => b >= 2*a

Similarly, o4 = c - o2 - 2*o3 >=0 => c - a - 2*(b - 2*a) >=0 => c - a -2*b +4*a >=0 => c -2*b +3*a >=0

So, in addition to a - b + c = d and sum divisible by 4, I need b >= 2*a and c -2*b +3*a >=0.

Let me check this with the example [2,3,2,1]

o2 =2

o3 =3-4=-1 <0, invalid

Hence, not possible.

Another example: [1,2,1,0]

o2=1

o3=2-2=0

o4=1-1-2*0=0

And o3 + o4 =0 =d

All oi are non-negative.

Hence, possible.

Another example: [1,3,5,5,2]

From the problem, it's possible.

Let's compute o2 to o4.

o2=1

o3=3-2*1=1

o4=5-1-2*1=2

o5=5 - o3 - o4=5-1-2=2

o6=2 - o4=2-2=0

Wait, n=5, so o2=1, o3=1, o4=2, o5=2

Check if all oi >=0: yes.

And a - b + c =1 -3 +5=3 != d=2, which matches d=2 only if a - b + c =d, which in this case 1-3+5=3 !=2, but in the problem, it's possible.

Wait, contradiction.

Wait, perhaps my earlier condition for n=4 is not generalizable.

I need to think differently.

Perhaps I need to generalize the condition for any n.

Let me consider that the operations can be seen as applying a certain filter, and the problem reduces to solving a system of equations.

But with large n, I need an O(n) solution.

Wait, perhaps I can use the fact that operations can be seen as a kind of convolution, and find a way to compute the required operations in linear time.

Alternatively, maybe there's a way to compute prefix sums or similar to determine the feasibility.

Let me try to iterate through the array and simulate the operations.

Start from the left:

Set o2 = a1

Then, set o3 = a2 - 2*o2

If o3 <0, invalid

Then, o4 = a3 - o2 - 2*o3

If o4 <0, invalid

...

Continue until the end.

Finally, check if the last condition holds.

This seems similar to what I did earlier for n=4.

So, perhaps I can generalize this approach.

Implement it as follows:

- Set o2 = a1

- For i from 3 to n-1:

- Set o_i = a_{i-1} - o_{i-1} - 2*o_{i-2}

- If o_i <0, invalid

- Set o_n = a_n - o_{n-1}

- If o_n <0, invalid

- Finally, check if a_n - o_{n-1} - o_n =0

Wait, I need to make sure that all a_i - (sum of operations affecting it) =0

This seems a bit messy.

Let me try to formalize it.

Define o2, o3, ..., o_{n-1}

Then:

a1 - o2 =0 => o2 =a1

a2 - 2*o2 - o3 =0 => o3 =a2 -2*o2 =a2 -2*a1

a3 - o2 -2*o3 -o4 =0 => o4 =a3 -o2 -2*o3 =a3 -a1 -2*(a2 -2*a1)=a3 -a1 -2*a2 +4*a1=a3 -2*a2 +3*a1

...

And so on, until

an - o_{n-1} =0 => o_{n-1} =an

But in the previous example, o_{n-1} depends on previous o's.

Wait, perhaps I need to iterate from left to right, computing o_i based on previous o's, and ensure that o_i >=0.

Then, at the end, check if the last condition holds.

In code, this would look like:

o2 = a1

o3 = a2 - 2*o2

if o3 <0: invalid

o4 = a3 - o2 - 2*o3

if o4 <0: invalid

...

on = an - o_{n-1}

if on <0: invalid

Finally, check if a_n - o_{n-1} - o_n =0

Wait, I'm getting confused.

Let me try to implement this logic step by step.

Initialize o2 = a1

if o2 <0: invalid

Then, for i from 3 to n-1:

oi = a_{i-1} - o_{i-1} - 2*o_{i-2}

if oi <0: invalid

Finally, on = an - o_{n-1}

if on <0: invalid

Then, check if a_n - o_{n-1} - o_n =0

Wait, but a_n - o_{n-1} - o_n should be zero by construction.

I think I need to adjust this.

Let me try to implement this logic in code and see.

But perhaps there's a better way.

Looking back at the problem, perhaps I can consider the array as a system where each operation reduces a certain combination of elements, and I need to see if the initial array is a linear combination of these operation vectors.

But again, with large n, this isn't practical.

Let me consider that the operations can be represented as vectors:

For operation on i:

- v_i = [-1, -2, -1] at positions i-1, i, i+1

Then, the problem is to find non-negative integers o2, o3, ..., o_{n-1} such that sum over j of o_j * v_j = a

This is equivalent to solving the system of equations:

- o2 = a1

- 2*o2 + o3 = a2

- o2 + 2*o3 + o4 = a3

...

- o_{n-2} + 2*o_{n-1} = a_{n-1}

- o_{n-1} = a_n

With o_j >=0 for all j.

This is a system of linear equations that can be solved step by step.

Starting from o2 = a1

Then o3 = a2 - 2*o2

Then o4 = a3 - o2 - 2*o3

...

And so on, until o_{n-1} = a_n - o_{n-2}

Finally, check if all o_j >=0 and the last equation holds.

This seems feasible.

Implementing this in code should be straightforward.

So, in code:

def can_reduce_to_zero(n, a):

if n <3 or n >2*10**5:

return "NO"

# Initialize operations

o = [0] * n

o[1] = a[0]

if o[1] <0:

return "NO"

for i in range(2, n-1):

o[i] = a[i-1] - o[i-1] - 2*o[i-2]

if o[i] <0:

return "NO"

o[n-1] = a[n-1] - o[n-2]

if o[n-1] <0:

return "NO"

# Finally, check if a_n - o_{n-1} - o_n =0

if a[n-1] - o[n-1] - o[n-1] !=0:

return "NO"

return "YES"

Wait, I think I messed up the indices.

Let me correct the indices.

Assuming 1-based indexing for the array a[1..n]

In code, lists are 0-based, so a[0] is a1, a[1] is a2, etc.

So, adjust accordingly.

Implement o[2] = a[0]

Then o[3] = a[1] - 2*o[2]

Then o[4] = a[2] - o[2] - 2*o[3]

...

o[n-1] = a[n-3] - o[n-3] - 2*o[n-2]

o[n] = a[n-1] - o[n-1]

Then check if a[n-1] - o[n-1] - o[n] ==0

Wait, I'm getting confused with the indices.

Let me try to implement this carefully.

Define o[2 to n-1]

But in code, it's easier to use 0-based indexing.

Let me define o[0] corresponding to o2, o[1] to o3, etc.

So, o[0] = a[0]

if o[0] <0: NO

for i in 1 to n-3:

o[i] = a[i] - 2*o[i-1]

if o[i] <0: NO

o[n-2] = a[n-2] - o[n-3] - 2*o[n-4]

if o[n-2] <0: NO

o[n-1] = a[n-1] - o[n-2]

if o[n-1] <0: NO

Finally, check if a[n-1] - o[n-2] - o[n-1] ==0

Wait, still a bit messy.

I need to get this straight.

Let me try to implement it step by step in code and see.

But perhaps there's a better way.

Looking back at the problem, maybe I can consider that the operations correspond to a certain kind of smoothing or filtering of the array, and see if the array can be "flattened" to zero.

Alternatively, perhaps there's a matrix inversion that can be done efficiently.

But with time constraints, I need a more efficient approach.

Let me consider that the operations can be seen as applying a certain mask to the array, and see if I can find an inverse to reach zero.

But this seems too vague.

Let me try to look for patterns in the examples.

In the first example:

n=5, a=[1,3,5,5,2]

Following the operations as described, it's possible to reach zero.

In the second example:

n=5, a=[2,4,4,5,1]

It's not possible.

Looking at the differences:

First example: [1,3,5,5,2]

Differences: 2,2,0,-3

Second example: [2,4,4,5,1]

Differences: 2,0,1,-4

Not sure.

Wait, perhaps I need to look at the second differences.

For the first example:

Second differences: 1,0,-2

For the second example:

Second differences: 0,-2,1

Not sure.

Wait, perhaps the sum of second differences should be zero or something.

But in the first example, sum of second differences is 1+0+(-2)=-1, which doesn't match.

Wait, perhaps I'm missing something.

Let me recall that in discrete calculus, the second difference corresponds to the "curvature" of the array.

But I'm not sure how to apply that here.

Perhaps I need to consider that the operations can reduce certain kinds of "peaks" in the array.

Each operation reduces a peak by flattening it, but affects the neighbors as well.

But this is too vague.

Let me consider that the operations can be represented as a matrix, and see if the initial array is in the span of the operations.

But again, with large n, this isn't practical.

I need a better approach.

Let me look for a pattern in the operations.

Suppose I have an array where a[i] = c for all i.

Then, to make all a[i]=0, I need to apply operations in such a way that the total decrement equals c for each position.

But in this problem, the array elements can be different.

Wait, perhaps I need to look for a way to make all a[i] equal first, and then use operations to make them zero.

But that doesn't seem directly applicable.

Let me consider that each operation reduces the "energy" of the array by a certain amount.

The energy could be the sum of a[i], and each operation reduces it by 4.

So, the total number of operations needed is sum(a)/4.

But in the first example, sum is 16, operations needed are 4, but in reality, fewer operations might be needed depending on the array configuration.

Wait, no, in the first example, sum is 16, and operations reduce sum by 4 each time, so 4 operations are needed.

But in the second example, sum is 16, but it's not possible to reach zero.

Hence, sum being divisible by 4 is necessary but not sufficient.

I need more conditions.

Let me consider that the operations can be seen as waves propagating through the array, affecting three elements at a time.

But I'm not sure.

At this point, I think I need to accept that my initial approaches are too slow or incorrect and look for a different perspective.

Let me consider that the operations can be used to propagate changes through the array in a certain way.

Perhaps I can model this as a system where changes are propagated from one end to the other.

Alternatively, maybe I can consider the array as a graph where each element is a node, and operations affect neighboring nodes.

But this seems too abstract.

Let me consider that operations can be applied in sequence, and see if I can find a way to chain them to zero out the array.

But without a clear pattern, this is difficult.

Given time constraints, perhaps I need to accept that I haven't found the right approach yet and move on.

But I'll try one more idea.

Let me consider that the operations can be used to reduce "bumps" in the array.

Each operation reduces a bump at position i by flattening it.

So, perhaps if the array has an even distribution of bumps that can be flattened sequentially, it's possible to reach zero.

But this is too vague.

I need a more concrete approach.

Let me consider implementing the approach I thought earlier, where I compute the operations step by step and check if they are non-negative.

Even if it's not fully correct, perhaps it's a starting point.

Implement o2 = a1

o3 = a2 - 2*o2

o4 = a3 - o2 - 2*o3

...

on = an - o_{n-1}

Then, check if all oi >=0 and the final condition holds.

Let me try this with the first example.

n=5, a=[1,3,5,5,2]

o2=1

o3=3-2*1=1

o4=