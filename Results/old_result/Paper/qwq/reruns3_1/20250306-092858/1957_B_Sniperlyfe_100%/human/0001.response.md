Alright, I've got this problem to solve. Let's see what it's asking for. So, I'm given two integers, n and k, and I need to construct a sequence of n non-negative integers that sum up to k. Additionally, I need to maximize the number of 1s in the binary representation of the bitwise OR of all these numbers.

First, I need to understand what the bitwise OR of a sequence of numbers is. The bitwise OR operation takes two numbers and performs the OR operation on each pair of corresponding bits. For example, 1 OR 2 is 3 because in binary, 1 is 01 and 2 is 10, and OR'ing them gives 11, which is 3.

So, if I have a sequence of numbers, their bitwise OR is the number you get by OR'ing all of them together. And I need to maximize the number of 1s in the binary representation of this result.

I also need to ensure that the sum of these n numbers is exactly k.

Let me think about how to approach this.

One way to maximize the number of 1s in the bitwise OR is to have as many different bits set to 1 across the sequence as possible. Because OR'ing numbers will set a bit to 1 if any of the numbers has that bit set to 1.

So, if I can have each number in the sequence contribute a unique set of bits that are set to 1, that would help maximize the total number of 1s in the bitwise OR.

But I also need to make sure that the sum of these numbers is k.

Let me consider an example to get a better understanding.

Take the second example from the problem:

n = 2, k = 3

Output: 1 2

So, 1 in binary is 01, and 2 is 10. OR'ing them gives 11, which is 3, and it has two 1s in binary.

Another possible sequence could be 0 and 3, but 0 OR 3 is 3, which is the same as 1 OR 2. So, it doesn't improve the number of 1s.

Alternatively, 1 and 2 is better because both contribute different bits.

Another example:

n = 1, k = 5

Output: 5

Since there's only one number, it has to be 5, which is 101 in binary, having two 1s.

Wait, but could I do better? No, because with only one number, the bitwise OR is just that number itself.

Another example:

n = 2, k = 5

Output: 5 0

So, 5 OR 0 is 5, which is 101 in binary, having two 1s.

But is there a better way? What if I choose 3 and 2?

3 is 011, 2 is 010. OR'ing them gives 011, which is 3, having two 1s.

Not better than 101.

Wait, but 5 OR 0 also gives 101, which has two 1s.

Alternatively, choose 4 and 1: 100 OR 001 is 101, again two 1s.

Seems like in this case, two 1s is the maximum achievable.

Looking at the fourth example:

n = 6, k = 51

Output: 3 1 1 32 2 12

Let's see:

3 is 00000011

1 is 00000001

1 is 00000001

32 is 00100000

2 is 00000010

12 is 00001100

OR'ing all of them gives:

00101111, which is 47 in decimal, having five 1s in binary.

Is this the maximum? According to the problem, yes.

So, how can I generalize this approach?

I need a strategy to distribute the sum k among n numbers such that their bitwise OR has as many 1s as possible in its binary representation.

One idea is to assign numbers that cover as many unique bits as possible.

For example, assign numbers that have only one bit set to 1, as much as possible.

But wait, if I have multiple numbers with single bits set, their OR will have those bits set to 1.

However, if n is larger than the number of bits in k, I might have to set some numbers to 0.

Wait, but I need to sum to k, so I can't have too many zeros.

Let me think differently.

Suppose I have a certain number of bits that I can set to 1 in the OR result.

Each bit position can be set by at least one number in the sequence.

To maximize the number of 1s, I need to set as many bit positions to 1 as possible.

So, I need to have at least one number in the sequence that has each of these bit positions set to 1.

But I also need the sum of the numbers to be k.

So, perhaps I should identify all the bit positions in k and try to distribute them among the n numbers.

Wait, but k is the sum, not the bitwise OR.

Wait, sum is different from bitwise OR.

Sum is the arithmetic sum, while bitwise OR is a bit-wise operation.

So, I need to choose n numbers that sum to k and whose bitwise OR has as many 1s in binary as possible.

I need to maximize the number of 1s in the binary representation of the bitwise OR of the sequence.

I need to think about how the bitwise OR is affected by the choices of the numbers.

Let me consider the binary representation of the numbers.

Suppose I have numbers with certain bits set, and I OR them together, the result will have a 1 in a bit position if at least one of the numbers has a 1 in that position.

So, to maximize the number of 1s in the OR, I need to have as many bit positions as possible where at least one number has a 1 in that position.

So, I need to cover as many bit positions with the 1s from the numbers in the sequence.

But I also need the sum of the numbers to be exactly k.

So, I need to distribute the sum k among n numbers, possibly with some numbers being zero, in a way that maximizes the number of unique bit positions set to 1 across all the numbers.

This seems a bit tricky.

Let me try to think of an algorithm.

First, I need to find out how many bit positions are possible in k.

Since k can be up to 1e9, which is less than 2^30, I can consider up to 30 bits.

So, the maximum number of 1s in the binary representation of the bitwise OR is 30.

But I need to maximize the number of 1s, so ideally, I want the bitwise OR to have as many bits set to 1 as possible, up to 30.

But I have to distribute the sum k among n numbers.

One approach could be to assign the smallest possible numbers to as many numbers as possible, leaving the largest part of the sum for the remaining numbers.

Wait, but I need to maximize the number of unique bits set across all numbers.

So, perhaps I should assign numbers with single bits set, as much as possible, and adjust the sum accordingly.

Let me think about that.

Suppose I have n numbers, and I want as many of them as possible to have a unique bit set to 1.

Each number can have any combination of bits set, but to maximize the unique bits, I can assign numbers that have only one bit set, each covering a different bit position.

So, for example, assign 1, 2, 4, 8, etc., each to different numbers.

But I need to make sure that the sum of these numbers is k.

So, if I assign 1, 2, 4, 8, ..., up to n numbers, their sum would be 1 + 2 + 4 + ... + 2^{n-1} = 2^n - 1.

If k is larger than this sum, I can assign some numbers higher values.

If k is smaller, I might need to adjust.

Wait, but n can be up to 2e5, which is much larger than the 30 bits in k.

So, I need to be careful because I can't have more unique bit positions than the number of bits in k.

So, the maximum number of 1s in the bitwise OR is limited by the number of bits in k, which is up to 30.

Therefore, if n >= 30, I can assign numbers such that each covers a unique bit position up to the 30th bit, and assign the remaining numbers as 0.

But wait, k might not have all 30 bits set, so I need to consider which bits are set in k.

Wait, no, because the bitwise OR is determined by which bits are set in any of the numbers, not just in k.

Wait, but the sum is k, which is separate from the bitwise OR.

So, I need to choose n numbers that sum to k, and their bitwise OR has as many 1s in binary as possible.

So, I need to maximize the number of bit positions that have at least one number with that bit set to 1.

Given that, and considering that n can be up to 2e5, which is much larger than the 30 possible bits, I need an efficient way to assign the numbers.

Let me consider the following strategy:

1. Identify the bit positions that need to be set in the bitwise OR.

2. Assign numbers to cover as many of these bit positions as possible.

3. Distribute the remaining sum among the numbers.

But I need to maximize the number of bit positions set in the OR.

So, to maximize the number of 1s in the OR, I need to have as many unique bit positions set across the numbers as possible.

Given that, perhaps I should assign numbers with single bits set, up to the number of n, but limited by the number of bits available.

Wait, but n can be up to 2e5, which is more than the 30 bits in k.

So, in practice, I can assign up to 30 numbers to cover each bit position, and set the remaining numbers to 0.

But I need to make sure that the sum of all numbers is k.

So, here's an idea:

- Find the maximum number of unique bit positions I can set, which is up to 30.

- Assign n numbers such that the first m numbers (where m is the number of unique bit positions I want to set) have one unique bit set to 1 each, and the remaining numbers are set to 0.

- Adjust the numbers to make sure their sum is k.

But this might not be efficient, because I might not be able to set m to 30 if n is smaller than m.

Wait, n can be up to 2e5, which is much larger than 30, so I can easily cover all 30 bits if needed.

But I need to maximize the number of 1s in the OR, which is up to 30.

So, the maximum number of 1s I can have in the OR is 30, but in practice, it might be less depending on k and n.

Wait, but k can be up to 1e9, which is less than 2^30, so 30 bits should cover it.

Wait, but the bitwise OR is not limited by k's bits, because the numbers can have bits higher than those in k.

Wait, no, the numbers can be up to k, which is up to 1e9, so up to 30 bits.

Wait, no, the numbers can be up to k, which is up to 1e9, but they can be zero or positive.

Wait, the problem says non-negative integers, so they can be zero or positive.

But the sum of n numbers is k, which is at least n*0 = 0, but in the constraints, k is at least 1, so n*0 doesn't make sense if k >=1.

Wait, k >=1, n >=1.

So, I need to distribute k among n numbers, some of which can be zero.

But if k is fixed, and I have to sum to k, and I have n numbers, I need to choose how to distribute k among these n numbers to maximize the number of unique bits set in their OR.

So, perhaps I should assign each number to cover a unique bit position, up to the number of bits needed.

Wait, but I need to maximize the number of 1s in the OR, which is the number of unique bit positions set across all numbers.

So, to maximize that, I need to have as many unique bit positions set across the numbers as possible.

Given that, I should assign numbers that have only one bit set, each covering a different bit position, up to the number of bits available or n, whichever is smaller.

But n can be up to 2e5, which is much larger than the 30 bits, so in practice, I can cover all 30 bits.

But I need to make sure that the sum of these numbers is k.

So, if I assign numbers with single bits set, like 1, 2, 4, 8, etc., up to 2^29, their sum would be 2^30 -1, which is about 1e9, which matches the upper limit of k.

So, if k is large enough to cover the sum of the first m numbers, each with a unique bit set, I can do that.

But if k is smaller than the sum of the first m numbers, I need to adjust.

Wait, but the sum of the first m numbers with unique bits set is 1 + 2 + 4 + ... + 2^{m-1} = 2^m -1.

So, if k >= 2^m -1, I can assign m numbers with unique bits set.

But m can be up to 30, since k can be up to 1e9.

So, I can assign up to 30 numbers with unique bits set, and set the remaining n -30 numbers to 0.

But I need to make sure that the sum is exactly k.

So, after assigning the first m numbers with unique bits set, I can adjust the last number to make sure the sum is k.

Wait, but the sum of the first m numbers is 2^m -1, so if k > 2^m -1, I need to add the difference to one of the numbers.

But I need to choose which number to add the remaining sum to.

I should add it to the number that doesn't affect the OR result.

Since OR is determined by which bits are set in any of the numbers, adding to a number that already has a bit set won't change the OR for that bit.

So, perhaps I should add the remaining sum to the first number, which has the highest potential to cover multiple bits.

Wait, but I need to maximize the number of 1s in the OR, so I need to make sure that the bits set in the additional sum don't overlap with the bits already set in the OR.

Wait, no, because OR already has those bits set.

So, adding more bits to a number that already has some bits set won't increase the number of 1s in the OR, unless those bits were not set before.

But in practice, since the OR is the union of all set bits across all numbers, adding more bits to any number won't increase the OR beyond the union of all set bits.

So, perhaps the best way is to assign numbers with unique bits set, up to the number of bits available in k, and set the remaining numbers to 0, then adjust the last number to make sure the sum is k.

Wait, but k might have some bits set that are already covered by the unique bits assigned to the first m numbers.

Wait, no, I need to maximize the number of unique bits set in the OR, not necessarily the bits set in k.

Wait, but the OR is determined by the bits set in any of the numbers, regardless of k.

So, I need to maximize the number of unique bits set across all numbers, while ensuring their sum is k.

So, perhaps I should assign numbers with unique bits set, up to the number of bits I can afford with the sum k.

Wait, but k can be up to 1e9, which is more than enough to cover 30 unique bits.

Because the sum of the first 30 unique bits is 2^30 -1, which is about 1e9.

So, in practice, for k >= 2^m -1, where m is the number of unique bits I want to set, I can assign m numbers with unique bits set and set the remaining n -m numbers to 0.

Then, if k > 2^m -1, I can assign the difference to one of the numbers, preferably one that doesn't affect the OR result.

But in reality, since the OR is already set by the m unique bits, adding more to any number won't change the OR, as long as the additional bits are already covered by the OR.

So, perhaps I can assign the first m numbers with unique bits set, and assign the remaining sum to the last number.

But I need to make sure that the OR is maximized, which is achieved by having as many unique bits set as possible.

So, in practice, assigning m numbers with unique bits set, where m is up to 30, and setting the remaining n -m numbers to 0, should be sufficient.

Then, adjust the last number to make sure the sum is k.

Wait, but in the example given, for n=6 and k=51, the output is 3 1 1 32 2 12.

Let's see:

3 is 00000011

1 is 00000001

1 is 00000001

32 is 00100000

2 is 00000010

12 is 00001100

OR'ing them gives 00101111, which is 47, having five 1s.

But according to my earlier strategy, if I assign six numbers with unique bits set, starting from 1, 2, 4, 8, 16, 32, their sum would be 1+2+4+8+16+32=63, which is more than 51.

But in the example, they chose 3,1,1,32,2,12, which sum to 51.

So, in this case, they have overlapping bits in some numbers.

Wait, 3 is 00000011, which is bits 0 and 1.

1 is 00000001 (bit 0)

1 is 00000001 (bit 0)

32 is 00100000 (bit 5)

2 is 00000010 (bit 1)

12 is 00001100 (bits 2 and 3)

OR'ing them gives 00101111, which is bits 0,1,2,3,5 set.

So, they have five unique bits set.

But if I follow my earlier strategy, assigning unique bits to each of the six numbers, I could have assigned 1,2,4,8,16,32, which would cover bits 0,1,2,3,4,5, which is six unique bits.

But in the example, they have only five unique bits set.

Wait, but in the example, they have bits 0,1,2,3,5 set, which is five bits.

But according to my strategy, I could have six bits set.

But perhaps their sum would exceed k=51.

Because 1+2+4+8+16+32=63, which is larger than 51.

So, in that case, I need to adjust.

So, perhaps I need to assign as many unique bits as possible without exceeding the sum k.

So, in this case, with k=51 and n=6, I need to assign numbers with unique bits set, summing up to at most 51, and then assign the remaining sum to one of the numbers.

But in the example, they have bits 0,1,2,3,5 set, which correspond to numbers 1,2,4,8,32.

But their sum is 1+2+4+8+32=47, which is less than 51.

Then, they assign the remaining 4 to one of the numbers, but in their output, they have 3,1,1,32,2,12.

Wait, 3 is 3 instead of 1, which covers bits 0 and 1.

So, perhaps they are overlapping some bits to reduce the sum.

Wait, but I'm getting confused.

Let me try to think differently.

Maybe I should start by finding the maximum number of unique bits I can set with the sum k.

So, I need to select a subset of bit positions (up to 30) such that the sum of the values corresponding to these bits is <=k.

Then, assign one number to each selected bit, setting that bit to 1.

Then, assign the remaining sum to one of the numbers.

This way, the OR will have those selected bits set to 1.

So, to maximize the number of unique bits set, I need to select as many bit positions as possible such that the sum of their corresponding values is <=k.

This sounds like a greedy approach.

So, I can select the smallest possible values first.

For example, start with bit 0 (value 1), bit 1 (value 2), bit 2 (value 4), and so on, adding them up until the sum reaches or exceeds k.

Then, assign n numbers such that the first m numbers correspond to these m bits, and set the remaining n -m numbers to 0.

If the sum of these m numbers is less than k, assign the difference to one of the numbers, preferably one that doesn't affect the OR result.

Wait, but assigning the difference to a number that already has some bits set might not increase the OR.

So, perhaps I should assign the difference to a new number that doesn't have any bits overlapping with the existing ones, if possible.

But in practice, if I have assigned m unique bits, and I need to add the remaining sum to one of the numbers, it won't affect the OR, because the OR already has those bits set.

So, in that case, it's fine.

Wait, but in the earlier example, with n=6 and k=51, assigning bits 0 to 5 would correspond to numbers 1,2,4,8,16,32, summing to 63, which is more than 51.

So, in that case, I need to select a subset of bits whose sum is <=51.

So, perhaps I need to select as many bits as possible starting from the smallest ones, until the sum exceeds 51.

So, 1+2+4+8+16=31, which is less than 51.

Adding 32 would make 63, which is more than 51.

So, I can select bits 0 to 4, summing to 31, and then assign the remaining 20 to one of the numbers.

But which number?

If I assign the remaining 20 to one of the existing numbers, say to the number with bit 4 (16), making it 36 (16 +20), but 36 is 00100100, which has bits 2 and 5 set.

Wait, 36 in binary is 100100, which is bits 2 and 5 set.

So, now the OR would have bits 0,1,2,3,4,5 set, which is six bits.

But in the example, they have only five bits set.

So, perhaps their approach is different.

Wait, perhaps I need to select the highest possible bits to maximize the number of unique bits set, without exceeding k.

Wait, but selecting higher bits might cover more bits, but I need to maximize the number of unique bits set.

So, selecting smaller bits is better because they cover more unique bits.

Wait, no, each bit is unique.

Wait, but lower bits are smaller in value, so I can fit more of them within k.

But each bit is unique in its position.

So, perhaps I should select as many bits as possible from the lowest to the highest, until the sum exceeds k.

Then, assign the remaining sum to one of the numbers.

Wait, but in the earlier example, selecting bits 0 to 4 sums to 31, and then assigning the remaining 20 to one of the numbers, say the last one, making it 20.

20 in binary is 10100, which has bits 2 and 4 set.

But bit 4 is already set in another number, so the OR won't have an additional bit set.

Wait, but bit 2 was not set before, so it will be set in the OR.

Wait, no, bit 4 is already set, but bit 2 is new.

So, the OR would have bits 0,1,2,3,4 set.

But in the example, they have bits 0,1,2,3,5 set.

So, perhaps their approach is different.

Wait, perhaps I should select the bits in such a way that the sum is <=k, and maximize the number of unique bits set.

So, it's like selecting as many unique bits as possible without exceeding k.

This sounds like a knapsack problem, where I want to maximize the number of unique bits selected, with the sum of their values <=k.

But since n can be up to 2e5, and t can be up to 1e4, I need an efficient solution.

So, perhaps I can precompute the maximum number of unique bits I can set for a given k.

Wait, but k can be up to 1e9, which is manageable.

So, here's an idea:

- Find the maximum number of unique bits I can set with sum <=k.

- Assign n numbers, with the first m numbers corresponding to these m unique bits, and set the remaining n -m numbers to 0.

- Then, assign the remaining sum (if any) to one of the numbers, preferably one that doesn't affect the OR.

Wait, but in practice, assigning the remaining sum to one of the numbers might affect the OR.

So, I need to make sure that the additional sum doesn't introduce new bits that are already set in the OR.

Wait, no, because OR is the union of all set bits.

So, adding more bits to a number that already has some bits set won't change the OR for those bits.

So, it's safe to add the remaining sum to one of the numbers.

So, in code, I can:

- Select the first m bits (starting from bit 0) such that their sum <=k.

- Assign the first m numbers to correspond to these m bits.

- Assign the remaining n -m numbers to 0.

- Assign the remaining sum (k -sum of the first m bits) to one of the m numbers.

But in the earlier example, with n=6, k=51:

- Select bits 0 to 4: 1+2+4+8+16=31 <=51

- Assign the remaining 20 to one of the first 5 numbers, say add 20 to the last one.

- So, the numbers would be 1,2,4,8,36,0

- 36 is 100100, which is bits 2 and 5 set.

- OR of all numbers: bits 0,1,2,3,4,5 set, which is six bits.

But in the example, they have only five bits set.

So, perhaps their approach is different.

Wait, maybe I need to select the minimal possible sum for the first m bits to maximize the remaining sum to distribute.

Wait, I'm getting confused.

Let me look at the provided program to understand their approach.

Given program:

t = int(input())

results = []

for _ in range(t):

(n, k) = map(int, input().split())

result = func_1(n, k)

results.append(' '.join(map(str, result)))

print('\n'.join(results))

def func_1(n, k):

nums = [0] * n

nums[0] = (1 << k.bit_length() -1) -1

k -= nums[0]

for i in range(1, n):

if k > 0:

nums[i] = min(nums[0] +1, k)

k -= nums[i]

nums[0] += k

return nums

So, in func_1:

- Initialize nums as a list of n zeros.

- Set nums[0] to (1 << k.bit_length() -1) -1

- Subtract nums[0] from k.

- For i from 1 to n-1:

- If k > 0, set nums[i] to min(nums[0] +1, k)

- Subtract nums[i] from k.

- Finally, add the remaining k to nums[0].

So, what does this do?

First, it sets nums[0] to (1 << b -1) -1, where b is the bit length of k.

Wait, k.bit_length() gives the number of bits needed to represent k in binary, excluding leading zeros.

So, for k=5, which is 101 in binary, k.bit_length() is 3.

So, (1 << (3 -1)) -1 = (1 << 2) -1 = 4 -1 =3.

So, nums[0] =3

Then, k -=3, so k=2

Then, for i from 1 to n-1:

If k >0, set nums[i] to min(nums[0]+1, k)

So, nums[0]+1 =4

k=2, so nums[1]=min(4,2)=2

k -=2, so k=0

Then, no more k left, so nums[0] +=0, remains 3.

So, the sequence is 3,2

But according to the problem's second example, for n=2, k=3, the output is 1,2.

But according to this function, it would set nums[0]=1<< (3.bit_length()-1)-1 =1<<(1)-1=1<<0=1-1=0

Wait, no, 3.bit_length() is 2, because 3 is 11 in binary.

So, (1 << (2 -1)) -1 =1 <<1 -1=2-1=1

So, nums[0]=1

k -=1, k=2

Then, for i=1:

k>0, nums[1]=min(1+1,2)=2

k -=2, k=0

Then, nums[0] +=0, remains 1

So, sequence is 1,2, which matches the example.

Another example:

n=2, k=5

According to the function:

k.bit_length()=3 for k=5

nums[0]=(1<<(3-1))-1=1<<2 -1=4-1=3

k -=3, k=2

nums[1]=min(3+1,2)=2

k -=2, k=0

nums[0] +=0

So, sequence is 3,2

But in the problem's example, it's 5,0

Which also sums to 5.

But the OR of 3 and 2 is 3|2=3 (11 | 10)=11=3, which has two 1s.

OR of 5 and 0 is 5|0=5 (101 | 000)=101=5, which also has two 1s.

So, both are valid, as the problem says any sequence that satisfies the conditions.

So, in this case, the function's output is acceptable.

Another example:

n=6, k=51

k.bit_length()=6 for k=51 (110011)

nums[0]=(1<<(6-1))-1=1<<5 -1=32-1=31

k -=31, k=20

Then, for i=1 to 5:

nums[1]=min(31+1,20)=20

k -=20, k=0

Then, nums[0] +=0

So, sequence is 31,20,0,0,0,0

OR of these is 31|20|0|0|0|0=31|20=31=11111|20=10100=31|20=31|20=31 in binary is 11111, 20 is 10100, OR'ed is 11111 | 10100 = 11111, which is 31, having five 1s.

But in the problem's example, they have 3,1,1,32,2,12, which OR to 47 (101111), which has five 1s.

So, both sequences have the same number of 1s in the OR, which is acceptable.

So, the function's output is correct in these cases.

But is it always optimal?

Wait, in the first example, n=1, k=5, output is 5.

OR is 5, which is 101, having two 1s.

Is there a better sequence? No, since n=1.

In the second example, n=2, k=3, output is 1,2 with OR=3 (11), having two 1s.

Is there a better sequence? No, because the maximum number of 1s in OR is two.

In the third example, n=2, k=5, output can be 5,0 or 3,2, both with OR having two 1s.

Again, two 1s is the maximum.

In the fourth example, n=6, k=51, output has OR with five 1s.

Is that the maximum? Yes, according to the problem.

So, the function seems to be producing correct sequences.

But is it always optimal?

Let me try to think of a case where it might not be optimal.

Suppose n=3, k=7

According to the function:

k.bit_length()=3 for k=7 (111)

nums[0]=(1<<(3-1))-1=1