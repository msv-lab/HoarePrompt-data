Alright, I've got this problem to solve. Let's see what it's asking for. So, Rudolf has an array of integers, and he can perform a specific operation on it any number of times. The operation involves choosing an index i (where 2 ≤ i ≤ n-1) and modifying the elements at positions i-1, i, and i+1 by subtracting 1, 2, and 1 respectively. The goal is to determine whether it's possible to make all elements of the array zero by applying this operation any number of times.

First, I need to understand the operation clearly. When Rudolf chooses an index i, he's effectively reducing the values of a[i-1], a[i], and a[i+1] by 1, 2, and 1 respectively. This seems like a way to distribute negative effects across adjacent elements, with the middle element receiving a larger deduction.

I need to think about what sequences of these operations could lead to all elements becoming zero. It feels like this might be related to solving a system of equations, where each operation corresponds to subtracting a specific combination from the array elements.

Let's consider the constraints:

- The array has at least 3 elements (since n ≥ 3).

- The operations can only be performed on indices from 2 to n-1.

- Each operation affects three consecutive elements.

- The values in the array are non-negative integers (0 ≤ a[j] ≤ 10^9).

Given that, I need to find a sequence of operations that can zero out the entire array.

I should think about the implications of performing these operations multiple times. Each operation reduces the sum of the array by 4 (1 + 2 + 1). So, the total sum of the array must be divisible by 4 for it to be possible to zero out the array. Wait, but that's not necessarily true because operations can overlap and affect the same elements multiple times.

Let me consider a smaller example to get a better understanding.

Take n=3, array [1, 2, 1].

If I perform the operation on i=2:

- a[1] = 1 - 1 = 0

- a[2] = 2 - 2 = 0

- a[3] = 1 - 1 = 0

So, in one operation, the array becomes [0, 0, 0]. That's straightforward.

Another example: n=4, array [1, 3, 3, 1].

Perform operation on i=2:

- a[1] = 1 - 1 = 0

- a[2] = 3 - 2 = 1

- a[3] = 3 - 1 = 2

- a[4] = 1

Now the array is [0, 1, 2, 1].

Perform operation on i=3:

- a[2] = 1 - 1 = 0

- a[3] = 2 - 2 = 0

- a[4] = 1 - 1 = 0

So, after two operations, the array becomes [0, 0, 0, 0]. Seems possible.

But what if the array is [1, 2, 1, 1]?

Perform operation on i=2:

- a[1] = 1 - 1 = 0

- a[2] = 2 - 2 = 0

- a[3] = 1 - 1 = 0

- a[4] = 1

Now the array is [0, 0, 0, 1]. There's no way to affect a[4] since operations can only be performed on i=2 and i=3, and neither of those operations affects a[4] directly. So, it's impossible to zero out the array in this case.

From this, I can see that the operations have a specific propagation pattern through the array.

I need to find a systematic way to determine if it's possible to zero out the entire array.

Let me think about this in terms of linear algebra. Each operation can be represented as subtracting a specific vector from the array vector. For example, for n=5, an operation on i=2 would correspond to subtracting [0,1,2,1,0] from the array.

So, the problem reduces to whether we can express the initial array as a linear combination of these operation vectors.

In linear algebra terms, this is equivalent to solving a system of linear equations where the vectors correspond to the columns of the matrix.

Given that, I need to check if the initial array vector is in the span of these operation vectors.

However, given the constraints on time and computational resources, I need a more efficient way to determine this.

Let's consider the differences between consecutive elements.

Suppose I look at the differences between a[i+1] and a[i] for all i from 1 to n-1.

Let me denote d[i] = a[i+1] - a[i].

I need to see how these differences change with each operation.

Performing an operation on i subtracts 1 from a[i-1], 2 from a[i], and 1 from a[i+1].

So, the differences are:

- d[i-1] becomes (a[i] - 1) - (a[i-1] - 1) = d[i-1]

- d[i] becomes (a[i+1] - 1) - (a[i] - 2) = d[i] + 1

Wait, let's compute d[i] after the operation:

Original d[i] = a[i+1] - a[i]

After operation on i:

d[i] = (a[i+1] - 1) - (a[i] - 2) = a[i+1] - 1 - a[i] + 2 = (a[i+1] - a[i]) + 1 = d[i] + 1

Similarly, d[i-1] remains the same.

So, each operation increases d[i-1] by 0 and increases d[i] by 1.

This seems like a way to adjust the differences.

If I can adjust the differences such that all d[i] become zero, then the array would be uniform, and since we aim for zero, all elements would be zero.

Wait, but in our operations, we can only increase d[i] by 1 at a time through operations on i+1.

This seems a bit messy. Maybe there's a better way.

Let me consider the prefix sums.

Let me define s[i] = a[1] + a[2] + ... + a[i]

Then, the operation on i affects s[i-1], s[i], and s[i+1]:

- s[i-1] -=1

- s[i] -=2 (since s[i] = s[i-1] + a[i], and a[i] -=2)

- s[i+1] -=3 (since s[i+1] = s[i] + a[i+1], and a[i+1] -=1)

Wait, that seems complicated.

Maybe I need to look at the array in a different way.

Let me consider the array as a sequence and see if there's a pattern in the operations that can zero it out.

Looking back at the first example:

n=5, a=[1,3,5,5,2]

Operations:

1. Operation on i=4: a[3] -=1, a[4] -=2, a[5] -=1 → [1,3,4,3,1]

2. Operation on i=3: [1,2,2,2,1]

3. Operation on i=2: [0,0,1,2,1]

4. Operation on i=4: [0,0,0,0,0]

So, it's possible.

In the second example:

n=5, a=[2,4,4,5,1]

After operations, it's not possible to zero it out.

Looking for a pattern or invariant that can help determine the possibility.

Perhaps, the sum of the array must be a multiple of 4, but from the earlier example, n=3, a=[1,2,1], sum=4, which is a multiple of 4, and it can be zeroed out.

But in n=4, a=[1,2,1,1], sum=5, which is not a multiple of 4, and it cannot be zeroed out.

But in the first example, sum=16, which is a multiple of 4, and it can be zeroed out.

But earlier I thought about sum needing to be a multiple of 4, but in the second example, n=5, a=[1,3,5,5,2], sum=16, which is a multiple of 4, and it can be zeroed out.

Wait, but n=4, a=[1,2,1,1], sum=5, which is not a multiple of 4, and it cannot be zeroed out.

So, sum being a multiple of 4 is a necessary condition, but is it sufficient?

From the earlier example, n=4, a=[1,2,1,1], sum=5, cannot be zeroed out.

Another example: n=3, a=[0,0,0], sum=0, which is a multiple of 4, and it's already zeroed out.

Another example: n=3, a=[2,4,2], sum=8, which is a multiple of 4.

Perform operation on i=2: [1,2,1]

Operation on i=2 again: [0,0,0]

So, it can be zeroed out.

Another example: n=4, a=[1,3,3,1], sum=8, which is a multiple of 4, and as per earlier, it can be zeroed out in two operations.

Another example: n=4, a=[2,2,2,2], sum=8.

Perform operation on i=2: [1,0,1,2]

Then operation on i=3: [1,0,0,0]

But a[1]=1 ≠0, so it cannot be zeroed out even though the sum is a multiple of 4.

Wait, but in this case, sum=8, multiple of 4, but it cannot be zeroed out.

So, sum being a multiple of 4 is necessary but not sufficient.

Hence, there must be another condition.

I need to find a better invariant or property that can help determine whether the array can be zeroed out.

Let me consider the differences again.

Looking at the differences d[i] = a[i+1] - a[i].

See how these differences behave with operations.

As previously, operation on i affects d[i-1] and d[i].

Specifically, d[i-1] remains the same, and d[i] increases by 1.

So, if I can adjust d[i] by performing operations, I need to make all d[i] = 0.

Starting from some initial differences, I can increment d[i] by performing operations on i+1.

So, I need to make all d[i] equal to some value, but since I'm aiming for all a[i] = 0, the differences should be zero.

Wait, if all a[i] = 0, then d[i] = 0 for all i.

So, I need to adjust the differences to zero.

But I can only increase d[i] by 1 at a time by performing operations on i+1.

So, if initial d[i] is negative, I may not be able to make it zero by adding 1 each time.

Wait, d[i] can be negative, zero, or positive.

If d[i] is negative, I need to perform operations to make it zero.

But each operation increases d[i] by 1.

So, for each d[i], the number of operations needed is -d[i], if d[i] is negative.

If d[i] is non-negative, I don't need to perform any operations on it.

But since operations on i affect d[i-1] and d[i], I need to find a way to satisfy all differences simultaneously.

This seems complicated.

Maybe there's another approach.

Let me consider the array as a system of equations.

Each operation corresponds to subtracting a specific vector from the array.

For example, for n=5, operation on i=2 subtracts [0,1,2,1,0], operation on i=3 subtracts [0,0,1,2,1], and so on.

So, the span of these operation vectors determines whether we can reach the zero vector from the initial array.

In linear algebra terms, I need to check if the initial array is in the span of these operation vectors.

But with large n (up to 2e5), I need an efficient way to do this.

Perhaps, I can look for a pattern in the operations or find a way to reduce the problem.

Let me consider the cumulative sum of the array.

Define s[i] = a[1] + a[2] + ... + a[i]

Then, the operation on i affects s[i-1], s[i], and s[i+1].

Specifically:

- s[i-1] -=1

- s[i] -=2

- s[i+1] -=1

Wait, s[i] = s[i-1] + a[i]

After operation on i:

s[i-1] -=1

s[i] = s[i-1] + a[i] -2

s[i+1] = s[i] + a[i+1] -1

This seems messy.

Maybe I need to consider the second differences or something similar.

Alternatively, perhaps I can model this as a system where each operation has a specific effect, and I need to solve for the number of operations on each i.

But with n up to 2e5, I need a linear or nearly linear time solution.

Let me think differently.

Suppose I try to zero out the array step by step, starting from the left or the right.

If I start from the left, I can try to make a[1] = 0 by performing operations on i=2.

Each operation on i=2 reduces a[1] by 1, a[2] by 2, and a[3] by 1.

So, to make a[1] = 0, I need to perform operations on i=2 exactly a[1] times.

But each time I do that, I reduce a[2] by 2 and a[3] by 1.

After making a[1] = 0, I can move to a[2], and so on.

Wait, but a[2] is also being modified by operations on i=3, etc.

This seems too entangled.

Let me try to formalize this.

Suppose I perform operations on indices i from 2 to n-1, each operation subtracting [0,1,2,1,0,...] from the array.

I need to find a combination of these operations that results in the entire array being zero.

This sounds like solving a system of linear equations.

But with large n, I need a smarter way.

Let me consider the array as a sequence and see if there's a way to propagate the operations.

Looking back at the first example:

n=5, a=[1,3,5,5,2]

Operations:

1. Operation on i=4: a[3] -=1, a[4] -=2, a[5] -=1 → [1,3,4,3,1]

2. Operation on i=3: [1,2,2,2,1]

3. Operation on i=2: [0,0,1,2,1]

4. Operation on i=4: [0,0,0,0,0]

So, it's possible.

I need to find a sequence of operations that achieves this.

But how to generalize this process?

Let me consider that each operation reduces a[i-1], a[i], a[i+1] by 1,2,1 respectively.

I can think of this as convolving the array with [-1,-2,-1] at position i.

Wait, that might be too advanced for this context.

Alternatively, perhaps I can model this as a system where each operation has a specific impact, and I need to find coefficients for each operation to achieve the desired result.

But again, with large n, I need a more efficient approach.

Let me consider the problem in terms of invariants.

Is there some property of the array that remains unchanged no matter how many operations I perform?

If I can find such an invariant, I can use it to determine whether zeroing out the array is possible.

For example, in some problems, the sum of the array modulo some number remains constant.

But in this case, each operation reduces the sum of the array by 4.

So, the sum of the array modulo 4 is an invariant.

Wait, no. Since each operation reduces the sum by 4, the sum modulo 4 decreases by 4 each time, but that doesn't help directly.

Actually, the sum decreases by 4 with each operation, so if I perform k operations, the sum decreases by 4k.

Therefore, the final sum would be sum(a) - 4k.

To reach zero, sum(a) - 4k = 0, so sum(a) must be divisible by 4.

But earlier, I saw that even if sum(a) is divisible by 4, it's not guaranteed that the array can be zeroed out.

So, sum being divisible by 4 is necessary but not sufficient.

I need another condition.

Let me consider the prefix sums again.

Define s[i] = a[1] + a[2] + ... + a[i]

Looking at how operations affect s[i]:

- Operation on i subtracts 1 from s[i-1], 2 from s[i], and 1 from s[i+1].

Wait, s[i] = s[i-1] + a[i]

After operation on i:

s[i-1] -=1

s[i] = s[i-1] + a[i] -2

s[i+1] = s[i] + a[i+1] -1

This seems too involved.

Maybe I need to look for another approach.

Let me consider the array as a system where each operation affects three consecutive elements.

This resembles a tridiagonal system in linear algebra.

In such systems, equations involve only consecutive variables.

Maybe I can model this as a recurrence relation.

Let me think recursively.

Suppose I have the array a[1], a[2], ..., a[n]

I need to make a[1] = 0, a[2] = 0, ..., a[n] = 0 using the allowed operations.

If I focus on a[1], the only way to reduce a[1] is by performing operations on i=2, which subtracts 1 from a[1].

So, to make a[1] = 0, I need to perform operations on i=2 exactly a[1] times.

But each operation on i=2 subtracts 2 from a[2] and 1 from a[3].

So, after making a[1] = 0, a[2] is reduced by 2*a[1], and a[3] is reduced by a[1].

Then, I can move to a[2], and to make it zero, I need to perform operations on i=3, subtracting 1 from a[2], 2 from a[3], and 1 from a[4].

But operations on i=3 affect a[2], a[3], and a[4].

This seems like a chain reaction where making one element zero affects the next elements.

This suggests a sweep from left to right, making each a[i] zero in sequence.

Let me try formalizing this.

Initialize the array a.

While there exists some a[i] > 0:

- Find the leftmost a[i] > 0.

- If i < n-1, perform operations on i+1 to reduce a[i] by 1, a[i+1] by 2, and a[i+2] by 1.

- Repeat until a[i] == 0.

- Move to the next i.

But this seems too vague.

Let me try to implement this idea step by step.

Start from i=1.

If a[1] > 0, perform operations on i=2 until a[1] == 0.

Each operation on i=2 reduces a[1] by 1, a[2] by 2, and a[3] by 1.

So, after making a[1] == 0, a[2] is reduced by 2*a[1], and a[3] is reduced by a[1].

Then, move to i=2.

If a[2] > 0, perform operations on i=3 until a[2] == 0.

Each operation on i=3 reduces a[2] by 1, a[3] by 2, and a[4] by 1.

And so on.

This seems like a way to sequentially make each a[i] zero, starting from the left.

But I need to ensure that when I move to the next i, the previous a[j] for j < i remain zero.

Given that each operation on i >= j+1 doesn't affect a[j], this should hold.

Wait, operations on i affect a[i-1], a[i], a[i+1].

So, operations on i >= j+2 won't affect a[j].

Hence, once a[j] is zero, it remains zero as we perform operations on higher i.

This seems promising.

Let me try this on the first example.

n=5, a=[1,3,5,5,2]

Step 1: Make a[1]=0 by performing operations on i=2.

Need to perform a[1]=1 operation on i=2.

After operation:

a[1]=0, a[2]=3-2=1, a[3]=5-1=4, a[4]=5, a[5]=2

Now, a=[0,1,4,5,2]

Step 2: Make a[2]=0 by performing operations on i=3.

Need to perform a[2]=1 operation on i=3.

After operation:

a[2]=0, a[3]=4-2=2, a[4]=5-1=4, a[5]=2

Now, a=[0,0,2,4,2]

Step 3: Make a[3]=0 by performing operations on i=4.

Need to perform a[3]=2 operations on i=4.

After first operation:

a[3]=1, a[4]=4-2=2, a[5]=2-1=1

After second operation:

a[3]=0, a[4]=0, a[5]=0

Now, a=[0,0,0,0,0]

Success.

This matches the earlier manual operations.

Let's try this on another example.

n=4, a=[1,2,1,1]

Step 1: Make a[1]=0 by performing 1 operation on i=2.

a[1]=0, a[2]=2-2=0, a[3]=1-1=0, a[4]=1

Now, a=[0,0,0,1]

Step 2: Make a[2]=0 (already 0), move to a[3]=0 (already 0), but a[4]=1 remains.

Since there's no operation that can affect a[4] directly, it's impossible to make a[4]=0.

Hence, output "NO".

Good, matches earlier observation.

Another example: n=3, a=[0,0,0]

Already zero, output "YES".

Another example: n=3, a=[2,4,2]

Step 1: Make a[1]=0 by performing 2 operations on i=2.

First operation:

a[1]=0, a[2]=4-2=2, a[3]=2-1=1

Second operation:

a[1]=0, a[2]=2-2=0, a[3]=1-1=0

Now, a=[0,0,0]

Success.

Another example: n=4, a=[1,3,3,1]

Step 1: Make a[1]=0 by performing 1 operation on i=2.

a[1]=0, a[2]=3-2=1, a[3]=3-1=2, a[4]=1

Now, a=[0,1,2,1]

Step 2: Make a[2]=0 by performing 1 operation on i=3.

a[2]=0, a[3]=2-2=0, a[4]=1-1=0

Now, a=[0,0,0,0]

Success.

Another example: n=4, a=[2,2,2,2]

Step 1: Make a[1]=0 by performing 2 operations on i=2.

First operation:

a[1]=0, a[2]=2-2=0, a[3]=2-1=1, a[4]=2

Second operation:

a[1]=0, a[2]=0-2=-2, a[3]=1-1=0, a[4]=2

Now, a=[0, -2, 0, 2]

Wait, now a[2] is negative, which is invalid because the problem likely assumes non-negative integers, but according to the problem statement, a[j] can be up to 1e9, including 0.

But in this step, a[2] becomes -2, which is invalid because you can't perform operations that result in negative values in the array, as operations can't be undone.

Hence, this approach might lead to negative values in the array, which aren't allowed.

Wait, but according to the problem, "Any index i can be used zero or more times." It doesn't specify that the array can't have negative values during intermediate steps.

But in reality, if a[2] becomes negative, it means we've over-subtracted, which isn't allowed because the operations are defined to subtract positive values.

Hence, in this case, it's impossible to zero out the array.

Indeed, in this example, it's not possible to zero out the array, as seen in the earlier manual attempt.

Hence, the approach needs to ensure that no element becomes negative during the process.

Therefore, when deciding how many operations to perform on a particular i, we need to make sure that we don't make any element negative.

In the previous example, performing 2 operations on i=2 to make a[1]=0 results in a[2] becoming -2, which is invalid.

Hence, in such cases, it's impossible to zero out the array.

So, the approach should include checking that no element becomes negative at any step.

Hence, in the algorithm, after making a[j]=0 for j from 1 to n-2, we need to ensure that a[j+1] and a[j+2] don't go negative.

Wait, in the earlier step, when making a[1]=0 by performing a[1] operations on i=2, we need to ensure that a[2] >= 2*a[1] and a[3] >= a[1].

In the failed example, a[2]=2 < 2*a[1]=4, so it's impossible.

Wait, a[1]=2, so performing 2 operations on i=2 requires a[2] >= 4 and a[3] >= 2.

But in the array [2,2,2,2], a[2]=2 < 4, so it's impossible.

Hence, the condition is that a[2] >= 2*a[1] and a[3] >= a[1].

Similarly, when making a[2]=0, we need to perform operations on i=3.

After making a[1]=0, suppose a[2] = a[2] - 2*a[1], a[3] = a[3] - a[1].

Then, to make a[2]=0, we need a[2] - 2*a[1] >=0, and after that, perform operations on i=3.

Similarly, for a[3], after making a[2]=0, we need to make sure that a[3] - 2*(operations on i=3) >=0, and so on.

This seems too involved.

Is there a better way to check these conditions without actually performing the operations?

Let me consider the following:

For the array to be zeroed out, it must satisfy certain conditions based on the operations allowed.

From the earlier analysis, sum(a) must be divisible by 4.

But as seen, it's not sufficient.

Additionally, there must be certain inequalities satisfied between consecutive elements.

Let me consider the following:

Define a new array b where b[i] = a[i] + a[i+1] + a[i+2] for i from 1 to n-2.

Wait, not sure if that helps.

Alternatively, perhaps look at a[i] in relation to a[i+1] and a[i+2].

From the earlier step, to make a[1]=0, we need a[2] >= 2*a[1] and a[3] >= a[1].

Similarly, after making a[1]=0, to make a[2]=0, we need a[3] >= 2*(a[2] - 2*a[1]) and a[4] >= (a[2] - 2*a[1]).

This is getting too complicated.

Let me look for a different invariant.

Suppose I consider the array as a system where each operation corresponds to subtracting a specific vector.

Each operation on i subtracts [0,...,0,1,2,1,0,...,0] from a, where 1,2,1 are at positions i-1, i, i+1.

I need to see if the initial array a can be expressed as a linear combination of these operation vectors.

In linear algebra terms, this is equivalent to checking if a is in the span of these vectors.

Given that, I can set up a system of equations and solve for the coefficients.

But with n up to 2e5, this is not feasible.

I need a smarter way.

Let me consider the problem in terms of error correction.

Each operation corrects the values at positions i-1, i, i+1 by subtracting 1,2,1 respectively.

I need to see if I can correct the entire array to zero.

Wait, maybe I can model this as a system where errors propagate, and operations can cancel out errors.

But I'm not sure.

Another idea: since each operation affects three consecutive elements, perhaps I can model this as a system of differences, similar to finite differences.

Wait, perhaps I can consider the second difference of the array.

In numerical analysis, the second difference is δ²a[i] = a[i+1] - 2*a[i] + a[i-1].

But I'm not sure if that helps here.

Wait, let's see.

If I perform an operation on i, it subtracts 1 from a[i-1], 2 from a[i], and 1 from a[i+1].

So, the second difference at position i would be:

δ²a[i] = (a[i+1] -1) - 2*(a[i] -2) + (a[i-1] -1)

= a[i+1] -1 -2*a[i] +4 +a[i-1] -1

= (a[i+1] - 2*a[i] + a[i-1]) +2

= δ²a[i] +2

Wait, so each operation on i increases the second difference at position i by 2.

Not sure if that helps.

But perhaps I can consider the second differences of the array and see if they can be adjusted to some specific values.

This seems too convoluted.

Let me try to think differently.

Suppose I fix the number of operations on each index i, say o[i] operations on i.

Then, the effect on the array is:

For each i from 2 to n-1:

a[i-1] -= o[i]

a[i] -= 2*o[i]

a[i+1] -= o[i]

This can be represented as:

For i from 1 to n:

a[i] -= sum of o[j] for j such that a[j] affects a[i]

Specifically:

- a[1] -= o[2]

- a[2] -= 2*o[2] + o[3]

- a[3] -= o[2] + 2*o[3] + o[4]

- ...

- a[n-1] -= o[n-2] + 2*o[n-1]

- a[n] -= o[n-1]

To make a[i] = 0 for all i, we need:

For each i:

a[i] - (sum of o[j] affecting a[i]) = 0

Which gives us a system of equations to solve for o[j].

This is a system of linear equations, but again, with large n, I need a smarter way.

Let me consider writing this in matrix form.

Let me define o = [o[2], o[3], ..., o[n-1]]

Then, for each a[i], the equation is:

a[1] - o[2] = 0 => o[2] = a[1]

a[2] - 2*o[2] - o[3] = 0

a[3] - o[2] - 2*o[3] - o[4] = 0

...

a[n-1] - o[n-2] - 2*o[n-1] = 0

a[n] - o[n-1] = 0 => o[n-1] = a[n]

So, o[n-1] = a[n]

Then, from the equation for a[n-1]:

a[n-1] - o[n