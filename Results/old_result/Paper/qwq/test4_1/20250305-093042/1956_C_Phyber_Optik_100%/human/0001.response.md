Alright, I have this problem to solve. Let's see what it's about. So, there's this magical girl named Nene who has an n by n matrix filled with zeros. She can perform two types of operations on this matrix:

1. Type 1: Choose a row i and a permutation p of numbers from 1 to n, and set the elements of that row to the permutation p.

2. Type 2: Choose a column j and a permutation p of numbers from 1 to n, and set the elements of that column to the permutation p.

The goal is to maximize the sum of all the elements in the matrix after performing some operations, and she wants to do this with no more than 2n operations.

First, I need to understand what these operations do. For Type 1, when I choose a row i and a permutation p, I'm essentially setting that entire row to the values in p. Similarly, for Type 2, I'm setting an entire column to a permutation p.

Since the matrix is initially all zeros, every operation I perform will set the chosen row or column to some permutation of 1 to n. But I have to be careful because if I set a row and then a column, they might overwrite each other.

Let me think about how to maximize the sum. Each operation sets a row or a column to a permutation of 1 to n, which means the sum of that row or column will be the sum of numbers from 1 to n, which is n(n+1)/2.

If I perform operations on all rows and all columns, that would be 2n operations, but I need to make sure that I'm not overwriting earlier operations in a way that reduces the total sum.

Wait, actually, when I set a row, it affects only that row, and when I set a column, it affects only that column. But where a row and a column intersect, the last operation on that cell will determine its value.

So, if I set all rows and all columns, each cell will be set by either its row operation or its column operation, depending on which one was the last to set that cell.

To maximize the sum, I need to maximize the value in each cell. Since each row and column operation can set cells to any permutation of 1 to n, I need a strategy to ensure that each cell gets the highest possible value possible.

One idea is to set the main diagonal with row operations and the anti-diagonal with column operations, but I need to think carefully.

Wait, perhaps a better approach is to set all rows first with permutations that maximize the sum, and then set all columns with permutations that maximize the sum, but considering that column operations will overwrite the row operations for the cells in that column.

Alternatively, maybe I can set the rows and columns in such a way that the maximum value possible is achieved in each cell, without overwriting earlier operations in a detrimental way.

Let me consider a small n, say n=1. Then the matrix has only one cell. I can perform either a Type 1 or Type 2 operation, setting that single cell to 1. So the maximum sum is 1, and I can do it with one operation.

For n=2, let's see. If I set both rows and both columns, that's 4 operations, but the limit is 2n=4 operations, so that's acceptable.

Let's think about what values I can set in each cell.

If I set row 1 to [2,1], and row 2 to [2,1], then the matrix would be:

2 1

2 1

Sum is 6.

Alternatively, if I set column 1 to [2,1], and column 2 to [2,1], the matrix would be:

2 2

1 1

Sum is 6.

If I set row 1 to [2,1], column 1 to [2,1], row 2 to [2,1], and column 2 to [2,1], the last operations would determine the matrix:

First set row 1 to [2,1]:

2 1

0 0

Then set column 1 to [2,1]:

2 1

1 0

Then set row 2 to [2,1]:

2 1

2 1

Then set column 2 to [2,1]:

2 1

2 1

So, sum is 6.

But in the example given in the problem, for n=2, the sum is 7 with 3 operations. So, I must be missing something.

Let's look at the example provided:

Operations:

1. Type 1, row 1, permutation [1,2]

2. Type 1, row 2, permutation [1,2]

3. Type 2, column 1, permutation [1,2]

After operation 1:

1 2

0 0

Operation 2:

1 2

1 2

Operation 3:

1 2

1 2

Wait, that's sum 6 again, but the example says sum 7 with those operations. Maybe I'm misunderstanding.

Wait, looking back at the example, it shows:

Operations:

1. Type 1, row 1, permutation [1,2]

2. Type 1, row 2, permutation [1,2]

3. Type 2, column 1, permutation [1,2]

After operation 1:

1 2

0 0

Operation 2:

1 2

1 2

Operation 3:

1 2

1 2

Sum is 1+2+1+2=6, but the example says sum is 7. Maybe I need to look closer.

Wait, perhaps the operations are overwriting in a different way. Let's see:

Start with all zeros:

0 0

0 0

Operation 1: Type 1, row 1, permutation [1,2]

1 2

0 0

Operation 2: Type 1, row 2, permutation [1,2]

1 2

1 2

Operation 3: Type 2, column 1, permutation [1,2]

So, setting column 1 to [1,2], which means:

a_{1,1} = 1

a_{2,1} = 2

So, the matrix becomes:

1 2

2 2

Sum is 1+2+2+2=7.

Ah, I see. So, operation 3 sets column 1 to [1,2], overwriting the previous values in a_{1,1} and a_{2,1}.

So, a_{1,1} was 1 from operation 1, then set to 1 by operation 3.

a_{2,1} was 1 from operation 2, then set to 2 by operation 3.

a_{1,2} was set to 2 by operation 1.

a_{2,2} was set to 2 by operation 2.

So, the matrix is:

1 2

2 2

Sum is 7.

Okay, so the operations can overwrite previous settings, and by choosing which operations to perform last, I can control which values stay.

Now, I need a general strategy for any n.

I need to maximize the sum of the matrix, which means maximizing each cell's value.

Each operation sets an entire row or column to a permutation of 1 to n.

I need to choose which rows and columns to set and in which order, making sure not to exceed 2n operations.

First, I need to realize that each cell will be set by either its row operation or its column operation, depending on which operation was performed last.

So, if I set all rows first, and then set all columns, each cell will have the value set by the column operation, because that's the last operation.

Wait, but in the example above, when they set rows first and then a column, the column operation overwrote the row operation for that column.

So, if I set all rows and then all columns, each cell will have the value set by its column operation, because that's the last operation.

But in the example, they set rows first and then a column, and some cells have row values and some have column values.

Wait, no. In the example, after setting rows 1 and 2 to [1,2], the matrix is:

1 2

1 2

Then, setting column 1 to [1,2], which sets a_{1,1}=1 and a_{2,1}=2.

So, the matrix becomes:

1 2

2 2

So, column operation overwrote the row operation for column 1.

Similarly, if I set another column, it would overwrite the row operations for that column.

So, in general, cells in columns that have been set will have the value from the last column operation, and cells in columns that haven't been set will have the value from the row operations.

So, to maximize the sum, I need to set the columns and rows in such a way that the highest possible values are set in the cells, considering the overwriting.

One idea is to set all rows with permutations that have higher numbers in positions where columns won't overwrite them.

But this seems complicated.

Another idea is to set the rows with permutations that maximize the sum, and then set the columns with permutations that maximize the sum for the cells that weren't already set to high values.

But I need a concrete strategy.

Let me consider that each operation sets an entire row or column, and the last operation on a cell determines its value.

I need to maximize the sum, which is the sum of all a_{i,j}.

I need to choose which rows and columns to set and in which order.

I have a limit of 2n operations.

I need to maximize the sum, so I should aim to set as many high values as possible in the matrix.

One approach could be to set all rows to the permutation [n, n-1, ..., 1], which is the decreasing order, and then set all columns to the same permutation.

But in this case, the column operations will overwrite the row operations for each column.

So, the cells in columns that have been set will have the column's permutation values, and cells in rows that have been set but not overwritten by column operations will have the row's permutation values.

Wait, but in the example, when they set rows first and then a column, the column operation overwrote the row operation for that column.

So, if I set all rows and then all columns, the columns will overwrite the rows for their respective columns.

But perhaps there's a better way to interleave the operations to maximize the sum.

Wait, maybe I should set the rows in such a way that the highest possible values are set in the cells that won't be overwritten by column operations.

Alternatively, perhaps I should set the columns in such a way that the highest possible values are set in the cells that haven't been set by row operations.

This is getting a bit tangled.

Let me try to think differently.

Each operation allows me to set an entire row or column to any permutation of 1 to n.

I need to maximize the sum of all a_{i,j}.

I need to choose which rows and columns to set and in which order, with no more than 2n operations.

I need to maximize the sum, so I should aim to set as many high values as possible in the matrix.

Let me consider that each operation sets an entire row or column, and that the last operation on a cell determines its value.

So, if I set a row and then set a column, the column operation overwrites the row operation for that cell.

Similarly, if I set a column and then a row, the row operation overwrites the column operation for that cell.

So, the order of operations matters.

I need to find an order of operations that maximizes the sum.

Perhaps I can set the rows first with high values and then set the columns with high values, but I need to make sure that the overwriting results in higher values.

Wait, maybe I should set the columns first with high values and then set the rows with high values, so that the row operations overwrite only the cells in those rows, leaving the columns with their high values.

But I need to think carefully.

Let me try to formalize this.

Let me denote that each cell a_{i,j} will take the value from the last operation that set that cell.

So, if I perform operations in a certain order, the cells will have the values from the last operation that set them.

I need to maximize the sum of all a_{i,j}.

I need to choose which rows and columns to set and in which order, to maximize the sum.

I have a limit of 2n operations.

I need to find a sequence of operations that achieves this.

Let me consider that each operation sets a entire row or column to a permutation of 1 to n.

I can choose different permutations for different operations, but for simplicity, perhaps I can choose the same permutation for all operations, say the decreasing order [n, n-1, ..., 1].

Then, if I set all rows to [n, n-1, ..., 1], the matrix would have each row as [n, n-1, ..., 1].

Then, if I set all columns to [n, n-1, ..., 1], the columns would be set accordingly, overwriting the row operations for those columns.

But I need to see what the resulting matrix would look like.

Wait, perhaps I should consider that the last operation on a cell determines its value.

So, if I set all rows first, then set all columns, the columns will overwrite the rows for their columns.

So, the cells in the columns that have been set will have the column's values, and the cells in rows that have been set but not overwritten by column operations will have the row's values.

But I need to maximize the sum, so perhaps I should set the columns that have the highest values in their permutations.

Wait, maybe I need a different approach.

Let me think about the maximum possible sum.

If I could set every cell to n, the sum would be n * n^2 = n^3, but that's not possible because operations set rows or columns to permutations of 1 to n, meaning that in any row or column, each number from 1 to n appears exactly once.

Therefore, the maximum sum is constrained by the fact that in any row or column, the sum is n(n+1)/2.

So, the maximum possible sum for the entire matrix is n * n(n+1)/2 = n^2(n+1)/2.

But I suspect that due to the overwriting, I might not be able to achieve this sum.

Wait, let's see.

If I set all rows to [n, n-1, ..., 1], then the matrix would have each row as [n, n-1, ..., 1], and the sum would be n * (n(n+1)/2) = n^2(n+1)/2.

Similarly, if I set all columns to [n, n-1, ..., 1], the matrix would have each column as [n, n-1, ..., 1], and the sum would be the same.

But because operations overwrite each other, I need to see what the actual sum would be when both row and column operations are performed.

In the example for n=2, the sum is 7, which is more than if I just set all rows or all columns.

So, there must be a way to combine row and column operations to get a higher sum than just setting all rows or all columns.

I need to find a general formula for the maximum sum for any n.

Let me try to find a pattern.

For n=1:

Maximum sum is 1, as shown in the example.

For n=2:

Maximum sum is 7.

For n=3:

Let's see what the sum would be.

If I set all rows to [3,2,1] and all columns to [3,2,1], in what order should I perform the operations to maximize the sum?

Let's try setting rows first:

Set row 1 to [3,2,1]:

3 2 1

0 0 0

0 0 0

Set row 2 to [3,2,1]:

3 2 1

3 2 1

0 0 0

Set row 3 to [3,2,1]:

3 2 1

3 2 1

3 2 1

Now, set column 1 to [3,2,1]:

3 2 1

2 2 1

1 2 1

Sum is 3+2+1 + 2+2+1 + 1+2+1 = 15.

Is there a better way?

Let's try setting columns first.

Set column 1 to [3,2,1]:

3 0 0

2 0 0

1 0 0

Set column 2 to [3,2,1]:

3 3 0

2 2 0

1 1 0

Set column 3 to [3,2,1]:

3 3 3

2 2 2

1 1 1

Sum is 3+3+3 + 2+2+2 + 1+1+1 = 21.

But wait, that's higher than before.

But is it possible to get higher?

Now, if I set rows and columns in a different order.

Let's set row 1 to [3,2,1]:

3 2 1

0 0 0

0 0 0

Set column 1 to [3,2,1]:

3 2 1

2 0 0

1 0 0

Set row 2 to [3,2,1]:

3 2 1

3 2 1

0 0 0

Set column 2 to [3,2,1]:

3 3 1

2 2 1

1 2 0

Set row 3 to [3,2,1]:

3 3 1

2 2 1

3 2 1

Set column 3 to [3,2,1]:

3 3 3

2 2 2

3 2 1

Sum is 3+3+3 + 2+2+2 + 3+2+1 = 23.

Is this the maximum?

Let me see.

Is there a way to get a higher sum?

Let's try a different sequence.

Set row 1 to [3,2,1]:

3 2 1

0 0 0

0 0 0

Set column 1 to [3,2,1]:

3 2 1

2 0 0

1 0 0

Set column 2 to [3,2,1]:

3 3 1

2 2 0

1 2 0

Set row 2 to [3,2,1]:

3 3 1

3 2 1

1 2 0

Set column 3 to [3,2,1]:

3 3 3

3 2 2

1 2 1

Sum is 3+3+3 + 3+2+2 + 1+2+1 = 22, which is less than 23.

So, the previous sequence gave a higher sum.

Is there a way to get higher than 23?

Let me try another sequence.

Set row 1 to [3,2,1]:

3 2 1

0 0 0

0 0 0

Set row 2 to [3,2,1]:

3 2 1

3 2 1

0 0 0

Set column 1 to [3,2,1]:

3 2 1

2 2 1

1 2 1

Set column 2 to [3,2,1]:

3 3 1

2 2 1

1 2 1

Set row 3 to [3,2,1]:

3 3 1

2 2 1

3 2 1

Set column 3 to [3,2,1]:

3 3 3

2 2 2

3 2 1

Sum is 3+3+3 + 2+2+2 + 3+2+1 = 23 again.

Seems like 23 is the maximum achievable with 6 operations (which is 2n for n=3).

So, for n=1, sum=1

n=2, sum=7

n=3, sum=23

Is there a pattern here?

Let's see:

n=1: 1

n=2: 7

n=3: 23

Looking at the differences:

7 - 1 = 6

23 - 7 = 16

6 is 2^2 * 3/1, 16 is 4^2 * 1, but that doesn't seem consistent.

Wait, maybe I can think of it differently.

Let me try to find a general formula.

Looking back at n=2:

Sum = 7 = 1 + 2 + 2 + 2

n=3:

Sum = 23 = 3 + 3 + 3 + 3 + 2 + 2 + 3 + 2 + 1

Is there a pattern or formula that can generalize this?

Let me try to find a formula for the maximum sum.

I need to maximize the sum of the matrix, given that I can perform up to 2n operations, each of which sets a row or a column to a permutation of 1 to n.

I need to choose which rows and columns to set and in which order, to maximize the sum.

I need to consider that operations overwrite previous operations on the cells they set.

I need a strategy to maximize the sum.

Let me consider that each operation sets a entire row or column to a permutation of 1 to n, and that the last operation on each cell determines its value.

So, if I set a row and then a column, the column operation overwrites the row operation for that cell.

So, to maximize the sum, I need to set the columns and rows in such a way that the highest possible values are set in the cells, considering the overwriting.

One possible strategy is to set all rows to the permutation [n, n-1, ..., 1], and then set all columns to the same permutation.

In this case, the columns will overwrite the rows for their columns, but perhaps not all cells are overwritten in the optimal way.

Wait, perhaps I can set the rows in such a way that the highest values are set in the cells that won't be overwritten by column operations.

Alternatively, maybe I can set the columns first with high values and then set the rows with high values, ensuring that the rows overwrite only specific cells.

This seems complicated.

Let me try to think of it in terms of the number of operations.

I have up to 2n operations.

Each row operation sets a entire row, and each column operation sets a entire column.

Each operation can be thought of as painting a row or a column with a permutation of 1 to n.

The last operation on each cell determines its value.

I need to maximize the sum of all cell values.

I need to find an optimal sequence of operations to achieve this.

Perhaps I can think in terms of how many times each cell is set by row operations and column operations.

Each cell is set by its row operation and its column operation, with the last one prevailing.

So, to maximize the sum, I need to maximize the value in each cell, which means choosing the highest possible value for each cell, considering the operations performed.

This seems tricky.

Let me consider that for each cell, the value is determined by the last operation that sets it, which is either a row operation or a column operation.

So, for each cell, if the last operation is a row operation, it gets the value from the row's permutation, and if it's a column operation, it gets the value from the column's permutation.

I need to maximize the sum, which is the sum of all these values.

I need to choose which rows and columns to set and in which order, to maximize this sum.

I need a systematic way to approach this.

Let me consider that each operation sets a entire row or column to a permutation of 1 to n.

I can choose different permutations for different operations, but perhaps choosing the same permutation for all operations simplifies things.

Let's assume that I choose the permutation [n, n-1, ..., 1] for all operations.

Then, if I set all rows to this permutation, the matrix would be:

n n-1 ... 1

n n-1 ... 1

...

n n-1 ... 1

Then, if I set all columns to this permutation, the matrix would be:

n n n

n-1 n-1 n-1

...

1 1 1

Because setting a column to [n, n-1, ..., 1] would set each cell in that column to the corresponding value.

So, if I set all rows first and then all columns, the matrix would be:

n n n

n-1 n-1 n-1

...

1 1 1

Sum would be sum from i=1 to n of i * n = n * sum from i=1 to n of i = n * n(n+1)/2 = n^2(n+1)/2

Similarly, if I set all columns first and then all rows, the matrix would be:

n n-1 ... 1

n n-1 ... 1

...

n n-1 ... 1

Sum would be n * sum from j=1 to n of j = n * n(n+1)/2 = n^2(n+1)/2

So, in both cases, the sum is n^2(n+1)/2

But in the example for n=2, this would be 2^2*(3)/2 = 4*3/2 = 6, but the example shows a sum of 7 with 3 operations.

So, perhaps I can do better by using fewer operations and strategically choosing which rows and columns to set.

Wait, but the operations overwrite each other, so perhaps by carefully choosing the order and which rows and columns to set, I can achieve a higher sum than n^2(n+1)/2.

Alternatively, maybe n^2(n+1)/2 is not the maximum sum, and there's a better way.

Wait, in the n=2 example, n^2(n+1)/2 = 4*3/2 = 6, but the example achieves 7 with 3 operations.

So, clearly, n^2(n+1)/2 is not the maximum sum.

So, perhaps I need to find a different approach.

Let me consider that each operation sets a entire row or column to a permutation of 1 to n, and that operations overwrite each other.

So, the sum is determined by which operations set each cell last.

I need to maximize the sum of these last operations.

I need to find a sequence of operations that maximizes the sum.

This seems similar to covering the matrix with rows and columns, where each cell is covered by the last operation that sets it.

I need to maximize the sum of the values set by these operations.

I need to find a way to cover the matrix with up to 2n operations, maximizing the sum.

This sounds like a problem of selecting a combination of rows and columns to maximize the sum, considering the overwriting.

I need to think about how to arrange the operations to maximize the sum.

Let me consider that each operation corresponds to setting a entire row or column to high values, and that the last operation on each cell determines its value.

I need to maximize the sum, so I should aim to set as many high values as possible in the matrix.

One way to think about it is to set the rows and columns in such a way that the highest possible values are set in the cells that are set by the last operation.

This is still a bit vague.

Let me try to think about it in terms of the number of operations.

I have up to 2n operations.

Each operation sets a entire row or column.

Each cell is set by the last operation that sets it.

So, for example, if I set row 1, then column 1, then row 1 again, the last operation on cell (1,1) is row 1, and for cells (1,j), j!=1, the last operation is row 1, and for cells (i,1), i!=1, the last operation is column 1.

This is getting too complicated.

Perhaps I need to accept that finding the exact maximum sum is tricky, and look for a pattern or formula based on the examples.

In the n=1 case, sum=1

n=2, sum=7

n=3, sum=23

Looking for a pattern:

n=1: 1 = 1^3

n=2: 7 = 2^3 -1

n=3: 23 = 3^3 - go

Wait, 1^3=1, 2^3=8-1=7, 3^3=27-4=23.

Wait, 27-4=23, but 8-1=7.

Is there a pattern here?

Wait, n^3 - (n-1)

For n=1: 1 - 0 =1

n=2: 8 -1=7

n=3:27-4=23

Wait, but 4 is not n-1 for n=3.

Wait, perhaps n^3 - (n-1)^2

For n=2: 8 -1=7

n=3:27-4=23

Yes, that matches.

So, sum = n^3 - (n-1)^2

Wait, but for n=1: 1 -0=1, which is correct.

So, sum = n^3 - (n-1)^2

Let me generalize this.

sum = n^3 - (n-1)^2

But is this correct?

Wait, for n=4: 64 - 9 =55

Let me check for n=4.

If I set all rows to [4,3,2,1] and all columns to [4,3,2,1], in a certain order to maximize the sum.

Let's try setting rows first:

Set row 1 to [4,3,2,1]:

4 3 2 1

0 0 0 0

0 0 0 0

0 0 0 0

Set row 2 to [4,3,2,1]:

4 3 2 1

4 3 2 1

0 0 0 0

0 0 0 0

Set row 3 to [4,3,2,1]:

4 3 2 1

4 3 2 1

4 3 2 1

0 0 0 0

Set row 4 to [4,3,2,1]:

4 3 2 1

4 3 2 1

4 3 2 1

4 3 2 1

Now, set column 1 to [4,3,2,1]:

4 3 2 1

3 3 2 1

2 3 2 1

1 3 2 1

Sum is 4+3+2+1 + 3+3+2+1 + 2+3+2+1 +1+3+2+1 = 4+3+2+1 +3+3+2+1 +2+3+2+1 +1+3+2+1= 10 +10 +10 +10=40

Is there a better way?

Let's try setting columns first.

Set column 1 to [4,3,2,1]:

4 0 0 0

3 0 0 0

2 0 0 0

1 0 0 0

Set column 2 to [4,3,2,1]:

4 4 0 0

3 3 0 0

2 2 0 0

1 1 0 0

Set column 3 to [4,3,2,1]:

4 4 4 0

3 3 3 0

2 2 2 0

1 1 1 0

Set column 4 to [4,3,2,1]:

4 4 4 4

3 3 3 3

2 2 2 2

1 1 1 1

Sum is 4+4+4+4 +3+3+3+3 +2+2+2+2 +1+1+1+1=16+12+8+4=40

Same as before.

Is there a way to get higher than 40?

Let's try a different sequence.

Set row 1 to [4,3,2,1]:

4 3 2 1

0 0 0 0

0 0 0 0

0 0 0 0

Set column 1 to [4,3,2,1]:

4 3 2 1

3 0 0 0

2 0 0 0

1 0 0 0

Set row 2 to [4,3,2,1]:

4 3 2 1

4 3 2 1

2 0 0 0

1 0 0 0

Set column 2 to [4,3,2,1]:

4 4 2 1

3 3 2 1

2 2 0 0

1 1 0 0

Set row 3 to [4,3,2,1]:

4 4 2 1

3 3 2 1

4 3 2 1

1 1 0 0

Set column 3 to [4,3,2,1]:

4 4 4 1

3 3 3 1

4 3 2 1

1 1 1 1

Set row 4 to [4,3,2,1]:

4 4 4 1

3 3 3 1

4 3 2 1

4 3 2 1

Set column 4 to [4,3,2,1]:

4 4 4 4

3 3 3 3

4 3 2 2

4 3 2 1

Sum is 4+4+4+4 +3+3+3+3 +4+3+2+2 +4+3+2+1=16+12+11+10=49

Better than 40.

Is there a way to get higher?

Let me try another sequence.

Set row 1 to [4,3,2,1]:

4 3 2 1

0 0 0 0

0 0 0 0

0 0 0 0

Set column 1 to [4,3,2,1]:

4 3 2 1

3 0 0 0

2 0 0 0

1 0 0 0

Set column 2 to [4,3,2,1]:

4 4 2 1

3 3 0 0

2 2 0 0

1 1 0 0

Set row 2 to [4,3,2,1]:

4 4 2 1

4 3 2 1

2 2 0 0

1 1 0 0

Set column 3 to [4,3,2,1]:

4 4 4 1

4 3 3 1

2 2 2 0

1 1 1 0

Set row 3 to [4,3,2,1]:

4 4 4 1

4 3 3 1

4 3 2 1

1 1 1 0

Set column 4 to [4,3,2,1]:

4 4 4 4

4 3 3 3

4 3 2 2

1 1 1 1

Sum is 4+4+4+4 +4+3+3+3 +4+3+2+2 +1+1+1+1=16+13+11+5=45, which is less than 49.

So, the previous sequence gave a higher sum.

Is there a way to get higher than 49?

Let me try another sequence.

Set row 1 to [4,3,2,1]:

4 3 2 1

0 0 0 0

0 0 0 0

0 0 0 0

Set row 2 to [4,3,2,1]:

4 3 2 1

4 3 2 1

0 0 0 0

0 0 0 0

Set column 1 to [4,3,2,1]:

4 3 2 1

3 3 2 1

2 3 2 1

1 3 2 1

Set column 2 to [4,3,2,1]:

4 4 2 1

3 3 2 1

2 3 2 1

1 3 2 1

Set row 3 to [4,3,2,1]:

4 4 2 1

3 3 2 1

4 3 2 1

1 3 2 1

Set column 3 to [4,3,2,1]:

4 4 4 1

3 3 3 1

4 3 2 1

1 3 2 1

Set row 4 to [4,3,2,1]:

4 4 4 1

3 3 3 1

4 3 2 1

4 3 2 1

Set column 4 to [4,3,2,1]:

4 4 4 4

3 3 3 3

4 3 2 2

4 3 2 1

Sum is 4+4+4+4 +3+3+3+3 +4+3+2+2 +4+3+2+1=16+12+11+10=49 again.

Seems like 49 is the maximum achievable with 8 operations (which is 2n for n=4).

So, for n=1: sum=1

n=2: sum=7

n=3: sum=23

n=4: sum=49

Looking for a pattern:

n=1: 1 =1^3

n=2:7=2^3 -1

n=3:23=3^3 -10

n=4:49=4^3 -27

This doesn't seem consistent.

Wait, perhaps sum = n^3 - (n-1)^3 + (n-1)^2

For n=2:8 -1 +1=8

But example is 7.

Not matching.

Wait, perhaps sum = n^3 - (n-1)^3

For n=2:8-1=7

n=3:27-8=19, but earlier calculation was 23.

Doesn't match.

Wait, perhaps sum = n^3 - (n-1)^2

For n=2:8-1=7

n=3:27-4=23

n=4:64-9=55, but earlier calculation was 49.

Doesn't match.

So, perhaps sum = n^3 - (n-1)^2 - c, where c is some constant.

For n=4:64-9-c=49 implies c=6

Not sure.

Alternatively, perhaps sum = n^3 - (n-1)^3 - (n-1)^2

For n=2:8-1-1=6, but example is 7.

Doesn't match.

This is getting too complicated.

Let me look for another approach.

I recall that in the problem statement, it's mentioned that it's always possible to achieve the maximum sum in no more than 2n operations.

So, perhaps there's a formula for the maximum sum in terms of n.

Looking back at the examples:

n=1: sum=1

n=2: sum=7

n=3: sum=23

n=4: sum=49

Looking at the differences:

7-1=6

23-7=16

49-23=26

The differences are increasing by 10 each time: 6,16,26,...

Wait, 16-6=10, 26-16=10.

So, the differences increase by 10 each time.

So, for n=1:1

n=2:1+6=7

n=3:7+16=23

n=4:23+26=49

So, the differences are increasing by 10 each time.

So, perhaps the general formula is sum = sum from k=1 to n of (something involving k)

But I need a better way to generalize this.

Alternatively, perhaps sum = sum_{k=1}^n (k*(2n - k +1))

Wait, for n=1:1*(2-1+1)=1*2=2, but actual sum is 1.

Doesn't match.

Wait, perhaps sum = sum_{k=1}^n (k*(2n - k +1)) - c

For n=2: (1*(4-1+1)=4) + (2*(4-2+1)=5) + (3*(4-3+1)=3) + (4*(4-4+1)=4) =4+5+3+4=16, but actual sum is 7.

Doesn't match.

This is not working.

Let me try to think differently.

Each operation sets a row or column to a permutation of 1 to n, meaning that the sum of that row or column is n(n+1)/2.

If I set m rows, the sum would be m*n(n+1)/2, but this is an overestimate because columns may overwrite some cells.

Similarly, if I set p columns, the sum would be p*n(n+1)/2, but again, there's overwriting.

I need to account for the overwriting.

Let me consider that each cell is set by either a row operation or a column operation, whichever was performed last.

So, the sum is equal to the sum of the values set by the last operations on each cell.

So, if I perform m row operations and p column operations, with m + p <= 2n, then the sum would be equal to the sum of the values set by these operations, considering the overwriting.

This seems too vague.

Perhaps I need to accept that finding a general formula is difficult, and look back at the code provided.

Looking at the code:

def func():

t = int(input())

for _ in range(t):

n = int(input())

sum = 1

for i in range(2, n + 1):

sum += (i * i - (i - 1) * (i - 1)) * i

print(sum, n + n)

for j in range(1, n + 1):

print(1, n - j + 1, *range(1, n + 1))

print(2, n - j + 1, *range(1, n + 1))

So, for each test case, it reads n, then computes sum as follows:

sum =1

for i from 2 to n:

sum += (i^2 - (i-1)^2) * i

Which simplifies to:

sum =1 + sum from i=2 to n of ( (2i-1)*i ) = sum from i=1 to n of ( (2i-1)*i )

Which is sum from i=1 to n of (2i^2 -i)

Which is 2*sum_{i=1 to n} i^2 - sum_{i=1 to n} i

Which is 2*(n(n+1)(2n+1)/6) - n(n+1)/2 = n(n+1)/6 * (4n+2) - n(n+1)/2

= n(n+1)/6 * (4n+2 -3) = n(n+1)/6 * (4n -1)

Wait, that doesn't seem right.

Wait, let's compute it properly.

sum = sum from i=1 to n of (2i^2 -i) = 2*sum_{i=1 to n} i^2 - sum_{i=1 to