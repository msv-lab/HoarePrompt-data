Alright, I've got this problem to solve. Let's see what it's asking for. So, there's this n by n matrix that's initially all zeros. Nene can perform two types of operations on this matrix. Each operation allows her to set an entire row or column to a permutation of numbers from 1 to n. The goal is to maximize the sum of all elements in the matrix using no more than 2n operations.

First, I need to understand what these operations do. A type 1 operation lets me choose a row and set its elements to any permutation of 1 through n. Similarly, a type 2 operation lets me choose a column and set its elements to any permutation of 1 through n.

Since the matrix is initially all zeros, every operation I perform will set the chosen row or column to some permutation. But I have to be careful because operations can overwrite each other if I choose the same row or column multiple times.

I need to maximize the sum of all elements in the matrix. Each element in the matrix can be set to a number between 1 and n, but the way operations work, entire rows and columns are set at once.

This sounds like there might be some conflict when both row and column operations are applied to the same cell. I need to think about how the operations interact with each other.

Let me consider a small example to get a better understanding. Let's take n=2.

Initially, the matrix is:

0 0

0 0

If I perform a type 1 operation on row 1, setting it to [2,1], the matrix becomes:

2 1

0 0

Then, if I perform a type 2 operation on column 1, setting it to [2,1], the matrix becomes:

2 1

1 0

Wait, but column 1 is now [2,1], and row 1 is [2,1]. So, when I set column 1 to [2,1], it overwrites the first element of row 1 from 2 to 2, which doesn't change it, and sets the first element of row 2 from 0 to 1.

Alternatively, if I set column 1 first to [2,1], then set row 1 to [2,1], it would be similar.

I need to see what's the maximum sum I can achieve. For n=2, the maximum sum seems to be 7, as per the example:

2 + 1 + 2 + 2 = 7

Wait, but in the note, they have:

2 + 1 + 2 + 2 = 7

Yes, that makes sense.

So, to maximize the sum, I should aim to have as many high-value elements as possible in the matrix.

Given that each operation sets an entire row or column, I need to decide which rows and columns to set and in what order.

I should consider that setting a row will affect all its columns, and setting a column will affect all its rows.

I need to find a way to cover as much of the matrix as possible with higher numbers.

One approach could be to set all rows first with the maximum permutation [n, n-1, ..., 1], but that might not be optimal because columns could overwrite some of these values.

Alternatively, I could set all columns first with [n, n-1, ..., 1], and then set specific rows.

Wait, perhaps I need to think in terms of which rows and columns to set and in what order to maximize the sum.

Let me think about the sum.

Each operation sets a row or column to a permutation of 1 to n, meaning that the sum of a row or column after setting it will be n(n+1)/2.

But since rows and columns can overlap, I need to account for that.

Wait, maybe I should think in terms of how many times each cell is set.

Each cell can be set by at most one row operation and one column operation.

The last operation that sets the cell determines its value.

So, to maximize the sum, I should aim to set as many cells as possible to the highest possible values.

I need to maximize the number of cells set to n, then to n-1, and so on.

I need a strategy to maximize the sum given the constraints.

Let me consider the example for n=2 again.

Set row 1 to [1,2], then row 2 to [1,2], then column 1 to [1,2].

Resulting matrix:

1 2

2 2

Sum: 1+2+2+2=7

Alternatively, set column 1 to [2,1], column 2 to [2,1], row 1 to [2,1].

Matrix:

2 1

2 1

Sum: 2+1+2+1=6

Which is less than 7.

So, the first approach is better.

Wait, in the first approach, using 3 operations: two row operations and one column operation.

Is there a way to get a higher sum with at most 4 operations (since 2n=4 for n=2)?

Let's try.

Set row 1 to [2,2], row 2 to [2,2], column 1 to [2,2], column 2 to [2,2].

But permutations must consist of distinct integers from 1 to n.

So, for n=2, [2,2] is invalid because it's not a permutation.

Ah, permutations must have all numbers from 1 to n exactly once.

So, [2,2] is invalid.

Thus, in n=2, permutations can only be [1,2] or [2,1].

So, in the first approach, setting row 1 to [1,2], row 2 to [1,2], and column 1 to [1,2], resulting in:

1 2

2 2

Sum: 7

Is this the maximum possible?

Is there a way to get 8? No, because no cell can be higher than 2.

So, 7 is indeed the maximum.

Wait, but in the note, they have set row 1 to [1,2], row 2 to [1,2], and column 1 to [1,2], resulting in:

2 1

1 2

Wait, no, in the note, they have:

Set row 1 to [1,2], row 2 to [1,2], column 1 to [1,2].

Matrix becomes:

1 2

2 2

Sum: 7

Yes, that makes sense.

So, the maximum sum is 7 for n=2.

Now, for general n, I need to find a way to maximize the sum using at most 2n operations.

I need to find a pattern or a formula to calculate the maximum possible sum and the operations to achieve it.

Let me think about the sum.

Each operation sets a row or column to a permutation of 1 to n, summing to n(n+1)/2.

If I set all rows, the sum would be n * (n(n+1)/2) = n^2(n+1)/2.

But, of course, columns can overwrite some of these values.

Similarly, if I set all columns, the sum would also be n * (n(n+1)/2) = n^2(n+1)/2.

But since rows and columns can overlap, the actual sum will be higher.

Wait, no. If I set all rows, then setting all columns would overwrite the appropriate columns, potentially increasing the sum further.

I need to find an optimal way to combine row and column operations.

Let me consider the following approach:

- Set all rows to [n, n-1, ..., 1]

- Then set all columns to [n, n-1, ..., 1]

But again, I need to see what the resulting matrix would be.

Wait, but since operations can overwrite each other, I need to think carefully.

Alternatively, perhaps I can set some rows and some columns in a way that maximizes the sum.

I need to find a way to cover as much of the matrix as possible with higher values.

Let me consider the sum if I set all rows.

Sum would be n * (n(n+1)/2) = n^2(n+1)/2

But actually, since columns can overwrite some cells, the sum could be higher.

Wait, but in reality, setting all rows gives me a sum of n^2(n+1)/2, but then setting columns can potentially increase some cells further.

However, I need to find the maximum possible sum and the operations to achieve it.

I need a better way to calculate the maximum sum.

Let me think about it differently.

Each cell in the matrix can be set to a value between 1 and n.

Each cell can be set by at most one row operation and one column operation.

The last operation that sets the cell determines its value.

So, to maximize the sum, I need to set as many cells as possible to n, then to n-1, and so on.

I need to maximize the number of cells set to n, then the remaining to n-1, and so on.

Wait, perhaps I can think in terms of how many cells can be set to n, how many to n-1, and so on.

Given that each row operation sets a row to a permutation, and each column operation sets a column to a permutation, there are constraints on how many cells can be set to n.

For example, in a single row operation, only one cell in that row can be set to n.

Similarly, in a column operation, only one cell in that column can be set to n.

Moreover, if I set a row and then a column that intersects with that row, the column operation will overwrite the row operation for that cell.

So, I need to carefully plan which rows and columns to set and in what order to maximize the number of cells set to n.

Let me consider the maximum number of cells that can be set to n.

If I set all rows, then each row has one cell set to n.

Similarly, if I set all columns, each column has one cell set to n.

But if I set all rows and all columns, the cells where row and column operations set n will be overwritten by the last operation.

Wait, in reality, for cells set by both a row and a column operation, the last operation determines the value.

So, if I set all rows first, setting one cell per row to n, then set all columns, setting one cell per column to n, the cells where row and column operations set n will be set to n by the last operation.

But I need to think carefully about the overlaps.

Wait, perhaps a better approach is to set some rows and some columns such that the number of cells set to n is maximized.

I need to maximize the sum, which is equivalent to maximizing the number of cells set to n, then n-1, and so on.

But perhaps there's a formula to calculate the maximum possible sum without worrying about the operations.

Let me think about it.

Suppose I set k rows and m columns, with k + m <= 2n.

Each row operation allows me to set one cell to n, and similarly for column operations.

But there might be overlaps where a cell is set by both a row and a column operation.

In that case, the last operation determines the value of that cell.

So, to maximize the sum, I need to maximize the number of cells set to n, minimizing overlaps where possible.

Wait, maybe I can model this as selecting k rows and m columns such that k + m <= 2n, and the number of cells that are set to n is maximized.

Each row operation sets one cell to n, and each column operation sets one cell to n.

But if a row and a column operation set the same cell, then only one of them contributes to setting that cell to n.

So, the total number of cells set to n is k + m - overlap, where overlap is the number of cells set by both a row and a column operation.

To maximize k + m - overlap, I need to minimize the overlap.

The minimal overlap occurs when the row and column operations are chosen such that their intersections are minimized.

In other words, if I choose k rows and m columns such that the number of cells where row and column operations set n is minimized.

Given that each row operation sets one cell to n, and each column operation sets one cell to n, the minimal overlap is when the cells where n is set by row operations and column operations are as distinct as possible.

The minimal overlap is max(k + m - n, 0).

So, the number of cells set to n is k + m - overlap = k + m - max(k + m - n, 0).

Which simplifies to min(k + m, n).

Therefore, the maximum number of cells that can be set to n is min(k + m, n), where k + m <= 2n.

Given that, the maximum number of cells set to n is n, achieved when k + m >= n.

Then, the remaining cells can be set to n-1, n-2, etc.

Wait, but this seems too simplistic.

Let me think differently.

Suppose I set k rows and m columns, with k + m <= 2n.

Each row operation sets one cell to n, and each column operation sets one cell to n.

The total number of cells set to n is min(k + m, n), assuming optimal choice of rows and columns.

Then, the remaining cells can be set to n-1, and so on.

But this seems unclear.

Maybe I need to consider the sum directly.

Each cell can be set to a value between 1 and n.

Each cell can be set by at most one row operation and one column operation.

The last operation that sets the cell determines its value.

So, to maximize the sum, I should aim to set as many cells as possible to n, then to n-1, and so on.

Given that, perhaps the maximum sum is n^3 - n^2(n-1)/2.

Wait, that doesn't seem right.

Alternatively, perhaps the maximum sum is n * (n(n+1)/2).

Wait, no.

Wait, n * (n(n+1)/2) is n^2(n+1)/2, which is the sum if all rows are set to [n, n-1, ..., 1].

But I can do better by setting some columns as well.

Wait, perhaps the maximum sum is n * (n(n+1)/2) + n * (n(n+1)/2) - n^2.

But that seems off.

Alternatively, perhaps the maximum sum is n * (n(n+1)/2) + (m - n) * n, where m is the number of column operations.

Wait, I'm getting confused.

Let me try to think in terms of the number of operations.

I have at most 2n operations.

Each operation sets a row or a column to a permutation of 1 to n, summing to n(n+1)/2 per operation.

But because operations can overwrite each other, the total sum isn't just the sum of individual operations.

I need a different approach.

Let me consider that each operation sets a entire row or column, and the last operation on a cell determines its value.

So, if I set a row, it sets all its cells, and if I later set a column that intersects with that row, the column operation overwrites the row operation for that cell.

So, perhaps I should aim to set columns after setting rows, to overwrite only specific cells.

Wait, perhaps I should set all rows first, then set specific columns to overwrite certain cells to higher values.

But I need to maximize the sum, so I need to maximize the values in the cells.

Wait, maybe I should set the columns first, setting the highest possible values in the columns, then set the rows to overwrite only necessary cells.

This is getting too convoluted.

Let me look for a pattern or formula that can give me the maximum sum directly.

Suppose I set k rows and m columns, with k + m <= 2n.

Each row operation sets a permutation of 1 to n, summing to n(n+1)/2.

Similarly for column operations.

But again, due to overwriting, the total sum isn't just k*(n(n+1)/2) + m*(n(n+1)/2).

I need to find a way to calculate the sum based on how the operations interact.

Alternatively, perhaps I can think in terms of the number of times each cell is set.

Each cell can be set at most once by a row operation and once by a column operation.

The last operation determines the cell's value.

So, if a cell is set by a row operation and not by a column operation, it takes the value from the row operation.

If it's set by a column operation after the row operation, it takes the value from the column operation.

So, to maximize the sum, I need to set as many cells as possible to n via column operations, and the remaining cells to n via row operations where possible.

Wait, perhaps I should aim to set the columns to have n in positions that aren't covered by row operations.

But this seems too vague.

Let me consider the dual approach: instead of thinking about operations, think about assigning values to cells directly, ensuring that each row and each column contains a permutation of 1 to n.

Wait, but that's not exactly correct because operations set entire rows or columns to permutations, but multiple operations can affect the same cell.

Actually, no, because operations overwrite previous values.

This is getting complicated.

Maybe I should look for a different strategy.

Let me consider that each operation, whether row or column, sets the entire row or column to a permutation of 1 to n.

So, if I set a row, I can choose any permutation for it.

Similarly for a column.

But since operations can overwrite each other, I need to sequence them carefully.

Wait, perhaps I can model this as a graph where nodes represent rows and columns, and edges represent cells.

But that might be too involved.

Let me try to find a pattern by looking at small n.

For n=1:

Only one cell.

I can set it via either a row operation or a column operation.

The maximum sum is 1.

For n=2:

As in the example, the maximum sum is 7.

For n=3:

Let's see.

If I set all rows: sum = 3 * (3*4/2) = 18

But setting columns can overwrite some cells, potentially increasing the sum.

If I set all rows and all columns, that's 6 operations, which is within 2n=6.

But what would the sum be?

Each cell is set by one row operation and one column operation, so the last operation determines its value.

If I set all rows first with [3,2,1], then set all columns with [3,2,1], the matrix would have the values from the column operations, as they overwrite the row operations.

So, the sum would be 3 + 2 + 1 + 3 + 2 + 1 + 3 + 2 + 1 = 18

But is this the maximum?

Alternatively, if I set rows to [3,2,1], and columns to [3,2,1], but in a way that maximizes the sum.

Wait, perhaps I can set rows to have higher values in certain positions, and columns to have higher values in other positions.

But I'm getting stuck.

Let me consider that for n=2, the maximum sum is 7, which is higher than setting all rows or all columns individually.

So, perhaps there's a formula for the maximum sum.

Let me see:

For n=1: sum=1

For n=2: sum=7

For n=3: ?

Let me try to calculate for n=3.

If I set all rows to [3,2,1], sum is 3+2+1+3+2+1+3+2+1=18

If I set all columns to [3,2,1], sum is the same.

But if I combine them, the sum doesn't increase because column operations overwrite row operations.

Wait, perhaps I can set some rows and some columns in a way that maximizes the sum.

For example, set row 1 to [3,3,3], but that's invalid because it's not a permutation.

Wait, permutations must be [1,2,3], [1,3,2], [2,1,3], etc.

So, for n=3, permutations sum to 6.

If I set all rows, sum is 3*6=18

If I set all columns, sum is 3*6=18

If I set rows and columns, sum is still 18, because column operations overwrite row operations.

Wait, but maybe I can set rows and columns in a way that the overwriting increases the sum.

For example, set row 1 to [3,2,1], row 2 to [3,2,1], row 3 to [3,2,1], then set column 1 to [3,2,1], column 2 to [3,2,1], column 3 to [3,2,1].

The matrix would be:

3 2 1

2 2 1

1 2 1

Sum: 3+2+1 + 2+2+1 + 1+2+1 = 15

Wait, that's less than 18.

Alternatively, set row 1 to [3,2,1], row 2 to [3,2,1], row 3 to [3,2,1], then set column 1 to [3,2,1], column 2 to [3,2,1], column 3 to [3,2,1].

Wait, in this case, the matrix would be:

3 2 1

2 2 1

1 2 1

Sum: 3+2+1 + 2+2+1 + 1+2+1 = 15

But if I only set all rows, sum is 3*(3+2+1)=18

So, setting columns after rows decreases the sum.

Wait, that's counterintuitive.

Alternatively, maybe set columns first, then rows.

Set column 1 to [3,2,1], column 2 to [3,2,1], column 3 to [3,2,1], then set row 1 to [3,2,1], row 2 to [3,2,1], row 3 to [3,2,1].

The matrix would be:

3 2 1

2 2 1

1 2 1

Again, sum is 15.

Same as before.

So, setting all columns or all rows gives a higher sum than setting both.

Wait, but for n=2, setting both gives a higher sum.

Wait, for n=2:

Set row 1 to [1,2], row 2 to [1,2], then set column 1 to [1,2].

Matrix:

1 2

2 2

Sum: 7

Alternatively, set all rows: sum is 1+2 + 1+2 = 6

Set all columns: sum is 1+2 + 1+2 = 6

But by setting rows and columns, sum is 7.

So, in n=2, setting both gives a higher sum.

But in n=3, setting all rows or all columns gives sum=18, while setting both gives sum=15, which is less.

Wait, that can't be right.

Wait, perhaps I miscalculated.

Let me try again for n=3.

Set row 1 to [3,2,1], row 2 to [3,2,1], row 3 to [3,2,1], then set column 1 to [3,2,1], column 2 to [3,2,1], column 3 to [3,2,1].

Matrix:

3 2 1

2 2 1

1 2 1

Sum: 3+2+1 + 2+2+1 + 1+2+1 = 15

But if I only set all rows: sum is 3+2+1 + 3+2+1 + 3+2+1 = 18

Similarly, if I only set all columns: sum is 3+2+1 + 3+2+1 + 3+2+1 = 18

So, indeed, setting both decreases the sum.

Wait, but in n=2, setting both gives a higher sum.

Wait, for n=2:

Set row 1 to [1,2], row 2 to [1,2], then set column 1 to [1,2].

Matrix:

1 2

2 2

Sum: 1+2+2+2=7

If I only set all rows: sum is 1+2 + 1+2 = 6

Setting both gives 7, which is higher.

But for n=3, setting all rows gives 18, setting all columns gives 18, and setting both gives 15, which is lower.

This suggests that for n=2, setting both is better, but for n=3, setting only rows or only columns is better.

Wait, perhaps there's a pattern based on n.

Let me try n=1: sum=1

n=2: sum=7

n=3: sum=18

n=4: ?

Wait, but n=1: sum=1

n=2: sum=7=2*3 +1

n=3: sum=18=3*6

n=4: sum=?

Is there a formula here?

Wait, for n=2: 7=2*3 +1

For n=3: 18=3*6

Wait, 2*3 +1=7, 3*6=18

Is there a general formula?

Wait, perhaps sum = n*(n+1) + (n-2)*(n-1)/2

Wait, for n=2: 2*3 +0=6, but example shows 7, so that doesn't match.

Alternatively, perhaps sum = n*(n+1)/2 + (n-1)*n/2

Wait, that's n*(n+1)/2 + n*(n-1)/2 = n^2

For n=2: 4, but example has 7, so no.

Wait, perhaps sum = n*(n^2 +1)/2

For n=2: 2*(4+1)/2=5, which is less than 7.

No.

Alternatively, sum = n*(n+1)/2 * something.

Wait, perhaps sum = n*(n+1)/2 + (n-1)*n(n+1)/2

Wait, for n=2: 3 + 2*3=9, which is more than 7.

No.

Alternatively, perhaps sum = n*(n+1)/2 + n*(n-1)

For n=2: 3 + 2*1=5, which is less than 7.

No.

Wait, perhaps sum = n*(n+1) - something.

For n=2: 6 - (-1)=7, which sort of matches, but not useful.

This isn't helping.

Let me think differently.

Each operation sets a row or column to a permutation of 1 to n, summing to n(n+1)/2 per operation.

But operations can overwrite each other.

If I perform k operations, the sum isn't k*(n(n+1)/2), but less due to overwriting.

So, perhaps the maximum sum is achieved by performing operations in a way that minimizes overwriting.

Wait, but in n=2, performing 3 operations gives sum=7, which is higher than performing 4 operations giving sum=6.

Similarly, in n=3, performing 6 operations gives sum=15, which is less than performing 3 operations giving sum=18.

Wait, but in n=3, performing 3 operations (all rows or all columns) gives sum=18, while performing 6 operations gives sum=15, which is less.

So, perhaps for n >=3, performing only row operations or only column operations gives the maximum sum.

But for n=2, performing a combination of row and column operations gives a higher sum.

This suggests that the optimal number of operations depends on n.

Wait, perhaps for n=1 and n>=3, performing only row or only column operations is better, while for n=2, performing a combination is better.

But n=1: sum=1, performing one operation is sufficient.

For n=2: sum=7, performing 3 operations is better than 4.

For n=3: sum=18, performing 3 operations is better than 6.

So, perhaps for general n, performing n operations (all rows or all columns) is sufficient to achieve the maximum sum.

But in n=2, performing n+1=3 operations gives a higher sum.

So, perhaps for n >=2, performing n + floor((n-1)/2) operations gives the maximum sum.

Wait, for n=2: n + floor(1/2)=2+0=2 operations, but in the example, they use 3 operations.

Wait, perhaps that's not the way.

Alternatively, perhaps the maximum sum is n*(n^2 +1)/2 - something.

Wait, n*(n^2 +1)/2 is the sum if the matrix were a magic square, but it's not applicable here.

I need to find a different approach.

Let me consider that each cell can be set to a value between 1 and n, and I need to maximize the sum.

Given that, the theoretical maximum sum is n*n*n = n^3.

But, due to the operations' constraints, I might not be able to set all cells to n.

So, I need to find how many cells can be set to n, how many to n-1, and so on.

Each row operation can set one cell in the row to n.

Similarly, each column operation can set one cell in the column to n.

But due to overwriting, some cells might be set to n by both operations, but only the last operation counts.

So, perhaps the maximum number of cells set to n is n + m - overlap, where m is the number of column operations.

Wait, but I need to minimize overlap to maximize the number of cells set to n.

Given that, perhaps the maximum number of cells set to n is n + m - min(n, m)

But I'm not sure.

This is getting too complicated.

Let me look for a different approach.

Suppose I set k rows and m columns, with k + m <= 2n.

Each row operation sets one cell to n, and each column operation sets one cell to n.

The total number of cells set to n is k + m - the number of overlaps.

The number of overlaps is the number of cells set by both a row and a column operation.

To maximize the number of cells set to n, I need to minimize the overlaps.

The minimal number of overlaps is max(k + m - n, 0).

Therefore, the number of cells set to n is k + m - max(k + m - n, 0)

Which simplifies to min(k + m, n)

Then, the remaining cells can be set to n-1, and so on.

So, the maximum sum would be:

sum_{i=1 to min(k + m, n)} n +

sum_{i=min(k + m, n)+1 to n^2} (n - ceil((i - min(k + m, n))/n))

Wait, this seems too convoluted.

Perhaps I need to accept that finding a general formula is difficult and look for a different approach.

Let me consider that performing operations on rows and columns allows me to set the matrix to any combination of permutations, with the constraint that each cell is set by the last operation that affects it.

So, perhaps I can think of the matrix as being built by combining row and column operations, where column operations overwrite row operations in the intersecting cells.

Given that, perhaps the maximum sum is achieved by setting rows and columns in a way that maximizes the number of cells set to n.

But I need a practical way to calculate this.

Let me consider the following approach:

- Set all rows to [n, n-1, ..., 1]

- Then, set as many columns as needed to [n, n-1, ..., 1], overwriting cells to potentially higher values.

But in practice, overwriting might not always increase the sum.

Alternatively, perhaps I can set the rows first, then set specific columns to adjust certain cells to higher values.

But this seems too vague.

Let me consider the sum if I set k rows and m columns.

The sum would be the sum of the values set by the operations, minus the overwrites.

But calculating this seems complex.

Perhaps I should look for an upper bound on the sum and see if it's achievable.

The theoretical maximum sum is n^3, but due to the permutation constraint, it's not achievable.

Wait, for n=2, 2^3=8, but the maximum sum is 7, which is less than 8.

So, the maximum sum is less than n^3.

Alternatively, perhaps the maximum sum is n*(n^2 +1)/2, but for n=2, that's 5, which is less than 7.

So, that's not it.

Alternatively, perhaps the maximum sum is n*(n(n+1)/2), which is n^2(n+1)/2.

For n=2, that's 4*3/2=6, but the example shows 7.

Wait, no, n^2(n+1)/2 for n=2 is 8/2=4, which is less than 7.

Wait, no, n^2(n+1)/2 for n=2 is 4*3/2=6, which is still less than 7.

So, that can't be it.

Wait, perhaps the maximum sum is n*(n(n+1)/2) + something.

Wait, for n=2: 6 +1=7, which matches the example.

Similarly, for n=3: 3*(3*4/2)=18, which seems to be the maximum sum.

For n=1: 1*(1*2/2)=1, which matches.

So, perhaps the maximum sum is n*(n(n+1)/2) = n^2(n+1)/2.

But for n=2, it's 6, but the example shows 7.

Wait, that doesn't match.

So, perhaps it's something else.

Wait, perhaps it's n*(n+1)^2 /2.

For n=2: 2*9/2=9, which is more than 7.

No.

Alternatively, perhaps it's n*(n+1)/2 + n*(n(n+1)/2).

Wait, that's n*(n+1)/2 + n^2(n+1)/2 = n(n+1)/2 * (1 + n)

For n=2: 2*3/2 * 3=3*3=9, which is more than 7.

No.

This isn't working.

Let me think differently.

Suppose I set all rows to [n, n-1, ..., 1], sum per row is n(n+1)/2, total sum is n * (n(n+1)/2) = n^2(n+1)/2

Similarly, setting all columns to [n, n-1, ..., 1], sum per column is n(n+1)/2, total sum is n * (n(n+1)/2) = n^2(n+1)/2

But when I set both, some cells are overwritten.

So, the total sum when setting all rows and all columns would be n^2(n+1)/2 + n^2(n+1)/2 - the sum of the cells that are overwritten.

But calculating the sum of overwritten cells is complex.

Alternatively, perhaps the maximum sum is n*(n^2 +1)/2 - something.

Wait, n*(n^2 +1)/2 is the sum of the first n^2 natural numbers, which is 1 + 2 + ... + n^2.

But for n=2: 2*5=10, but the example shows 7, which is less than 10.

So, perhaps it's not that.

I'm stuck.

Maybe I should look for a different approach.

Let me consider that each operation sets a row or column to a permutation of 1 to n, summing to n(n+1)/2.

If I perform m operations, the sum would be m*(n(n+1)/2) minus the sum of the overwrites.

But without knowing the overwrites, this is not helpful.

Alternatively, perhaps the maximum sum is achieved by performing operations in a way that minimizes the overwrites.

Wait, but in n=2, performing 3 operations gives a higher sum than performing 4 operations.

So, perhaps performing exactly n operations is not always optimal.

Wait, for n=2, performing 3 operations gives sum=7, while performing 4 operations gives sum=6.

For n=3, performing 3 operations gives sum=18, while performing 6 operations gives sum=15.

So, for n=2, performing n + floor((n-1)/2) operations is optimal.

Wait, n + floor((n-1)/2) for n=2 is 2 +0=2, which is less than 3.

No.

Alternatively, perhaps performing n + ceil(n/2) operations is optimal.

For n=2: 2 +1=3, which matches the example.

For n=3: 3 +1=4 operations, but in the earlier attempt, performing 3 operations gives sum=18, while performing 4 operations might give less.

Wait, but in n=3, performing 3 operations gives sum=18, which seems better than performing 4 operations.

So, perhaps for n >=3, performing n operations is optimal, while for n=2, performing n+1 operations is better.

This suggests that there's a different strategy for n=2.

Perhaps for n >=3, performing n operations (all rows or all columns) is optimal, while for n=2, performing n+1 operations gives a better sum.

So, perhaps for general n, the maximum sum is:

sum = n * (n(n+1)/2) = n^2(n+1)/2

But for n=2, it's 8, but the example shows 7.

Wait, 2* (2*3/2) = 6, but example has 7.

Wait, perhaps it's different.

Wait, perhaps for n=2, the maximum sum is 1 + 2 + 2 + 2 =7

Wait, perhaps the formula is:

sum = n * (n +1)/2 + (n -1) * n

For n=2: 3 + 2*1=5, which is less than 7.

No.

Alternatively, sum = n^2 + n -1

For n=2: 4 + 2 -1=5, less than 7.

No.

Alternatively, sum = n^2 + n -1 for n>=2

Wait, for n=2: 4 + 2 -1=5, but example is 7.

No.

Alternatively, sum = n^2 + n -1 for n>=2, but doesn't match.

This isn't working.

Let me try to find a different pattern.

Looking back at n=1: sum=1

n=2: sum=7

n=3: sum=18

n=4: ?

Looking for a sequence: 1,7,18,...

Looking at differences: 6,11,...

Looking at second differences: 5,...

So, perhaps it's a quadratic function.

Let me assume sum = a*n^2 + b*n + c

For n=1: a + b + c =1

n=2: 4a +2b +c=7

n=3:9a +3b +c=18

Subtracting n=1 from n=2: 3a + b=6

Subtracting n=2 from n=3:5a +b=11

Subtracting these two: 2a=5 => a=2.5

Then, 3*2.5 + b=6 => 7.5 + b=6 => b=-1.5

Then, 2.5 -1.5 +c=1 => c=0

So, sum =2.5 n^2 -1.5 n

For n=2: 2.5*4 -1.5*2=10 -3=7, matches.

For n=3:2.5*9 -1.5*3=22.5 -4.5=18, matches.

For n=4:2.5*16 -1.5*4=40 -6=34

So, sum =2.5 n^2 -1.5 n = (5/2)n^2 - (3/2)n = (5n^2 -3n)/2

So, sum = (5n^2 -3n)/2

Is this correct?

For n=1: (5-3)/2=1, matches.

n=2: (20-6)/2=14/2=7, matches.

n=3: (45-9)/2=36/2=18, matches.

n=4: (80-12)/2=68/2=34, assuming that's correct.

So, sum = (5n^2 -3n)/2

Now, I need to confirm if this is indeed the maximum sum.

Given that, for n=2, sum=7, which matches the example.

For n=3, sum=18, which matches setting all rows or all columns.

For n=4, sum=34.

Now, I need to find a way to achieve this sum with at most 2n operations.

Given that, for n=2, sum=7 with 3 operations.

For n=3, sum=18 with 3 operations (all rows or all columns).

For n=4, sum=34 with 4 operations (all rows or all columns).

Wait, for n=4, sum=34.

If I set all rows, sum is 4*(4*5/2)=4*10=40, which is more than 34.

Wait, but according to the formula, sum should be 34.

Wait, perhaps the formula is incorrect.

Wait, according to the formula, sum=(5n^2 -3n)/2

For n=4: (80-12)/2=68/2=34

But if setting all rows gives sum=40, which is higher than 34, but according to the formula, it's 34.

So, perhaps the formula is wrong.

Wait, perhaps the formula is sum=(n^3 +n^2)/2

Wait, for n=2: (8 +4)/2=6, but example shows 7.

No.

Alternatively, sum=(n^3 +n)/2

For n=2: (8 +2)/2=5, less than