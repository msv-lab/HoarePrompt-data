Alright, I've got this problem to solve. Let's see what it's asking for. So, there's this n x n matrix that's initially filled with zeros. Nene can perform two types of operations on this matrix. 

The first type allows her to choose a row and assign a permutation of numbers from 1 to n to that row. Similarly, the second type lets her choose a column and assign a permutation of 1 to n to that column. The goal is to maximize the sum of all elements in the matrix using no more than 2n operations.

First, I need to understand what these operations do. For type 1, when she chooses a row i and a permutation p, she sets a[i][j] to p[j] for all j. Similarly, for type 2, choosing a column i and a permutation p sets a[j][i] to p[j] for all j.

Since the matrix starts with all zeros, every operation will set the values in either a row or a column to some permutation of 1 to n. The key here is that permutations are used, meaning each number from 1 to n appears exactly once in the row or column being set.

Now, the sum we're trying to maximize is the sum of all elements in the matrix. Since each operation sets a whole row or column, I need to think about how to cover the matrix with these operations to maximize the sum.

One important observation is that if a cell is set by both a row operation and a column operation, the value in that cell will be set by the last operation performed. This is because each operation overwrites the values in the row or column.

So, to maximize the sum, I should aim to set as many cells as possible to the highest possible values. Given that permutations are used, the highest possible value in any cell is n, the next is n-1, and so on, down to 1.

But since operations overwrite each other, I need to be strategic about which operations I perform and in what order.

Let me think about the maximum possible sum. If I could set every cell to n, the sum would be n * n * n = n^3. However, because permutations are used, and each row or column can only have each number from 1 to n once, I can't set all cells to n.

So, what's the actual maximum sum possible?

Let me consider that each row operation sets one row to a permutation of 1 to n, and each column operation sets one column to a permutation of 1 to n.

If I perform row operations on all rows, that would set each row to a permutation of 1 to n, and the sum would be n times the sum of a permutation, which is n times (n(n+1)/2), so n * n(n+1)/2 = n^2(n+1)/2.

Similarly, if I perform column operations on all columns, the sum would be the same.

But since operations can overwrite each other, perhaps I can do a combination of row and column operations to get a higher sum.

Wait, but in reality, overwriting might not help because the overwrite would set some cells to lower values.

Actually, no. If I set a row to a permutation and then set a column that intersects with that row, the cell at the intersection will be set to the value from the column operation, potentially overwriting a higher value from the row operation.

So, perhaps it's better to separate the operations so that there's minimal overwriting, or strategically overwrite to maximize the sum.

Alternatively, maybe it's optimal to perform operations in such a way that rows and columns are set independently, without overwriting each other.

Wait, but in practice, it's impossible to set rows and columns without overwriting the cells at their intersections.

So, perhaps I need to accept that some overwriting will occur and find a way to maximize the sum given that.

Let me consider a small example, say n=2.

If I perform row operations on both rows, setting them to permutations [1,2] and [2,1], the matrix would be:

1 2

2 1

Sum is 1+2+2+1=6.

Alternatively, if I perform column operations on both columns, setting them to permutations [1,2] and [2,1], the matrix would be:

1 2

2 1

Same sum as above.

If I perform one row operation and one column operation, for example, set row 1 to [2,1] and then set column 1 to [2,1], the matrix becomes:

2 1

1 1

Sum is 2+1+1+1=5, which is less than 6.

Alternatively, set row 1 to [2,1] and column 2 to [2,1], resulting in:

2 2

1 1

Sum is 2+2+1+1=6.

So, same sum as before.

Seems like in this case, performing operations on all rows or all columns gives the maximum sum.

Wait, but according to the example in the problem, for n=2, the maximum sum is 7, not 6.

Wait, in the example, they show a sequence of operations that results in sum 7.

Let me look back at the example.

In the second test case of the example, n=2, and they perform 3 operations to get sum 7.

Wait, but in my earlier calculation, I only got sum 6 with 2 operations. So, apparently, using an extra operation allows increasing the sum to 7.

Let me see their operations:

Operation 1: Type 1 on row 1 with permutation [1,2]. So, a[1][1]=1, a[1][2]=2.

Operation 2: Type 1 on row 2 with permutation [1,2]. So, a[2][1]=1, a[2][2]=2.

Operation 3: Type 2 on column 1 with permutation [1,2]. So, a[1][1]=1, a[2][1]=2.

After these operations, the matrix is:

a[1][1]=1 (set by operation 3)

a[1][2]=2 (set by operation 1)

a[2][1]=2 (set by operation 3)

a[2][2]=2 (set by operation 2)

So, sum is 1+2+2+2=7.

Indeed, higher than 6.

So, by performing operations on both rows and columns, and accepting overwriting, we can achieve a higher sum.

In this case, performing operations on both rows and columns, with column operations potentially overwriting row operations, allows setting more cells to higher values.

So, perhaps the strategy is to perform operations on all rows and some columns, or vice versa.

But how to determine which rows and columns to operate on?

Let me think about the contributions.

Each row operation sets a row to a permutation, contributing sum(n(n+1)/2) for that row.

Similarly, each column operation sets a column to a permutation, contributing sum(n(n+1)/2) for that column.

But since operations can overwrite each other, the total sum isn't just the sum of individual contributions.

In particular, for cells where both a row operation and a column operation have been performed, the value will be set by the last operation.

So, if I perform operations on r rows and c columns, with some overwriting, what's the total sum?

It's complex to calculate directly, so maybe there's a smarter way.

Perhaps I can think in terms of which cells are set by row operations and which by column operations.

Specifically, if a cell is only set by a row operation, its value is whatever was set by that row operation.

If it's only set by a column operation, its value is from that column operation.

If it's set by both, its value is from the last operation performed.

To maximize the sum, I should aim to set as many cells as possible to the highest values, possibly by having column operations set higher values in cells that were previously set by row operations to lower values.

Wait, perhaps it's better to perform row operations first, setting lower values, and then use column operations to set higher values in specific cells.

But this seems too vague. Maybe I need a different approach.

Let me consider the maximum possible sum achievable.

Suppose I can set each cell to n, but due to the permutation constraint, I can't do that directly.

Alternatively, perhaps I can set some cells to n, some to n-1, and so on, in a way that respects the permutation constraints.

But this seems too vague. Maybe I need to think in terms of linear algebra or some combinatorial optimization.

Wait, perhaps I can model this as a maximum flow or some assignment problem, but that might be too complicated for this context.

Let me consider the dual perspective.

Each row operation allows me to set a row to any permutation of 1 to n.

Similarly for column operations.

I need to maximize the sum of the matrix, which is equivalent to maximizing the sum of all row and column operations, minus the overwrites.

But this seems tricky.

Maybe I can consider that each row operation sets a row, and each column operation sets a column, and the cell at their intersection is set by the last operation.

So, perhaps I can think of the matrix as being built by combining row and column operations, with column operations overwriting row operations in the intersection cells.

Wait, perhaps it's better to fix the order of operations.

Suppose I first perform all row operations, and then all column operations.

In this case, the cells in the columns that have a column operation will be set by the column operation, overwriting any value set by the row operations.

So, the cells not covered by any column operation will have the values set by the row operations.

To maximize the sum, I need to choose which columns to operate on to maximize the sum of the matrix.

But this still seems complicated.

Maybe I need to find a way to cover the matrix with row and column operations such that the sum is maximized, without worrying too much about overwrites.

Wait, perhaps there's a formula or a pattern here.

Let me consider the sum contributed by row operations and column operations.

Each row operation contributes sum of a permutation, which is n(n+1)/2.

Similarly for column operations.

But since column operations overwrite row operations in the intersection cells, I need to account for that.

Wait, maybe inclusion-exclusion can help here.

If I perform r row operations and c column operations, the total sum would be r * n(n+1)/2 + c * n(n+1)/2 - c * r * (n+1)/2.

Wait, why subtract c * r * (n+1)/2?

Because for each intersection of a row operation and a column operation, the cell is set by the column operation, so the contribution from the row operation is overwritten.

So, the formula would be:

sum = (r * n + c * n - c * r) * (n+1)/2

Wait, no.

Actually, each row operation contributes n(n+1)/2, each column operation contributes n(n+1)/2, but the intersections are counted twice, so we need to subtract the overlap.

Wait, but in reality, the overlap is that the cell is set by the column operation, so the row operation's contribution for that cell is lost.

So, for each cell where both a row operation and a column operation are performed, the row operation's contribution is overwritten.

Therefore, the total sum is:

sum = (r * n + c * n - r * c) * (n+1)/2

Because for the r * c intersections, the row operation's contribution is overwritten.

Wait, but this seems simplistic. Maybe I need to think differently.

Alternatively, perhaps I should consider that performing operations on r rows and c columns, the sum is:

sum = r * n(n+1)/2 + c * n(n+1)/2 - r * c * (n+1)/2

But I'm not sure if this is accurate.

Let me test this with the n=2 example.

In the example, r=2 rows and c=1 column, so sum = 2*2*3/2 + 1*2*3/2 - 2*1*3/2 = 6 + 3 - 3 = 6, but in the example, they achieved 7 with r=2 and c=1.

So, my formula is giving 6, but the actual sum is 7.

Therefore, my formula is incorrect.

Perhaps a different approach is needed.

Let me think about the maximum sum achievable.

Each cell can be set to at most n, but due to the permutation constraints, I can't set all cells to n.

Wait, actually, I can set some cells to n, but I have to ensure that in each row and each column, the values form a permutation.

Wait, no, the operations set entire rows or columns to permutations, but multiple operations can be performed, overwriting previous values.

So, perhaps I need to think in terms of how many operations I perform on rows and columns.

Let me consider performing operations on r rows and c columns, with r + c <= 2n.

But actually, the problem allows up to 2n operations, which could be any combination of row and column operations.

So, r + c <= 2n.

But I need to maximize the sum given these operations.

Wait, perhaps I can fix the number of operations and try to maximize the sum.

But that seems too vague.

Let me consider that each operation sets a row or a column to a permutation of 1 to n.

So, the sum contributed by a row operation is the sum of the permutation, which is n(n+1)/2.

Similarly for a column operation.

But again, with overwriting, it's not straightforward to calculate the total sum.

Maybe I need to consider that the sum is the sum of the maximum values that can be set in each cell, considering the operations performed.

Wait, perhaps duality can help here.

Each cell can be set by either a row operation or a column operation, whichever was performed last.

So, the value in each cell is determined by the last operation that set that cell.

Therefore, to maximize the sum, I need to set as many cells as possible to the highest possible values, by choosing the operations that set those values.

But how?

Perhaps I can think in terms of assigning operations to maximize the minimum values, but that seems off.

Wait, maybe I should look for an upper bound on the sum and then see if it's achievable.

What's the maximum possible sum?

If I could set each cell to n, the sum would be n^3.

But due to the permutation constraints, that's not possible.

Alternatively, perhaps the maximum sum is n * n * (n+1)/2, but in the example, n=2, n^2(n+1)/2 = 4*3/2=6, but they achieved 7.

Wait, that can't be.

Wait, n=2, n^2(n+1)/2=8*3/2=12, but in the example, they achieved 7.

Wait, no, n^2(n+1)/2 for n=2 is 4*3/2=6, but in the example, they achieved 7.

Wait, perhaps my formula is incorrect.

Wait, n^2(n+1)/2 would be the sum if all rows are set to permutations, without any column operations.

But in the example, by performing column operations, they were able to increase the sum beyond that.

So, perhaps the upper bound is higher.

Wait, maybe the upper bound is n * n * n = n^3.

But in the n=2 example, n^3=8, and they achieved 7, which is less than 8.

Wait, but in their operations, they set some cells to 2, which is n=2, but not all cells to 2.

So, perhaps n^3 is not achievable.

Wait, but n^3 would be achievable if all cells could be set to n, but due to permutation constraints, that's not possible.

So, perhaps the maximum sum is less than n^3.

Alternatively, maybe it's n * n * (n+1)/2, but in the example, that's 6, and they achieved 7, which is higher.

Wait, that doesn't make sense.

Wait, n=2, n^2=4, sum of permutation is 3, so 4*3/2=6, but they achieved 7.

So, perhaps my understanding is incomplete.

Maybe I need to consider that column operations can set cells to higher values, overwriting row operations.

So, perhaps the maximum sum is higher than n * n * (n+1)/2.

Wait, perhaps it's n * n * n, but again, in n=2, that's 8, but they achieved 7, which is less than 8.

Wait, but in their operations, they set three cells to 2 and one cell to 1, totaling 7.

If they could set all four cells to 2, that would be 8, but perhaps that's not possible due to permutation constraints.

Wait, if I try to set both rows to [2,2], but that's not a permutation, because permutations must have distinct elements.

Similarly for columns.

So, I can't set all cells to n due to the permutation constraint.

Therefore, the maximum sum achievable is less than n^3.

But in the n=2 example, they achieved 7, which is higher than n^2(n+1)/2=6, so there must be a better way.

Let me think differently.

Suppose I perform row operations on some rows and column operations on some columns.

Each row operation sets a row to a permutation, and each column operation sets a column to a permutation, overwriting the cells at the intersections.

So, for cells that are set by both a row operation and a column operation, the value is set by the last operation.

To maximize the sum, perhaps I should aim to set as many cells as possible to n, then to n-1, and so on.

But due to the permutation constraints, I can't have all cells set to n.

Wait, perhaps I can calculate the maximum sum by considering that each operation can set a row or a column to a permutation, and the last operation on each cell determines its value.

So, perhaps I can model this as a graph where rows and columns are vertices, and operations are edges, but that might be too abstract.

Alternatively, perhaps I can consider that performing operations on r rows and c columns allows me to set the matrix to a combination of these operations, with column operations overwriting row operations in their intersections.

So, the sum would be the sum over all cells of the value set by the last operation that set that cell.

To maximize this sum, I need to choose r and c such that the sum is maximized.

But how to choose r and c?

Wait, perhaps there's a formula for the maximum sum in terms of n.

Looking back at the example, for n=1, sum=1.

For n=2, sum=7.

For n=3, what would be the sum?

Let me try n=3.

If I perform row operations on all three rows, setting them to permutations like [3,2,1], [3,2,1], [3,2,1], the sum would be 3+2+1 + 3+2+1 + 3+2+1 = 3*6 = 18.

Alternatively, if I perform column operations on all three columns, setting them to permutations like [3,2,1], [3,2,1], [3,2,1], the sum would be the same, 18.

But perhaps by combining row and column operations, I can get a higher sum.

For example, perform row operations on two rows and column operations on two columns.

Let's say perform row operations on row 1 and row 2, setting them to [3,2,1] and [3,2,1], then column operations on column 1 and column 3, setting them to [3,2,1] and [3,2,1].

Then, the matrix would be:

Column 1: set by column operation to [3,2,1]

Column 2: set by row operations to [2,2,?]

Column 3: set by column operation to [3,2,1]

Wait, but column operations overwrite row operations in their cells.

So, for column 1, a[1][1]=3, a[2][1]=2, a[3][1]=1

For column 3, a[1][3]=3, a[2][3]=2, a[3][3]=1

For row 1, a[1][1]=3, a[1][2]=2, a[1][3]=3

For row 2, a[2][1]=2, a[2][2]=2, a[2][3]=2

For row 3, a[3][1]=1, a[3][2]=?, a[3][3]=1

Wait, but row 3 was not set by a row operation, so it remains [0,0,0], unless column operations set some of its cells.

So, a[3][1]=1 (from column 1), a[3][3]=1 (from column 3), and a[3][2]=0.

So, the sum would be 3+2+3 + 2+2+2 + 1+0+1 = 3+2+3 + 2+2+2 + 1+0+1 = 10 + 6 + 2 = 18.

Same as before.

Alternatively, perform row operations on all three rows and column operations on one column.

So, perform row operations on rows 1,2,3 with permutations [3,2,1], [3,2,1], [3,2,1], then column operation on column 1 with permutation [3,2,1].

Then, the matrix would be:

a[1][1]=3 (set by column operation)

a[1][2]=2 (set by row operation)

a[1][3]=1 (set by row operation)

a[2][1]=2 (set by column operation)

a[2][2]=2 (set by row operation)

a[2][3]=1 (set by row operation)

a[3][1]=1 (set by column operation)

a[3][2]=2 (set by row operation)

a[3][3]=1 (set by row operation)

Sum: 3+2+1 + 2+2+1 + 1+2+1 = 6 + 6 + 4 = 16.

Which is less than 18.

So, perhaps performing operations on all rows and some columns doesn't always increase the sum.

Wait, but in the n=2 example, performing operations on both rows and one column gave a higher sum than operating on just rows or just columns.

So, perhaps it depends on the specific combination.

This is getting complicated.

Maybe I need to find a general formula for the maximum sum.

Let me consider that each operation (row or column) can set n cells to a permutation of 1 to n, contributing n(n+1)/2 to the sum, but with potential overwrites.

Alternatively, perhaps the maximum sum is achieved when the number of row operations plus the number of column operations is minimized while covering as much of the high values as possible.

But that seems too vague.

Wait, perhaps I can think in terms of the number of operations.

Since we're allowed up to 2n operations, perhaps performing n row operations and n column operations would be optimal.

But in the n=2 example, they used 3 operations to get sum 7, which is better than using 4 operations.

Wait, but 2n for n=2 is 4 operations, but they used only 3 to get 7.

So, perhaps performing 2n operations doesn't necessarily give the maximum sum.

Wait, but the problem says that it's always possible to achieve the maximum sum in no more than 2n operations.

So, perhaps I need to find what that maximum sum is.

Let me consider that each operation can set n cells to a permutation, and the last operation on each cell determines its value.

So, if I perform r row operations and c column operations, with r + c <= 2n, then the sum would be the sum over all cells of the value set by the last operation that set that cell.

This seems too vague to compute directly.

Maybe I need to look for a different approach.

Let me consider the dual problem.

Suppose I fix the values in the matrix and see how many operations are needed to set them.

But that seems too involved.

Alternatively, perhaps I can think in terms of the sum contributed by row operations and column operations, taking into account the overwrites.

Wait, perhaps I can calculate the sum as follows:

sum = sum of values set by row operations + sum of values set by column operations - sum of values set by both row and column operations.

Because the column operations overwrite the row operations in the intersection cells.

So, sum = sum_row + sum_col - sum_row_col

Where sum_row is the sum of values set by row operations,

sum_col is the sum of values set by column operations,

and sum_row_col is the sum of values in the cells that are set by both row and column operations.

But sum_row_col is equal to the sum of values set by row operations in the cells that are also set by column operations.

But since column operations overwrite row operations, sum_row_col is actually the sum of values set by column operations in those cells.

Wait, no.

Actually, sum_row_col is the sum of values that would have been set by row operations in the cells that are also set by column operations, but since column operations overwrite, those values are actually set by column operations.

So, sum_row_col = sum of values set by row operations in cells not overwritten by column operations + sum of values set by column operations in cells that overwrite row operations.

Wait, this is getting too convoluted.

Perhaps I need to accept that calculating the exact sum for arbitrary r and c is too difficult and look for a better approach.

Let me consider that in order to maximize the sum, I should aim to set as many cells as possible to the highest values, n, n-1, etc., respecting the permutation constraints.

Given that, perhaps the maximum sum is achieved when the matrix is filled with the highest possible values, given the permutation constraints.

Wait, but what's the highest possible sum under these constraints?

Perhaps it's the sum of the maximum possible values that can be assigned to each cell, considering the permutations for rows and columns.

This sounds like the problem of finding the maximum weight matching in a bipartite graph, where one partition represents rows and the other represents columns.

Wait, perhaps it's related to the assignment problem.

In the assignment problem, we assign tasks to workers to maximize the total weight.

Similarly, here, we need to assign values to cells, respecting the permutation constraints for rows and columns.

This seems promising.

So, perhaps I can model this as an assignment problem where I need to assign values to cells, ensuring that each row and each column contains a permutation of 1 to n.

Wait, but the operations allow setting entire rows or columns to permutations, not individual cells.

So, perhaps I need to think in terms of covering the matrix with row and column operations.

Wait, maybe it's similar to covering the matrix with row and column operations, where each operation sets a row or column to a permutation.

Given that, perhaps the maximum sum can be calculated based on the number of row and column operations performed.

But I still need a way to compute this.

Let me consider that performing r row operations and c column operations, with r + c <= 2n.

Then, the sum would be sum_row + sum_col - sum_overlap, where sum_row is the sum of values set by row operations, sum_col is the sum of values set by column operations, and sum_overlap is the sum of values in the cells where both operations set the value, with the column operation overwriting the row operation.

So, sum = sum_row + sum_col - sum_overlap.

But I need to maximize this sum.

To maximize sum, I need to maximize sum_row + sum_col - sum_overlap.

Given that sum_row and sum_col are both sums of permutations, but sum_overlap is the sum of values in the overlapping cells.

Wait, perhaps I can think of sum_overlap as the sum of values set by row operations in the cells that are also set by column operations.

But since column operations overwrite these, sum_overlap is actually the sum of values set by column operations in those cells.

Wait, I'm getting stuck here.

Maybe I need to consider that the sum is equal to the sum of the values set by the last operations that set each cell.

So, for each cell, its value is determined by the last operation that set it, whether a row operation or a column operation.

Therefore, the sum is the sum over all cells of the value set by the last operation that set that cell.

To maximize this sum, I need to choose operations that set as many cells as possible to high values.

But this is still too vague.

Perhaps I need to accept that finding the exact formula is difficult and look for a pattern or a different approach.

Let me consider that performing operations on rows and columns allows me to set the matrix to a combination of these operations.

Specifically, the matrix can be seen as the sum of the row operations and column operations, minus the overlaps.

Wait, but that's similar to what I thought before.

Alternatively, perhaps I can think of the matrix as being the sum of the row operations and the column operations, minus the Hadamard product of the row and column operations.

But this seems too complicated.

Maybe I need to consider specific cases to find a pattern.

Let me consider n=1.

For n=1, the matrix is 1x1.

Performing a row operation sets the cell to 1.

Performing a column operation sets the cell to 1.

So, the maximum sum is 1, achieved with either one row operation or one column operation.

Now, n=2.

From the example, the maximum sum is 7, achieved with 3 operations.

What if I perform operations on both rows and one column, as in the example.

Is there a better way?

Let me try performing operations on both rows and both columns.

Perform row operations on row 1 and row 2, setting them to [2,1] and [2,1].

Then, perform column operations on column 1 and column 2, setting them to [2,1] and [2,1].

The matrix would be:

a[1][1]=2 (set by column operation)

a[1][2]=2 (set by column operation)

a[2][1]=1 (set by column operation)

a[2][2]=1 (set by column operation)

Sum: 2+2+1+1=6.

But in the example, they achieved 7 with 3 operations.

So, performing operations on both rows and both columns gives sum 6, which is less than 7.

Wait, that's interesting.

So, perhaps performing operations on all rows and all columns doesn't give the maximum sum.

Alternatively, performing operations on both rows and one column gives sum 7.

So, perhaps the maximum sum is achieved when the number of column operations is less than n.

Wait, perhaps there's a trade-off between the number of row and column operations.

Let me consider performing operations on r rows and c columns, with r + c <= 2n.

I need to maximize the sum based on this.

But I need a general formula.

Wait, perhaps the maximum sum is n * n * n, but due to permutation constraints, it's not achievable.

Alternatively, perhaps it's n * n * (n+1)/2 + something.

Wait, in the n=2 example, n * n * (n+1)/2 = 4 * 3 / 2 = 6, but they achieved 7.

So, perhaps it's n * n * (n+1)/2 + (n - 1) * n / 2 or something.

Wait, for n=2, that would be 6 + (2-1)*2/2 = 6 + 1 = 7, which matches the example.

For n=3, it would be 9*4/2 + (3-1)*3/2 = 18 + 3 = 21.

Is that the maximum sum for n=3?

Let me see.

If I perform row operations on all three rows, setting them to [3,2,1], sum per row is 6, total 18.

If I perform column operations on two columns, setting them to [3,2,1], sum per column is 6, but with overwriting.

Wait, let's say perform row operations on rows 1,2,3, and column operations on columns 1 and 2.

Then, the matrix would be:

Column 1: set by column operation to [3,2,1]

Column 2: set by column operation to [3,2,1]

Row 1: set by row operation to [3,2,1], but column operations have already set columns 1 and 2 to 3 and 3, so a[1][1]=3 (from column), a[1][2]=3 (from column), a[1][3]=1 (from row)

Row 2: set by row operation to [3,2,1], but columns 1 and 2 set to 2 and 2, so a[2][1]=2, a[2][2]=2, a[2][3]=1

Row 3: set by row operation to [3,2,1], but columns 1 and 2 set to 1 and 1, so a[3][1]=1, a[3][2]=1, a[3][3]=1

Sum: a[1][1]=3, a[1][2]=3, a[1][3]=1

a[2][1]=2, a[2][2]=2, a[2][3]=1

a[3][1]=1, a[3][2]=1, a[3][3]=1

Total sum: 3+3+1 + 2+2+1 + 1+1+1 = 7 + 6 + 3 = 16, which is less than 21.

Wait, but according to the formula, it should be 21.

So, perhaps my formula is incorrect.

Alternatively, perhaps the formula is n * n * n - (n - r)(n - c), but I'm not sure.

This is getting too complicated.

Maybe I need to accept that finding a general formula is difficult and look for a different approach.

Let me consider that in each operation, I can set a row or a column to a permutation of 1 to n, and I can choose which permutation to use.

To maximize the sum, I should aim to set as many cells as possible to the highest values.

Given that, perhaps I should perform row operations to set the highest possible values in the rows, and column operations to set the highest possible values in the columns.

But due to the permutation constraints, I can't just set all cells to n.

Alternatively, perhaps I can prioritize setting the main diagonal to n, then the next highest values elsewhere.

But this seems too vague.

Maybe I need to accept that finding the exact maximum sum is difficult and look for a bound.

Wait, perhaps the maximum sum is n * n * (n+1)/2 + (n - 1) * n / 2, as I thought earlier for n=2.

But for n=3, that would be 9*4/2 + (3-1)*3/2 = 18 + 3 = 21.

But in my earlier calculation, performing operations on all three rows and two columns gave a sum of 16, which is less than 21.

So, perhaps there's a better way to achieve 21.

Let me think differently.

Suppose I perform row operations on all rows, setting them to [n, n-1, ..., 1], and then perform column operations on the first n-1 columns, setting them to [n, n-1, ..., 1].

Then, the matrix would have:

- For columns 1 to n-1: set by column operations to [n, n-1, ..., 1]

- For column n: set by row operations to [n, n-1, ..., 1]

So, the sum would be:

sum = sum of column operations on n-1 columns + sum of row operations on column n

sum = (n-1) * n(n+1)/2 + n(n+1)/2 = n(n+1)/2 * n = n^2(n+1)/2

Wait, for n=2, that would be 4*3/2 = 6, but the example shows 7.

So, this doesn't match.

Alternatively, perhaps it's n^2(n+1)/2 - some adjustment.

But I'm getting stuck.

Maybe I need to consider that the maximum sum is achieved when the matrix is filled with the highest possible values, given the permutation constraints.

Given that, perhaps the maximum sum is the sum of the n largest possible values repeated in a way that satisfies the permutations.

But this seems too vague.

Wait, perhaps the maximum sum is n * n * n - the sum of the first n - r numbers, where r is the number of row operations.

But I'm not sure.

Alternatively, perhaps the maximum sum is n * n * n - the minimal sum of the cells that are not set to n.

But this seems too vague.

Maybe I need to accept that finding the exact formula is difficult and look for a different approach.

Let me consider that each operation can set n cells to a permutation, and that operations can overwrite each other.

Given that, perhaps the maximum sum is achieved when as many cells as possible are set by column operations, since columns can be set independently of rows.

Wait, but in reality, column operations overwrite row operations in their intersection cells.

So, perhaps performing operations on all rows and then on all columns would set all cells to the values from the column operations.

But in that case, the sum would be the sum of the column operations, which is n times the sum of a permutation, i.e., n * n(n+1)/2 = n^2(n+1)/2.

But in the n=2 example, that would be 4*3/2=6, but they achieved 7 with fewer operations.

So, perhaps performing operations on all columns and some rows can give a higher sum.

Wait, but in the n=2 example, performing operations on both rows and one column gave sum 7.

So, perhaps the formula is sum = n * n * n - (n - c) * n, where c is the number of column operations.

Wait, for n=2 and c=1, sum = 8 - (2-1)*2 = 8 - 2 = 6, but they achieved 7.

So, that doesn't match.

Alternatively, perhaps sum = n * n * n - (n - c)(n - r), where r is the number of row operations and c is the number of column operations.

For n=2, r=2, c=1: sum = 8 - (2-1)(2-2) = 8 - 1*0 = 8, but in reality, it's 7.

So, still not matching.

Perhaps I need to abandon this approach.

Let me consider that the maximum sum is achieved when the matrix is filled with the highest possible values, given the constraints.

Given that, perhaps the maximum sum is the sum of the n largest numbers repeated in a way that satisfies the permutations.

But I need a better approach.

Wait, perhaps I can think in terms of linear algebra.

If I consider the matrix as the sum of matrices from row operations and column operations, but again, with overwriting, it's not a simple sum.

This seems too complicated.

Maybe I need to look for a different strategy.

Let me consider that each operation (row or column) can set n cells to a permutation, and that operations can overwrite each other.

Given that, perhaps the maximum sum is achieved when the operations are chosen such that the overwriting sets higher values over lower values.

So, perhaps performing row operations first with lower values and then column operations with higher values on some columns.

But this is too vague.

Alternatively, perhaps performing row operations with higher values and column operations with higher values on specific columns.

But again, too vague.

Maybe I need to accept that finding the exact formula is difficult and look for a different approach.

Let me consider that the maximum sum is n * n * n - the minimal sum of the cells that must be set to less than n.

Given the permutation constraints, in each row and column, there must be one cell set to n, one to n-1, and so on.

But this seems too vague.

Alternatively, perhaps the maximum sum is n * n * n - n * (n+1)/2.

But for n=2, that would be 8 - 3 = 5, which is less than the achieved sum of 7.

So, that doesn't make sense.

Alternatively, perhaps it's n * n * n - (n - c)(n - r), where r and c are the number of row and column operations.

But earlier, that didn't match.

Maybe I need to think differently.

Let me consider that each row operation sets a row to a permutation, and each column operation sets a column to a permutation, overwriting the row operations in the intersection cells.

So, the sum is the sum of the values set by the last operations that set each cell.

To maximize this sum, perhaps I should perform row operations with higher permutations first, and then column operations that set even higher values in specific cells.

But due to the permutation constraints, I can't set all cells to high values.

This seems too vague.

Maybe I need to accept that finding the exact formula is difficult and look for a different approach.

Let me consider that the maximum sum is achieved when I perform operations on all rows and some columns, choosing the columns to maximize the sum.

But I need a way to calculate this.

Alternatively, perhaps the maximum sum is n * n * n - the sum of the first n - c numbers, where c is the number of column operations.

But in the n=2 example, that would be 8 - (2-1)*3/2=8-1.5=6.5, which doesn't make sense.

Wait, perhaps I need to think in terms of the number of operations.

Given that I can perform up to 2n operations, perhaps the maximum sum is achieved when I perform operations on all rows and some columns.

But I need a general formula.

Wait, perhaps the maximum sum is n * n * n - (n - c)(n - r), where r is the number of row operations and c is the number of column operations.

For n=2, r=2, c=1: sum=8 - (2-1)(2-2)=8-1*0=8, but in reality, it's 7.

So, still not matching.

Alternatively, perhaps it's n * n * n - (n - c)(n - r) * something.

I'm stuck.

Maybe I need to accept that finding a general formula is too difficult and look for a different approach.

Let me consider that the maximum sum is achieved when I perform operations on all rows and a certain number of columns, and calculate the sum based on that.

Wait, perhaps the sum is sum = r * n(n+1)/2 + c * n(n+1)/2 - r * c * (n+1)/2

But earlier, for n=2, r=2, c