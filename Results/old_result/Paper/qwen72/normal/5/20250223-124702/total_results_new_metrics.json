{
    "total_valid_rows": {
        "value": 91,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "54",
        "agreement_percentage": 59.34065934065934,
        "mcc": 0.20440158894881794,
        "accuracy": 0.5934065934065934,
        "precision": 0.8333333333333334,
        "recall": 0.12195121951219512,
        "f1_score": 0.21276595744680848,
        "balanced_accuracy": 0.5509756097560976,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "57",
        "agreement_percentage": 62.637362637362635,
        "mcc": 0.291869918699187,
        "accuracy": 0.6263736263736264,
        "precision": 0.8888888888888888,
        "recall": 0.1951219512195122,
        "f1_score": 0.32,
        "balanced_accuracy": 0.5875609756097561,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "57",
        "agreement_percentage": 62.637362637362635,
        "mcc": 0.24227915096406855,
        "accuracy": 0.6263736263736264,
        "precision": 0.5897435897435898,
        "recall": 0.5609756097560976,
        "f1_score": 0.575,
        "balanced_accuracy": 0.6204878048780489,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "58",
        "agreement_percentage": 63.73626373626373,
        "mcc": 0.2692312797534438,
        "accuracy": 0.6373626373626373,
        "precision": 0.5952380952380952,
        "recall": 0.6097560975609756,
        "f1_score": 0.6024096385542169,
        "balanced_accuracy": 0.6348780487804878,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "52",
        "agreement_percentage": 57.14285714285714,
        "mcc": 0.14924733963196382,
        "accuracy": 0.5714285714285714,
        "precision": 0.5208333333333334,
        "recall": 0.6097560975609756,
        "f1_score": 0.5617977528089888,
        "balanced_accuracy": 0.5748780487804879,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "57",
        "agreement_percentage": 62.637362637362635,
        "mcc": 0.23567697004315166,
        "accuracy": 0.6263736263736264,
        "precision": 0.6521739130434783,
        "recall": 0.36585365853658536,
        "f1_score": 0.46874999999999994,
        "balanced_accuracy": 0.6029268292682927,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "54",
        "agreement_percentage": 59.34065934065934,
        "mcc": 0.17372728866988663,
        "accuracy": 0.5934065934065934,
        "precision": 0.5526315789473685,
        "recall": 0.5121951219512195,
        "f1_score": 0.5316455696202531,
        "balanced_accuracy": 0.5860975609756098,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "54",
        "agreement_percentage": 59.34065934065934,
        "mcc": 0.1770176440178758,
        "accuracy": 0.5934065934065934,
        "precision": 0.55,
        "recall": 0.5365853658536586,
        "f1_score": 0.54320987654321,
        "balanced_accuracy": 0.5882926829268293,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "55",
        "agreement_percentage": 60.43956043956044,
        "mcc": 0.20097560975609757,
        "accuracy": 0.6043956043956044,
        "precision": 0.5609756097560976,
        "recall": 0.5609756097560976,
        "f1_score": 0.5609756097560976,
        "balanced_accuracy": 0.6004878048780489,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "60",
        "agreement_percentage": 65.93406593406593,
        "mcc": 0.30808295384518136,
        "accuracy": 0.6593406593406593,
        "precision": 0.631578947368421,
        "recall": 0.5853658536585366,
        "f1_score": 0.6075949367088608,
        "balanced_accuracy": 0.6526829268292682,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "66",
        "agreement_percentage": 72.52747252747253,
        "mcc": 0.4688054946958971,
        "accuracy": 0.7252747252747253,
        "precision": 0.8636363636363636,
        "recall": 0.4634146341463415,
        "f1_score": 0.6031746031746033,
        "balanced_accuracy": 0.7017073170731707,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "59",
        "agreement_percentage": 64.83516483516483,
        "mcc": 0.2838256233657132,
        "accuracy": 0.6483516483516484,
        "precision": 0.68,
        "recall": 0.4146341463414634,
        "f1_score": 0.5151515151515151,
        "balanced_accuracy": 0.6273170731707317,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "60",
        "agreement_percentage": 65.93406593406593,
        "mcc": 0.3140486627104317,
        "accuracy": 0.6593406593406593,
        "precision": 0.7272727272727273,
        "recall": 0.3902439024390244,
        "f1_score": 0.5079365079365079,
        "balanced_accuracy": 0.6351219512195122,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}