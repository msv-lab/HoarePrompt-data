{
    "total_valid_rows": {
        "value": 289,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "140",
        "agreement_percentage": 48.44290657439446,
        "mcc": 0.10446580380506297,
        "accuracy": 0.4844290657439446,
        "precision": 0.7058823529411765,
        "recall": 0.147239263803681,
        "f1_score": 0.2436548223350254,
        "balanced_accuracy": 0.5339370922193007,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "146",
        "agreement_percentage": 50.51903114186851,
        "mcc": 0.12118590486940818,
        "accuracy": 0.5051903114186851,
        "precision": 0.6923076923076923,
        "recall": 0.22085889570552147,
        "f1_score": 0.33488372093023255,
        "balanced_accuracy": 0.5469373843606973,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "178",
        "agreement_percentage": 61.5916955017301,
        "mcc": 0.20345948065613279,
        "accuracy": 0.615916955017301,
        "precision": 0.6368421052631579,
        "recall": 0.7423312883435583,
        "f1_score": 0.6855524079320113,
        "balanced_accuracy": 0.5973561203622554,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "178",
        "agreement_percentage": 61.5916955017301,
        "mcc": 0.19818372219495073,
        "accuracy": 0.615916955017301,
        "precision": 0.6274509803921569,
        "recall": 0.7852760736196319,
        "f1_score": 0.6975476839237058,
        "balanced_accuracy": 0.5910507352225144,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "171",
        "agreement_percentage": 59.16955017301038,
        "mcc": 0.13968417845773692,
        "accuracy": 0.5916955017301038,
        "precision": 0.6046511627906976,
        "recall": 0.7975460122699386,
        "f1_score": 0.6878306878306878,
        "balanced_accuracy": 0.561471418833382,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "158",
        "agreement_percentage": 54.67128027681662,
        "mcc": 0.13341775057895433,
        "accuracy": 0.5467128027681661,
        "precision": 0.6509433962264151,
        "recall": 0.4233128834355828,
        "f1_score": 0.5130111524163569,
        "balanced_accuracy": 0.5648310448923946,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "172",
        "agreement_percentage": 59.515570934256054,
        "mcc": 0.16909789220315694,
        "accuracy": 0.5951557093425606,
        "precision": 0.632183908045977,
        "recall": 0.6748466257668712,
        "f1_score": 0.6528189910979229,
        "balanced_accuracy": 0.5834550589151816,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "171",
        "agreement_percentage": 59.16955017301038,
        "mcc": 0.14920667788243727,
        "accuracy": 0.5916955017301038,
        "precision": 0.6153846153846154,
        "recall": 0.7361963190184049,
        "f1_score": 0.670391061452514,
        "balanced_accuracy": 0.5704791118901549,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "172",
        "agreement_percentage": 59.515570934256054,
        "mcc": 0.153171724943501,
        "accuracy": 0.5951557093425606,
        "precision": 0.6138613861386139,
        "recall": 0.7607361963190185,
        "f1_score": 0.6794520547945205,
        "balanced_accuracy": 0.5708442886356997,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "171",
        "agreement_percentage": 59.16955017301038,
        "mcc": 0.15868097904569511,
        "accuracy": 0.5916955017301038,
        "precision": 0.6256983240223464,
        "recall": 0.6871165644171779,
        "f1_score": 0.6549707602339181,
        "balanced_accuracy": 0.5776852663355732,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "161",
        "agreement_percentage": 55.70934256055363,
        "mcc": 0.18794796185416587,
        "accuracy": 0.5570934256055363,
        "precision": 0.7108433734939759,
        "recall": 0.3619631901840491,
        "f1_score": 0.47967479674796737,
        "balanced_accuracy": 0.5857434998539293,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "164",
        "agreement_percentage": 56.747404844290664,
        "mcc": 0.20267784063708577,
        "accuracy": 0.5674740484429066,
        "precision": 0.7159090909090909,
        "recall": 0.38650306748466257,
        "f1_score": 0.5019920318725101,
        "balanced_accuracy": 0.5940451845359821,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "166",
        "agreement_percentage": 57.43944636678201,
        "mcc": 0.20232679602210663,
        "accuracy": 0.5743944636678201,
        "precision": 0.7040816326530612,
        "recall": 0.4233128834355828,
        "f1_score": 0.528735632183908,
        "balanced_accuracy": 0.5965770766384264,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}