{
    "total_valid_rows": {
        "value": 21,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "9",
        "agreement_percentage": 42.857142857142854,
        "mcc": 0.17541160386140586,
        "accuracy": 0.42857142857142855,
        "precision": 1.0,
        "recall": 0.07692307692307693,
        "f1_score": 0.14285714285714288,
        "balanced_accuracy": 0.5384615384615384,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "9",
        "agreement_percentage": 42.857142857142854,
        "mcc": 0.17541160386140586,
        "accuracy": 0.42857142857142855,
        "precision": 1.0,
        "recall": 0.07692307692307693,
        "f1_score": 0.14285714285714288,
        "balanced_accuracy": 0.5384615384615384,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "16",
        "agreement_percentage": 76.19047619047619,
        "mcc": 0.4823819106188661,
        "accuracy": 0.7619047619047619,
        "precision": 0.75,
        "recall": 0.9230769230769231,
        "f1_score": 0.8275862068965517,
        "balanced_accuracy": 0.7115384615384616,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "14",
        "agreement_percentage": 66.66666666666666,
        "mcc": 0.2401922307076307,
        "accuracy": 0.6666666666666666,
        "precision": 0.6666666666666666,
        "recall": 0.9230769230769231,
        "f1_score": 0.7741935483870968,
        "balanced_accuracy": 0.5865384615384616,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "14",
        "agreement_percentage": 66.66666666666666,
        "mcc": 0.2850438562747845,
        "accuracy": 0.6666666666666666,
        "precision": 0.65,
        "recall": 1.0,
        "f1_score": 0.787878787878788,
        "balanced_accuracy": 0.5625,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "13",
        "agreement_percentage": 61.904761904761905,
        "mcc": 0.2337367475021143,
        "accuracy": 0.6190476190476191,
        "precision": 0.7272727272727273,
        "recall": 0.6153846153846154,
        "f1_score": 0.6666666666666667,
        "balanced_accuracy": 0.6201923076923077,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "15",
        "agreement_percentage": 71.42857142857143,
        "mcc": 0.3686299079697329,
        "accuracy": 0.7142857142857143,
        "precision": 0.7058823529411765,
        "recall": 0.9230769230769231,
        "f1_score": 0.8000000000000002,
        "balanced_accuracy": 0.6490384615384616,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "14",
        "agreement_percentage": 66.66666666666666,
        "mcc": 0.2401922307076307,
        "accuracy": 0.6666666666666666,
        "precision": 0.6666666666666666,
        "recall": 0.9230769230769231,
        "f1_score": 0.7741935483870968,
        "balanced_accuracy": 0.5865384615384616,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "14",
        "agreement_percentage": 66.66666666666666,
        "mcc": 0.2401922307076307,
        "accuracy": 0.6666666666666666,
        "precision": 0.6666666666666666,
        "recall": 0.9230769230769231,
        "f1_score": 0.7741935483870968,
        "balanced_accuracy": 0.5865384615384616,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "13",
        "agreement_percentage": 61.904761904761905,
        "mcc": 0.11891287353862351,
        "accuracy": 0.6190476190476191,
        "precision": 0.6470588235294118,
        "recall": 0.8461538461538461,
        "f1_score": 0.7333333333333334,
        "balanced_accuracy": 0.5480769230769231,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "9",
        "agreement_percentage": 42.857142857142854,
        "mcc": -0.021926450482675733,
        "accuracy": 0.42857142857142855,
        "precision": 0.6,
        "recall": 0.23076923076923078,
        "f1_score": 0.33333333333333337,
        "balanced_accuracy": 0.4903846153846154,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "11",
        "agreement_percentage": 52.38095238095239,
        "mcc": 0.20830127958541944,
        "accuracy": 0.5238095238095238,
        "precision": 0.8,
        "recall": 0.3076923076923077,
        "f1_score": 0.4444444444444444,
        "balanced_accuracy": 0.5913461538461539,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "11",
        "agreement_percentage": 52.38095238095239,
        "mcc": 0.20830127958541944,
        "accuracy": 0.5238095238095238,
        "precision": 0.8,
        "recall": 0.3076923076923077,
        "f1_score": 0.4444444444444444,
        "balanced_accuracy": 0.5913461538461539,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}