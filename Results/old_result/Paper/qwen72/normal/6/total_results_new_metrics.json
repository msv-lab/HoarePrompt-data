{
    "total_valid_rows": {
        "value": 300,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "162",
        "agreement_percentage": 54.0,
        "mcc": 0.07512080679031063,
        "accuracy": 0.54,
        "precision": 0.6428571428571429,
        "recall": 0.06338028169014084,
        "f1_score": 0.11538461538461538,
        "balanced_accuracy": 0.5158673560349438,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "168",
        "agreement_percentage": 56.00000000000001,
        "mcc": 0.13879297380661929,
        "accuracy": 0.56,
        "precision": 0.7083333333333334,
        "recall": 0.11971830985915492,
        "f1_score": 0.20481927710843376,
        "balanced_accuracy": 0.5377072561954003,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "182",
        "agreement_percentage": 60.66666666666667,
        "mcc": 0.21167041977709067,
        "accuracy": 0.6066666666666667,
        "precision": 0.5833333333333334,
        "recall": 0.5915492957746479,
        "f1_score": 0.5874125874125875,
        "balanced_accuracy": 0.6059012301658049,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "181",
        "agreement_percentage": 60.333333333333336,
        "mcc": 0.20359271181613373,
        "accuracy": 0.6033333333333334,
        "precision": 0.5827338129496403,
        "recall": 0.5704225352112676,
        "f1_score": 0.5765124555160143,
        "balanced_accuracy": 0.6016669638081655,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "172",
        "agreement_percentage": 57.333333333333336,
        "mcc": 0.15744962212005653,
        "accuracy": 0.5733333333333334,
        "precision": 0.5402298850574713,
        "recall": 0.6619718309859155,
        "f1_score": 0.5949367088607594,
        "balanced_accuracy": 0.5778213585309324,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "182",
        "agreement_percentage": 60.66666666666667,
        "mcc": 0.21102113213948281,
        "accuracy": 0.6066666666666667,
        "precision": 0.6395348837209303,
        "recall": 0.3873239436619718,
        "f1_score": 0.48245614035087725,
        "balanced_accuracy": 0.5955607060082011,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "182",
        "agreement_percentage": 60.66666666666667,
        "mcc": 0.20837668660750427,
        "accuracy": 0.6066666666666667,
        "precision": 0.5923076923076923,
        "recall": 0.5422535211267606,
        "f1_score": 0.5661764705882353,
        "balanced_accuracy": 0.6034052415760385,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "179",
        "agreement_percentage": 59.66666666666667,
        "mcc": 0.18877207930021453,
        "accuracy": 0.5966666666666667,
        "precision": 0.5789473684210527,
        "recall": 0.5422535211267606,
        "f1_score": 0.56,
        "balanced_accuracy": 0.5939115706899626,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "179",
        "agreement_percentage": 59.66666666666667,
        "mcc": 0.19074797936669294,
        "accuracy": 0.5966666666666667,
        "precision": 0.574468085106383,
        "recall": 0.5704225352112676,
        "f1_score": 0.5724381625441696,
        "balanced_accuracy": 0.5953378498841149,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "171",
        "agreement_percentage": 56.99999999999999,
        "mcc": 0.13451784855764642,
        "accuracy": 0.57,
        "precision": 0.549618320610687,
        "recall": 0.5070422535211268,
        "f1_score": 0.5274725274725275,
        "balanced_accuracy": 0.5668122660010697,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "164",
        "agreement_percentage": 54.666666666666664,
        "mcc": 0.07672349521701875,
        "accuracy": 0.5466666666666666,
        "precision": 0.5483870967741935,
        "recall": 0.23943661971830985,
        "f1_score": 0.3333333333333333,
        "balanced_accuracy": 0.5311107149224461,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "166",
        "agreement_percentage": 55.333333333333336,
        "mcc": 0.09346635792723798,
        "accuracy": 0.5533333333333333,
        "precision": 0.5666666666666667,
        "recall": 0.23943661971830985,
        "f1_score": 0.3366336633663366,
        "balanced_accuracy": 0.5374398288464967,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "164",
        "agreement_percentage": 54.666666666666664,
        "mcc": 0.07677593686880263,
        "accuracy": 0.5466666666666666,
        "precision": 0.55,
        "recall": 0.2323943661971831,
        "f1_score": 0.3267326732673267,
        "balanced_accuracy": 0.530754145123908,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}