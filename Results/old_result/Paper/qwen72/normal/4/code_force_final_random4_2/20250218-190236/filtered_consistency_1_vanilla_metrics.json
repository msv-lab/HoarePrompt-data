{
    "total_valid_rows": {
        "value": 23,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "11",
        "agreement_percentage": 47.82608695652174,
        "mcc": 0,
        "accuracy": 0.4782608695652174,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "10",
        "agreement_percentage": 43.47826086956522,
        "mcc": -0.22268088570756164,
        "accuracy": 0.43478260869565216,
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.45454545454545453,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "14",
        "agreement_percentage": 60.86956521739131,
        "mcc": 0.22407133233117496,
        "accuracy": 0.6086956521739131,
        "precision": 0.5882352941176471,
        "recall": 0.8333333333333334,
        "f1_score": 0.6896551724137931,
        "balanced_accuracy": 0.5984848484848485,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "15",
        "agreement_percentage": 65.21739130434783,
        "mcc": 0.302407368379503,
        "accuracy": 0.6521739130434783,
        "precision": 0.6428571428571429,
        "recall": 0.75,
        "f1_score": 0.6923076923076924,
        "balanced_accuracy": 0.6477272727272727,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "12",
        "agreement_percentage": 52.17391304347826,
        "mcc": 0.01996807659577179,
        "accuracy": 0.5217391304347826,
        "precision": 0.5263157894736842,
        "recall": 0.8333333333333334,
        "f1_score": 0.6451612903225806,
        "balanced_accuracy": 0.5075757575757576,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "9",
        "agreement_percentage": 39.130434782608695,
        "mcc": -0.2196969696969697,
        "accuracy": 0.391304347826087,
        "precision": 0.4166666666666667,
        "recall": 0.4166666666666667,
        "f1_score": 0.4166666666666667,
        "balanced_accuracy": 0.39015151515151514,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "15",
        "agreement_percentage": 65.21739130434783,
        "mcc": 0.40451991747794525,
        "accuracy": 0.6521739130434783,
        "precision": 0.6,
        "recall": 1.0,
        "f1_score": 0.7499999999999999,
        "balanced_accuracy": 0.6363636363636364,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "12",
        "agreement_percentage": 52.17391304347826,
        "mcc": 0.0381690510345287,
        "accuracy": 0.5217391304347826,
        "precision": 0.5384615384615384,
        "recall": 0.5833333333333334,
        "f1_score": 0.5599999999999999,
        "balanced_accuracy": 0.5189393939393939,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "14",
        "agreement_percentage": 60.86956521739131,
        "mcc": 0.21374668579336073,
        "accuracy": 0.6086956521739131,
        "precision": 0.6153846153846154,
        "recall": 0.6666666666666666,
        "f1_score": 0.64,
        "balanced_accuracy": 0.606060606060606,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "15",
        "agreement_percentage": 65.21739130434783,
        "mcc": 0.30303030303030304,
        "accuracy": 0.6521739130434783,
        "precision": 0.6666666666666666,
        "recall": 0.6666666666666666,
        "f1_score": 0.6666666666666666,
        "balanced_accuracy": 0.6515151515151515,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "10",
        "agreement_percentage": 43.47826086956522,
        "mcc": -0.12336594280495668,
        "accuracy": 0.43478260869565216,
        "precision": 0.42857142857142855,
        "recall": 0.25,
        "f1_score": 0.3157894736842105,
        "balanced_accuracy": 0.4431818181818182,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "9",
        "agreement_percentage": 39.130434782608695,
        "mcc": -0.22407133233117496,
        "accuracy": 0.391304347826087,
        "precision": 0.3333333333333333,
        "recall": 0.16666666666666666,
        "f1_score": 0.2222222222222222,
        "balanced_accuracy": 0.4015151515151515,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "11",
        "agreement_percentage": 47.82608695652174,
        "mcc": -0.025854384499750957,
        "accuracy": 0.4782608695652174,
        "precision": 0.5,
        "recall": 0.25,
        "f1_score": 0.3333333333333333,
        "balanced_accuracy": 0.48863636363636365,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}