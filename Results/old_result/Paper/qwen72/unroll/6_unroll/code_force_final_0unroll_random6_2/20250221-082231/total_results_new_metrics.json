{
    "total_valid_rows": {
        "value": 83,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "41",
        "agreement_percentage": 49.39759036144578,
        "mcc": 0.057587984588733855,
        "accuracy": 0.4939759036144578,
        "precision": 0.6666666666666666,
        "recall": 0.046511627906976744,
        "f1_score": 0.08695652173913045,
        "balanced_accuracy": 0.5107558139534883,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "45",
        "agreement_percentage": 54.21686746987952,
        "mcc": 0.24419314525275218,
        "accuracy": 0.5421686746987951,
        "precision": 1.0,
        "recall": 0.11627906976744186,
        "f1_score": 0.20833333333333334,
        "balanced_accuracy": 0.5581395348837209,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "47",
        "agreement_percentage": 56.62650602409639,
        "mcc": 0.1313953488372093,
        "accuracy": 0.5662650602409639,
        "precision": 0.5813953488372093,
        "recall": 0.5813953488372093,
        "f1_score": 0.5813953488372093,
        "balanced_accuracy": 0.5656976744186046,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "49",
        "agreement_percentage": 59.036144578313255,
        "mcc": 0.18335285998211237,
        "accuracy": 0.5903614457831325,
        "precision": 0.6153846153846154,
        "recall": 0.5581395348837209,
        "f1_score": 0.5853658536585366,
        "balanced_accuracy": 0.5915697674418605,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "51",
        "agreement_percentage": 61.44578313253012,
        "mcc": 0.2262544095006244,
        "accuracy": 0.6144578313253012,
        "precision": 0.6122448979591837,
        "recall": 0.6976744186046512,
        "f1_score": 0.6521739130434783,
        "balanced_accuracy": 0.6113372093023256,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "51",
        "agreement_percentage": 61.44578313253012,
        "mcc": 0.27391050228597436,
        "accuracy": 0.6144578313253012,
        "precision": 0.7391304347826086,
        "recall": 0.3953488372093023,
        "f1_score": 0.5151515151515151,
        "balanced_accuracy": 0.6226744186046511,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "48",
        "agreement_percentage": 57.831325301204814,
        "mcc": 0.1629597662776215,
        "accuracy": 0.5783132530120482,
        "precision": 0.6111111111111112,
        "recall": 0.5116279069767442,
        "f1_score": 0.5569620253164557,
        "balanced_accuracy": 0.5808139534883721,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "46",
        "agreement_percentage": 55.42168674698795,
        "mcc": 0.10807671783811604,
        "accuracy": 0.5542168674698795,
        "precision": 0.5714285714285714,
        "recall": 0.5581395348837209,
        "f1_score": 0.5647058823529412,
        "balanced_accuracy": 0.5540697674418604,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "54",
        "agreement_percentage": 65.06024096385542,
        "mcc": 0.30290697674418604,
        "accuracy": 0.6506024096385542,
        "precision": 0.675,
        "recall": 0.627906976744186,
        "f1_score": 0.6506024096385542,
        "balanced_accuracy": 0.651453488372093,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "52",
        "agreement_percentage": 62.65060240963856,
        "mcc": 0.27392736279487995,
        "accuracy": 0.6265060240963856,
        "precision": 0.7,
        "recall": 0.4883720930232558,
        "f1_score": 0.5753424657534246,
        "balanced_accuracy": 0.6316860465116279,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "43",
        "agreement_percentage": 51.80722891566265,
        "mcc": 0.08392751792325623,
        "accuracy": 0.5180722891566265,
        "precision": 0.6153846153846154,
        "recall": 0.18604651162790697,
        "f1_score": 0.2857142857142857,
        "balanced_accuracy": 0.5305232558139534,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "44",
        "agreement_percentage": 53.01204819277109,
        "mcc": 0.09798455981142681,
        "accuracy": 0.5301204819277109,
        "precision": 0.6111111111111112,
        "recall": 0.2558139534883721,
        "f1_score": 0.36065573770491804,
        "balanced_accuracy": 0.540406976744186,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "48",
        "agreement_percentage": 57.831325301204814,
        "mcc": 0.21500209167255524,
        "accuracy": 0.5783132530120482,
        "precision": 0.7222222222222222,
        "recall": 0.3023255813953488,
        "f1_score": 0.4262295081967213,
        "balanced_accuracy": 0.5886627906976745,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}