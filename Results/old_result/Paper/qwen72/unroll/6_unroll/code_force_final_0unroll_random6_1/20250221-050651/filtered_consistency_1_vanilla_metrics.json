{
    "total_valid_rows": {
        "value": 19,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "5",
        "agreement_percentage": 26.31578947368421,
        "mcc": 0,
        "accuracy": 0.2631578947368421,
        "precision": 0,
        "recall": 0.0,
        "f1_score": 0,
        "balanced_accuracy": 0.5,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "9",
        "agreement_percentage": 47.368421052631575,
        "mcc": 0.3086066999241838,
        "accuracy": 0.47368421052631576,
        "precision": 1.0,
        "recall": 0.2857142857142857,
        "f1_score": 0.4444444444444445,
        "balanced_accuracy": 0.6428571428571428,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "13",
        "agreement_percentage": 68.42105263157895,
        "mcc": 0.06900655593423542,
        "accuracy": 0.6842105263157895,
        "precision": 0.75,
        "recall": 0.8571428571428571,
        "f1_score": 0.7999999999999999,
        "balanced_accuracy": 0.5285714285714286,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "13",
        "agreement_percentage": 68.42105263157895,
        "mcc": -0.14085904245475275,
        "accuracy": 0.6842105263157895,
        "precision": 0.7222222222222222,
        "recall": 0.9285714285714286,
        "f1_score": 0.8125000000000001,
        "balanced_accuracy": 0.4642857142857143,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "15",
        "agreement_percentage": 78.94736842105263,
        "mcc": 0.3944053188733077,
        "accuracy": 0.7894736842105263,
        "precision": 0.7777777777777778,
        "recall": 1.0,
        "f1_score": 0.8750000000000001,
        "balanced_accuracy": 0.6,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "9",
        "agreement_percentage": 47.368421052631575,
        "mcc": -0.20865621238292043,
        "accuracy": 0.47368421052631576,
        "precision": 0.6666666666666666,
        "recall": 0.5714285714285714,
        "f1_score": 0.6153846153846153,
        "balanced_accuracy": 0.3857142857142857,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "16",
        "agreement_percentage": 84.21052631578947,
        "mcc": 0.5739440431835514,
        "accuracy": 0.8421052631578947,
        "precision": 0.8235294117647058,
        "recall": 1.0,
        "f1_score": 0.9032258064516129,
        "balanced_accuracy": 0.7,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "13",
        "agreement_percentage": 68.42105263157895,
        "mcc": 0.06900655593423542,
        "accuracy": 0.6842105263157895,
        "precision": 0.75,
        "recall": 0.8571428571428571,
        "f1_score": 0.7999999999999999,
        "balanced_accuracy": 0.5285714285714286,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "12",
        "agreement_percentage": 63.1578947368421,
        "mcc": -0.015430334996209192,
        "accuracy": 0.631578947368421,
        "precision": 0.7333333333333333,
        "recall": 0.7857142857142857,
        "f1_score": 0.7586206896551724,
        "balanced_accuracy": 0.4928571428571429,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "10",
        "agreement_percentage": 52.63157894736842,
        "mcc": -0.14886628953921086,
        "accuracy": 0.5263157894736842,
        "precision": 0.6923076923076923,
        "recall": 0.6428571428571429,
        "f1_score": 0.6666666666666666,
        "balanced_accuracy": 0.4214285714285715,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "9",
        "agreement_percentage": 47.368421052631575,
        "mcc": 0.025482359571881278,
        "accuracy": 0.47368421052631576,
        "precision": 0.75,
        "recall": 0.42857142857142855,
        "f1_score": 0.5454545454545454,
        "balanced_accuracy": 0.5142857142857142,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "7",
        "agreement_percentage": 36.84210526315789,
        "mcc": -0.21660005636099086,
        "accuracy": 0.3684210526315789,
        "precision": 0.625,
        "recall": 0.35714285714285715,
        "f1_score": 0.45454545454545453,
        "balanced_accuracy": 0.37857142857142856,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "9",
        "agreement_percentage": 47.368421052631575,
        "mcc": 0.025482359571881278,
        "accuracy": 0.47368421052631576,
        "precision": 0.75,
        "recall": 0.42857142857142855,
        "f1_score": 0.5454545454545454,
        "balanced_accuracy": 0.5142857142857142,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}