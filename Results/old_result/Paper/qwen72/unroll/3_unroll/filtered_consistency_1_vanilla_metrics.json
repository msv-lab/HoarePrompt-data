{
    "total_valid_rows": {
        "value": 39,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "13",
        "agreement_percentage": 33.33333333333333,
        "mcc": 0.10814761408717502,
        "accuracy": 0.3333333333333333,
        "precision": 1.0,
        "recall": 0.037037037037037035,
        "f1_score": 0.07142857142857142,
        "balanced_accuracy": 0.5185185185185185,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "16",
        "agreement_percentage": 41.02564102564102,
        "mcc": 0.2253744679276044,
        "accuracy": 0.41025641025641024,
        "precision": 1.0,
        "recall": 0.14814814814814814,
        "f1_score": 0.25806451612903225,
        "balanced_accuracy": 0.5740740740740741,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "27",
        "agreement_percentage": 69.23076923076923,
        "mcc": 0.14085904245475275,
        "accuracy": 0.6923076923076923,
        "precision": 0.7142857142857143,
        "recall": 0.9259259259259259,
        "f1_score": 0.8064516129032259,
        "balanced_accuracy": 0.5462962962962963,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "24",
        "agreement_percentage": 61.53846153846154,
        "mcc": -0.0222717701593687,
        "accuracy": 0.6153846153846154,
        "precision": 0.6875,
        "recall": 0.8148148148148148,
        "f1_score": 0.7457627118644067,
        "balanced_accuracy": 0.4907407407407407,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "26",
        "agreement_percentage": 66.66666666666666,
        "mcc": 0.016037507477489603,
        "accuracy": 0.6666666666666666,
        "precision": 0.6944444444444444,
        "recall": 0.9259259259259259,
        "f1_score": 0.7936507936507936,
        "balanced_accuracy": 0.5046296296296297,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "vanilla_no_cot": {
        "agreement_count": "28",
        "agreement_percentage": 71.7948717948718,
        "mcc": 0.3535533905932738,
        "accuracy": 0.717948717948718,
        "precision": 0.8076923076923077,
        "recall": 0.7777777777777778,
        "f1_score": 0.7924528301886792,
        "balanced_accuracy": 0.6805555555555556,
        "description": "Agreement analysis between 'vanilla_no_cot' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "23",
        "agreement_percentage": 58.97435897435898,
        "mcc": -0.2253744679276044,
        "accuracy": 0.5897435897435898,
        "precision": 0.6571428571428571,
        "recall": 0.8518518518518519,
        "f1_score": 0.7419354838709677,
        "balanced_accuracy": 0.42592592592592593,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "28",
        "agreement_percentage": 71.7948717948718,
        "mcc": 0.24287224646833397,
        "accuracy": 0.717948717948718,
        "precision": 0.7352941176470589,
        "recall": 0.9259259259259259,
        "f1_score": 0.819672131147541,
        "balanced_accuracy": 0.587962962962963,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "25",
        "agreement_percentage": 64.1025641025641,
        "mcc": 0.023688968483956716,
        "accuracy": 0.6410256410256411,
        "precision": 0.696969696969697,
        "recall": 0.8518518518518519,
        "f1_score": 0.7666666666666667,
        "balanced_accuracy": 0.5092592592592593,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "25",
        "agreement_percentage": 64.1025641025641,
        "mcc": 0.023688968483956716,
        "accuracy": 0.6410256410256411,
        "precision": 0.696969696969697,
        "recall": 0.8518518518518519,
        "f1_score": 0.7666666666666667,
        "balanced_accuracy": 0.5092592592592593,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "18",
        "agreement_percentage": 46.15384615384615,
        "mcc": -0.051434449987363975,
        "accuracy": 0.46153846153846156,
        "precision": 0.6666666666666666,
        "recall": 0.4444444444444444,
        "f1_score": 0.5333333333333333,
        "balanced_accuracy": 0.4722222222222222,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "20",
        "agreement_percentage": 51.28205128205128,
        "mcc": 0.0600068583185913,
        "accuracy": 0.5128205128205128,
        "precision": 0.7222222222222222,
        "recall": 0.48148148148148145,
        "f1_score": 0.5777777777777777,
        "balanced_accuracy": 0.5324074074074074,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "19",
        "agreement_percentage": 48.717948717948715,
        "mcc": -0.0600068583185913,
        "accuracy": 0.48717948717948717,
        "precision": 0.6666666666666666,
        "recall": 0.5185185185185185,
        "f1_score": 0.5833333333333334,
        "balanced_accuracy": 0.46759259259259256,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}