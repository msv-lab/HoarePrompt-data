This function calculates and returns the polar coordinates of a point given its Cartesian coordinates. It accepts two real number parameters, `x` and `y`, and returns a tuple containing the Euclidean distance `r` from the origin to the point (`x`, `y`) and the angle `theta` in radians from the positive x-axis to the line connecting the origin to (`x`, `y`). The function handles all possible real number inputs for `x` and `y`, including zero, positive, and negative values, and returns the corresponding `r` and `theta` values. For the edge case where both `x` and `y` are zero, the function will return `r = 0` and `theta = 0` because `math.atan2(0, 0)` is defined to return 0 in Python. The function does not perform any error checking on the inputs, so it assumes that the inputs are always real numbers. The state of the program after it concludes is that the original `x` and `y` values remain unchanged, and the function returns a tuple containing the calculated `r` and `theta` values.