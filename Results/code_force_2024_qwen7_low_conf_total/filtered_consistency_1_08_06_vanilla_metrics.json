{
    "total_valid_rows": {
        "value": 268,
        "description": "Total number of valid rows after preprocessing and removing invalid entries."
    },
    "summary fsl": {
        "agreement_count": "141",
        "agreement_percentage": 52.61194029850746,
        "mcc": -0.03213877744215004,
        "accuracy": 0.5261194029850746,
        "precision": 0.4074074074074074,
        "recall": 0.09016393442622951,
        "f1_score": 0.1476510067114094,
        "balanced_accuracy": 0.49028744666516955,
        "description": "Agreement analysis between 'summary fsl' and 'original correctness'."
    },
    "naive correctness fsl": {
        "agreement_count": "148",
        "agreement_percentage": 55.223880597014926,
        "mcc": 0.057391351758358466,
        "accuracy": 0.5522388059701493,
        "precision": 0.5277777777777778,
        "recall": 0.1557377049180328,
        "f1_score": 0.24050632911392406,
        "balanced_accuracy": 0.5196496743768246,
        "description": "Agreement analysis between 'naive correctness fsl' and 'original correctness'."
    },
    "simple tree": {
        "agreement_count": "131",
        "agreement_percentage": 48.88059701492538,
        "mcc": -0.041445315555948915,
        "accuracy": 0.48880597014925375,
        "precision": 0.42990654205607476,
        "recall": 0.3770491803278688,
        "f1_score": 0.40174672489082963,
        "balanced_accuracy": 0.4796204805748933,
        "description": "Agreement analysis between 'simple tree' and 'original correctness'."
    },
    "complex tree": {
        "agreement_count": "125",
        "agreement_percentage": 46.64179104477612,
        "mcc": -0.001493496396869764,
        "accuracy": 0.4664179104477612,
        "precision": 0.45493562231759654,
        "recall": 0.8688524590163934,
        "f1_score": 0.5971830985915493,
        "balanced_accuracy": 0.4994947226588816,
        "description": "Agreement analysis between 'complex tree' and 'original correctness'."
    },
    "vanilla": {
        "agreement_count": "126",
        "agreement_percentage": 47.01492537313433,
        "mcc": -0.006221538336212237,
        "accuracy": 0.4701492537313433,
        "precision": 0.4537037037037037,
        "recall": 0.8032786885245902,
        "f1_score": 0.5798816568047337,
        "balanced_accuracy": 0.4975297552211992,
        "description": "Agreement analysis between 'vanilla' and 'original correctness'."
    },
    "summary": {
        "agreement_count": "131",
        "agreement_percentage": 48.88059701492538,
        "mcc": 0.04470046432973836,
        "accuracy": 0.48880597014925375,
        "precision": 0.4657534246575342,
        "recall": 0.8360655737704918,
        "f1_score": 0.5982404692082112,
        "balanced_accuracy": 0.5173478553783966,
        "description": "Agreement analysis between 'summary' and 'original correctness'."
    },
    "simple verify": {
        "agreement_count": "127",
        "agreement_percentage": 47.38805970149254,
        "mcc": -0.04651561035291928,
        "accuracy": 0.47388059701492535,
        "precision": 0.43356643356643354,
        "recall": 0.5081967213114754,
        "f1_score": 0.4679245283018868,
        "balanced_accuracy": 0.4767011003817651,
        "description": "Agreement analysis between 'simple verify' and 'original correctness'."
    },
    "complex verify": {
        "agreement_count": "131",
        "agreement_percentage": 48.88059701492538,
        "mcc": -0.015148543002269092,
        "accuracy": 0.48880597014925375,
        "precision": 0.4482758620689655,
        "recall": 0.5327868852459017,
        "f1_score": 0.4868913857677903,
        "balanced_accuracy": 0.4924208398832248,
        "description": "Agreement analysis between 'complex verify' and 'original correctness'."
    },
    "summary verify": {
        "agreement_count": "135",
        "agreement_percentage": 50.373134328358205,
        "mcc": -0.0012359900797757838,
        "accuracy": 0.503731343283582,
        "precision": 0.45454545454545453,
        "recall": 0.45081967213114754,
        "f1_score": 0.45267489711934156,
        "balanced_accuracy": 0.49938243880529976,
        "description": "Agreement analysis between 'summary verify' and 'original correctness'."
    },
    "simple verify fsl": {
        "agreement_count": "141",
        "agreement_percentage": 52.61194029850746,
        "mcc": 0.049128772967520225,
        "accuracy": 0.5261194029850746,
        "precision": 0.4806201550387597,
        "recall": 0.5081967213114754,
        "f1_score": 0.4940239043824701,
        "balanced_accuracy": 0.5246463058612172,
        "description": "Agreement analysis between 'simple verify fsl' and 'original correctness'."
    },
    "complex verify fsl": {
        "agreement_count": "129",
        "agreement_percentage": 48.134328358208954,
        "mcc": -0.04499678328822153,
        "accuracy": 0.48134328358208955,
        "precision": 0.43089430894308944,
        "recall": 0.4344262295081967,
        "f1_score": 0.4326530612244898,
        "balanced_accuracy": 0.4774870873568381,
        "description": "Agreement analysis between 'complex verify fsl' and 'original correctness'."
    },
    "summary verify fsl": {
        "agreement_count": "135",
        "agreement_percentage": 50.373134328358205,
        "mcc": 0.013562382777598152,
        "accuracy": 0.503731343283582,
        "precision": 0.46153846153846156,
        "recall": 0.5409836065573771,
        "f1_score": 0.49811320754716987,
        "balanced_accuracy": 0.5067931731417022,
        "description": "Agreement analysis between 'summary verify fsl' and 'original correctness'."
    }
}