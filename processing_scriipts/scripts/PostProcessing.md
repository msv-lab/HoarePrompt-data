
# Analysis Workflow for Pilot Dataset

This document provides a detailed guide to process and analyze your pilot dataset using the available tools and scripts.

## Step 1: Generate Consistency for the Dataset

1. Use `test_confidence.py` from the experiments repository to calculate the consistency for your dataset.
   - The output will be a `consistency.json` file.
   - Example: 
     ```
     python test_confidence.py --input <your_dataset>.json --output consistency.json
     ```


## Step 2: Obtain the Initial Results

1. Ensure your dataset results are in a CSV format (`original.csv`).


## Step 3: Generate Augmented Data and Subsets

1. Using `consistency.json` and `original.csv`, run `not_consistent.py` to generate the augmented data:
   - Output: `augmented.json` (includes unique_id and consistency).
   ```
   python not_consistent.py --input original.csv --consistency consistency.json --output augmented.json
   ```

2. Subsets will also be generated during this step:
   - `filtered_1.json`
   - `filtered_1_09.json`
   - `filtered_1_09_08.json`
   - `filtered_1_09_08_07.json`
   - These subsets exclude rows with specific confidence levels (e.g., 1, 0.9, etc.).
3. If the number of functions in the script is not included in the json, use `transfer_functions_num.py` to generate it for each row in the CSV:
   ```
   python transfer_functions_num.py - original.csv 
   ```
## Step 4: Analyze the Results

1. Use `postprocessing_new.py` from the experiments repository to generate an analysis report:
   - Output: `analysis_reports.json`
   ```
   python postprocessing_new.py --input augmented.json --output analysis_reports.json
   ```

2. For consistency correlation with classifier performance:
   - Run `consistency_correlation.py` on the augmented data:
     ```
     python consistency_correlation.py --input augmented.csv --output consistency_correlation.json
     ```

3. For correlation between the number of functions and classifier performance:
   - Run `functions_num_correlation.py`:
     ```
     python functions_num_correlation.py --input augmented.csv --output functions_num_correlation.json
     ```

## Step 5: Qualitative Analysis

1. Use `qualitative_analysis.py` for case-by-case analysis:
   - This identifies examples where one classifier consistently outperforms another.
   ```
   python qualitative_analysis.py --input augmented.csv --output qualitative_analysis.json
   ```

2. Example output:
   ```
   "naive no fsl correctness_outperforms_Correctness": {
       "rows": [
           {
               "unique_id": "62_llama3-70b",
               "consistency": 1.0,
               "count": 3
           }
       ]
   }
   ```

   - This shows that for test case 62 (unique_id: 62_llama3-70b, generated by llama model):
     - Consistency: 1.0
     - The `naive_no_fsl` classifier outperformed the `Correctness` classifier 3 times.

3. Summary for each comparison includes:
   - Total count of examples where one classifier outperformed another.
   - Average consistency of those examples:
     ```
     "count": 59,
     "average_consistency": 0.8559322033898303
     ```

## Notes

- Higher count values in `qualitative_analysis.json` indicate examples worth manual inspection.
- Use the results to refine your dataset and improve classifier performance.
